# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šæ‘˜è¦ç”Ÿæˆå™¨

å°†å†—é•¿çš„è¾©è®ºæŠ¥å‘Šï¼ˆå¦‚ research_team_decision.md, risk_management_decision.mdï¼‰
ç²¾ç®€ä¸ºæ˜“è¯»çš„æ‘˜è¦ç‰ˆæœ¬ï¼ŒåŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯ã€‚

ç›®æ ‡ï¼š
- å°† 100KB+ çš„æŠ¥å‘Šå‹ç¼©åˆ° 10KB ä»¥å†…
- ä¿ç•™ç»“è®ºã€å…³é”®è®ºç‚¹ã€æ•°æ®éªŒè¯ç»“æœ
- ç”Ÿæˆç»“æ„åŒ–çš„æ‘˜è¦æ ¼å¼
"""

import re
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime

# å¯¼å…¥æ—¥å¿—
try:
    from tradingagents.utils.logging_init import get_logger
    logger = get_logger("report_summarizer")
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


class ReportSummarizer:
    """æŠ¥å‘Šæ‘˜è¦ç”Ÿæˆå™¨"""

    # æ‘˜è¦ç›®æ ‡å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
    TARGET_SUMMARY_SIZE = 8000  # çº¦ 8KB
    MAX_SUMMARY_SIZE = 12000    # æœ€å¤§ 12KB

    # å…³é”®è¯æƒé‡ï¼ˆç”¨äºè¯†åˆ«é‡è¦å¥å­ï¼‰
    IMPORTANCE_KEYWORDS = {
        # ç»“è®ºæ€§å…³é”®è¯ï¼ˆæœ€é«˜æƒé‡ï¼‰
        "conclusion": ["å»ºè®®", "ç»“è®º", "å†³ç­–", "åˆ¤æ–­", "æ€»ç»“", "æœ€ç»ˆ", "ç»¼åˆ", "ä¹°å…¥", "å–å‡º", "æŒæœ‰"],
        # æ•°æ®å…³é”®è¯ï¼ˆé«˜æƒé‡ï¼‰
        "data": ["å¸‚ç›ˆç‡", "PE", "PB", "ROE", "æˆäº¤é‡", "æ¶¨è·Œ", "ä»·æ ¼", "ä¼°å€¼", "è¥æ”¶", "åˆ©æ¶¦"],
        # é£é™©å…³é”®è¯ï¼ˆä¸­é«˜æƒé‡ï¼‰
        "risk": ["é£é™©", "è­¦å‘Š", "æ³¨æ„", "è°¨æ…", "æ³¢åŠ¨", "ä¸‹è·Œ", "äºæŸ", "æ­¢æŸ"],
        # è®ºç‚¹å…³é”®è¯ï¼ˆä¸­æƒé‡ï¼‰
        "argument": ["å› ä¸º", "å› æ­¤", "æ‰€ä»¥", "ç”±äº", "å¯¼è‡´", "è¡¨æ˜", "æ˜¾ç¤º", "æ”¯æ’‘", "åé©³"],
    }

    def __init__(self):
        self.extraction_stats = {}

    def summarize_research_decision(
        self,
        full_content: str,
        stock_code: str = "",
        company_name: str = ""
    ) -> Tuple[str, str]:
        """
        ç”Ÿæˆç ”ç©¶å›¢é˜Ÿå†³ç­–æŠ¥å‘Šçš„æ‘˜è¦

        Args:
            full_content: å®Œæ•´æŠ¥å‘Šå†…å®¹
            stock_code: è‚¡ç¥¨ä»£ç 
            company_name: å…¬å¸åç§°

        Returns:
            Tuple[str, str]: (æ‘˜è¦ç‰ˆæœ¬, å®Œæ•´ç‰ˆæœ¬æ ‡è®°)
        """
        if not full_content or len(full_content) < 1000:
            # å†…å®¹å¤ªçŸ­ï¼Œæ— éœ€æ‘˜è¦
            return full_content, full_content

        logger.info(f"ğŸ“ [æ‘˜è¦ç”Ÿæˆ] ç ”ç©¶å†³ç­–æŠ¥å‘ŠåŸå§‹é•¿åº¦: {len(full_content):,} å­—ç¬¦")

        # æå–å…³é”®éƒ¨åˆ†
        conclusion = self._extract_conclusion(full_content)
        key_arguments = self._extract_key_arguments(full_content)
        data_points = self._extract_data_points(full_content)
        recommendation = self._extract_recommendation(full_content)

        # æ„å»ºæ‘˜è¦
        summary = self._build_research_summary(
            conclusion=conclusion,
            key_arguments=key_arguments,
            data_points=data_points,
            recommendation=recommendation,
            stock_code=stock_code,
            company_name=company_name,
            original_length=len(full_content)
        )

        logger.info(f"ğŸ“ [æ‘˜è¦ç”Ÿæˆ] ç ”ç©¶å†³ç­–æŠ¥å‘Šæ‘˜è¦é•¿åº¦: {len(summary):,} å­—ç¬¦ (å‹ç¼©ç‡: {len(summary)/len(full_content)*100:.1f}%)")

        return summary, full_content

    def summarize_risk_decision(
        self,
        full_content: str,
        stock_code: str = "",
        company_name: str = ""
    ) -> Tuple[str, str]:
        """
        ç”Ÿæˆé£é™©ç®¡ç†å†³ç­–æŠ¥å‘Šçš„æ‘˜è¦

        Args:
            full_content: å®Œæ•´æŠ¥å‘Šå†…å®¹
            stock_code: è‚¡ç¥¨ä»£ç 
            company_name: å…¬å¸åç§°

        Returns:
            Tuple[str, str]: (æ‘˜è¦ç‰ˆæœ¬, å®Œæ•´ç‰ˆæœ¬)
        """
        if not full_content or len(full_content) < 1000:
            return full_content, full_content

        logger.info(f"ğŸ“ [æ‘˜è¦ç”Ÿæˆ] é£é™©å†³ç­–æŠ¥å‘ŠåŸå§‹é•¿åº¦: {len(full_content):,} å­—ç¬¦")

        # æå–å…³é”®éƒ¨åˆ†
        conclusion = self._extract_conclusion(full_content)
        risk_factors = self._extract_risk_factors(full_content)
        risk_assessment = self._extract_risk_assessment(full_content)
        recommendation = self._extract_recommendation(full_content)

        # æ„å»ºæ‘˜è¦
        summary = self._build_risk_summary(
            conclusion=conclusion,
            risk_factors=risk_factors,
            risk_assessment=risk_assessment,
            recommendation=recommendation,
            stock_code=stock_code,
            company_name=company_name,
            original_length=len(full_content)
        )

        logger.info(f"ğŸ“ [æ‘˜è¦ç”Ÿæˆ] é£é™©å†³ç­–æŠ¥å‘Šæ‘˜è¦é•¿åº¦: {len(summary):,} å­—ç¬¦ (å‹ç¼©ç‡: {len(summary)/len(full_content)*100:.1f}%)")

        return summary, full_content

    def _extract_conclusion(self, content: str) -> str:
        """æå–ç»“è®ºéƒ¨åˆ†"""
        # å°è¯•å¤šç§æ¨¡å¼åŒ¹é…ç»“è®º
        patterns = [
            r'(?:ç»“è®º|æ€»ç»“|æœ€ç»ˆå†³ç­–|ç»¼åˆè¯„ä¼°)[ï¼š:\s]*(.{100,800}?)(?=\n\n|\n#|$)',
            r'(?:å»ºè®®|å†³ç­–)[ï¼š:\s]*\*{0,2}(ä¹°å…¥|å–å‡º|æŒæœ‰)\*{0,2}(.{0,500}?)(?=\n\n|\n#|$)',
            r'(?:ç»¼åˆæ¥çœ‹|æ€»ä½“è€Œè¨€|ç»¼ä¸Šæ‰€è¿°)[ï¼Œ,](.{100,600}?)(?=\n\n|\n#|$)',
        ]

        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL)
            if match:
                return match.group(0).strip()[:800]

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œæå–æœ€åä¸€æ®µä½œä¸ºç»“è®º
        paragraphs = content.split('\n\n')
        for para in reversed(paragraphs):
            if len(para.strip()) > 100:
                return para.strip()[:800]

        return ""

    def _extract_key_arguments(self, content: str) -> List[str]:
        """æå–å…³é”®è®ºç‚¹"""
        arguments = []

        # æŸ¥æ‰¾çœ‹æ¶¨/çœ‹è·Œè®ºç‚¹
        bull_pattern = r'(?:çœ‹æ¶¨|å¤šå¤´|ç§¯æ)[^ï¼š:]*[ï¼š:](.{50,300}?)(?=\n\n|\n-|\n#|$)'
        bear_pattern = r'(?:çœ‹è·Œ|ç©ºå¤´|æ¶ˆæ|é£é™©)[^ï¼š:]*[ï¼š:](.{50,300}?)(?=\n\n|\n-|\n#|$)'

        for pattern in [bull_pattern, bear_pattern]:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches[:3]:  # æ¯ç±»æœ€å¤š3ä¸ª
                clean_arg = match.strip()
                if len(clean_arg) > 50:
                    arguments.append(clean_arg[:300])

        # å¦‚æœè®ºç‚¹ä¸è¶³ï¼ŒæŒ‰é‡è¦æ€§æå–å¥å­
        if len(arguments) < 4:
            important_sentences = self._extract_important_sentences(content, 6 - len(arguments))
            arguments.extend(important_sentences)

        return arguments[:6]  # æœ€å¤š6ä¸ªå…³é”®è®ºç‚¹

    def _extract_data_points(self, content: str) -> List[str]:
        """æå–å…³é”®æ•°æ®ç‚¹"""
        data_points = []

        # æŸ¥æ‰¾åŒ…å«æ•°å­—çš„å…³é”®æ•°æ®
        patterns = [
            r'(?:å¸‚ç›ˆç‡|PE)[ï¼š:\s]*(\d+\.?\d*)',
            r'(?:å¸‚å‡€ç‡|PB)[ï¼š:\s]*(\d+\.?\d*)',
            r'(?:ROE|å‡€èµ„äº§æ”¶ç›Šç‡)[ï¼š:\s]*(\d+\.?\d*%?)',
            r'(?:å½“å‰ä»·|ç°ä»·|è‚¡ä»·)[ï¼š:\s]*[Â¥ï¿¥$]?(\d+\.?\d*)',
            r'(?:ç›®æ ‡ä»·)[ï¼š:\s]*[Â¥ï¿¥$]?(\d+\.?\d*)',
            r'(?:æ¶¨è·Œå¹…|æ¶¨å¹…|è·Œå¹…)[ï¼š:\s]*([+-]?\d+\.?\d*%?)',
            r'(?:æˆäº¤é‡)[ï¼š:\s]*([\d,]+\.?\d*)\s*(?:è‚¡|ä¸‡è‚¡)?',
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                # è·å–å®Œæ•´ä¸Šä¸‹æ–‡
                start = max(0, match.start() - 20)
                end = min(len(content), match.end() + 20)
                context = content[start:end].strip()
                if context not in data_points:
                    data_points.append(context)

        return data_points[:8]  # æœ€å¤š8ä¸ªæ•°æ®ç‚¹

    def _extract_risk_factors(self, content: str) -> List[str]:
        """æå–é£é™©å› ç´ """
        risk_factors = []

        # æŸ¥æ‰¾é£é™©ç›¸å…³å†…å®¹
        patterns = [
            r'(?:é£é™©å› ç´ |ä¸»è¦é£é™©|æ½œåœ¨é£é™©)[ï¼š:\s]*(.{50,300}?)(?=\n\n|\n-|\n#|$)',
            r'(?:éœ€è¦æ³¨æ„|å€¼å¾—å…³æ³¨|è­¦æƒ•)[ï¼š:\s]*(.{30,200}?)(?=\n\n|\nã€‚|$)',
            r'(?:ä¸‹è¡Œé£é™©|ä¸åˆ©å› ç´ )[ï¼š:\s]*(.{50,300}?)(?=\n\n|\n-|\n#|$)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches[:3]:
                clean_risk = match.strip()
                if len(clean_risk) > 30:
                    risk_factors.append(clean_risk[:300])

        return risk_factors[:5]

    def _extract_risk_assessment(self, content: str) -> str:
        """æå–é£é™©è¯„ä¼°ç»“æœ"""
        patterns = [
            r'(?:é£é™©ç­‰çº§|é£é™©è¯„çº§|é£é™©è¯„ä¼°)[ï¼š:\s]*(.{20,200}?)(?=\n|\n\n|$)',
            r'(?:æ¿€è¿›|ä¿å®ˆ|ä¸­æ€§)[^ï¼š:]*åˆ†æå¸ˆ[^ï¼š:]*[ï¼š:](.{50,300}?)(?=\n\n|$)',
        ]

        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL)
            if match:
                return match.group(0).strip()[:400]

        return ""

    def _extract_recommendation(self, content: str) -> str:
        """æå–æŠ•èµ„å»ºè®®"""
        patterns = [
            r'(?:æœ€ç»ˆäº¤æ˜“å»ºè®®|æŠ•èµ„å»ºè®®|å»ºè®®)[ï¼š:\s]*\*{0,2}(ä¹°å…¥|æŒæœ‰|å–å‡º)\*{0,2}',
            r'\*{2}(ä¹°å…¥|æŒæœ‰|å–å‡º)\*{2}',
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1)

        return "æœªæ˜ç¡®"

    def _extract_important_sentences(self, content: str, count: int) -> List[str]:
        """æŒ‰é‡è¦æ€§æå–å¥å­"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
        scored_sentences = []

        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 30 or len(sentence) > 300:
                continue

            score = 0
            for category, keywords in self.IMPORTANCE_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in sentence:
                        if category == "conclusion":
                            score += 3
                        elif category == "data":
                            score += 2
                        elif category == "risk":
                            score += 2
                        else:
                            score += 1

            if score > 0:
                scored_sentences.append((score, sentence))

        # æŒ‰åˆ†æ•°æ’åºï¼Œå–å‰Nä¸ª
        scored_sentences.sort(key=lambda x: x[0], reverse=True)
        return [s[1] for s in scored_sentences[:count]]

    def _build_research_summary(
        self,
        conclusion: str,
        key_arguments: List[str],
        data_points: List[str],
        recommendation: str,
        stock_code: str,
        company_name: str,
        original_length: int
    ) -> str:
        """æ„å»ºç ”ç©¶å›¢é˜Ÿå†³ç­–æ‘˜è¦"""
        display_name = company_name if company_name else stock_code

        summary = f"""# {display_name} ç ”ç©¶å›¢é˜Ÿå†³ç­–æ‘˜è¦

> æœ¬æ‘˜è¦ä» {original_length:,} å­—ç¬¦çš„å®Œæ•´è¾©è®ºä¸­æå–å…³é”®ä¿¡æ¯
> å®Œæ•´ç‰ˆæœ¬è¯·æŸ¥çœ‹: research_team_decision_full.md

---

## æ ¸å¿ƒç»“è®º

**æŠ•èµ„å»ºè®®**: **{recommendation}**

{conclusion if conclusion else "ï¼ˆç»“è®ºæå–ä¸­...ï¼‰"}

---

## å…³é”®è®ºç‚¹

"""
        # æ·»åŠ å…³é”®è®ºç‚¹
        if key_arguments:
            for i, arg in enumerate(key_arguments, 1):
                summary += f"### è®ºç‚¹ {i}\n{arg}\n\n"
        else:
            summary += "*æš‚æ— æ˜ç¡®è®ºç‚¹*\n\n"

        # æ·»åŠ æ•°æ®éªŒè¯
        summary += "---\n\n## å…³é”®æ•°æ®ç‚¹\n\n"
        if data_points:
            summary += "| æŒ‡æ ‡ | æ•°å€¼ |\n|------|------|\n"
            for dp in data_points:
                # æ¸…ç†å¹¶æ ¼å¼åŒ–æ•°æ®ç‚¹
                clean_dp = dp.replace('\n', ' ').strip()
                summary += f"| {clean_dp} |\n"
        else:
            summary += "*æš‚æ— å…³é”®æ•°æ®*\n\n"

        # æ·»åŠ æ—¶é—´æˆ³
        summary += f"""
---

*æ‘˜è¦ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*æ­¤ä¸ºç²¾ç®€æ‘˜è¦ï¼Œå¦‚éœ€æŸ¥çœ‹å®Œæ•´è¾©è®ºè¿‡ç¨‹ï¼Œè¯·å‚é˜…å®Œæ•´ç‰ˆæŠ¥å‘Š*
"""

        return summary

    def _build_risk_summary(
        self,
        conclusion: str,
        risk_factors: List[str],
        risk_assessment: str,
        recommendation: str,
        stock_code: str,
        company_name: str,
        original_length: int
    ) -> str:
        """æ„å»ºé£é™©ç®¡ç†å†³ç­–æ‘˜è¦"""
        display_name = company_name if company_name else stock_code

        summary = f"""# {display_name} é£é™©ç®¡ç†å†³ç­–æ‘˜è¦

> æœ¬æ‘˜è¦ä» {original_length:,} å­—ç¬¦çš„å®Œæ•´é£é™©è¾©è®ºä¸­æå–å…³é”®ä¿¡æ¯
> å®Œæ•´ç‰ˆæœ¬è¯·æŸ¥çœ‹: risk_management_decision_full.md

---

## é£é™©è¯„ä¼°ç»“è®º

**æœ€ç»ˆå»ºè®®**: **{recommendation}**

{risk_assessment if risk_assessment else "ï¼ˆé£é™©è¯„ä¼°æå–ä¸­...ï¼‰"}

---

## ä¸»è¦é£é™©å› ç´ 

"""
        # æ·»åŠ é£é™©å› ç´ 
        if risk_factors:
            for i, risk in enumerate(risk_factors, 1):
                summary += f"### é£é™© {i}\n{risk}\n\n"
        else:
            summary += "*æš‚æ— æ˜ç¡®é£é™©å› ç´ *\n\n"

        # æ·»åŠ ç»“è®º
        if conclusion:
            summary += f"---\n\n## ç»¼åˆè¯„ä¼°\n\n{conclusion}\n\n"

        # æ·»åŠ æ—¶é—´æˆ³
        summary += f"""
---

*æ‘˜è¦ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*æ­¤ä¸ºç²¾ç®€æ‘˜è¦ï¼Œå¦‚éœ€æŸ¥çœ‹å®Œæ•´é£é™©è¾©è®ºè¿‡ç¨‹ï¼Œè¯·å‚é˜…å®Œæ•´ç‰ˆæŠ¥å‘Š*
"""

        return summary


def summarize_report(
    content: str,
    report_type: str,
    stock_code: str = "",
    company_name: str = ""
) -> Tuple[str, str]:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”ŸæˆæŠ¥å‘Šæ‘˜è¦

    Args:
        content: æŠ¥å‘Šå†…å®¹
        report_type: æŠ¥å‘Šç±»å‹ ("research" æˆ– "risk")
        stock_code: è‚¡ç¥¨ä»£ç 
        company_name: å…¬å¸åç§°

    Returns:
        Tuple[str, str]: (æ‘˜è¦ç‰ˆæœ¬, å®Œæ•´ç‰ˆæœ¬)
    """
    summarizer = ReportSummarizer()

    if report_type == "research":
        return summarizer.summarize_research_decision(content, stock_code, company_name)
    elif report_type == "risk":
        return summarizer.summarize_risk_decision(content, stock_code, company_name)
    else:
        return content, content
