#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æºç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†ä¸­å›½è‚¡ç¥¨æ•°æ®æºçš„é€‰æ‹©å’Œåˆ‡æ¢ï¼Œæ”¯æŒTushareã€AKShareã€BaoStockç­‰
"""

import os
import time
import warnings
from enum import Enum
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger

logger = get_logger("agents")
warnings.filterwarnings("ignore")

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import setup_dataflow_logging

logger = setup_dataflow_logging()

# å¯¼å…¥ç»Ÿä¸€æ•°æ®æºç¼–ç 
from tradingagents.constants import DataSourceCode

# å¯¼å…¥æ•°æ®æ ‡å‡†åŒ–å™¨
from tradingagents.dataflows.standardizers.stock_basic_standardizer import (
    standardize_stock_basic,
)


class ChinaDataSource(Enum):
    """
    ä¸­å›½è‚¡ç¥¨æ•°æ®æºæšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæšä¸¾ä¸ tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """

    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    TUSHARE = DataSourceCode.TUSHARE
    AKSHARE = DataSourceCode.AKSHARE
    BAOSTOCK = DataSourceCode.BAOSTOCK


class USDataSource(Enum):
    """
    ç¾è‚¡æ•°æ®æºæšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæšä¸¾ä¸ tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """

    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    YFINANCE = DataSourceCode.YFINANCE  # Yahoo Financeï¼ˆå…è´¹ï¼Œè‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼‰
    ALPHA_VANTAGE = DataSourceCode.ALPHA_VANTAGE  # Alpha Vantageï¼ˆåŸºæœ¬é¢å’Œæ–°é—»ï¼‰
    FINNHUB = DataSourceCode.FINNHUB  # Finnhubï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰


class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        self.default_source = self._get_default_source()
        self.available_sources = self._check_available_sources()
        self.current_source = self.default_source

        # åˆå§‹åŒ–ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = None
        self.cache_enabled = False
        try:
            from .cache import get_cache

            self.cache_manager = get_cache()
            self.cache_enabled = True
            logger.info(f"âœ… ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨å·²å¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        logger.info(f"ğŸ“Š æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(
            f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(
            f"   ç»Ÿä¸€ç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.cache_enabled else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled

        return use_app_cache_enabled()

    def _get_data_source_priority_order(
        self, symbol: Optional[str] = None
    ) -> List[ChinaDataSource]:
        """
        ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºé™çº§ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œç”¨äºè¯†åˆ«å¸‚åœºç±»å‹ï¼ˆAè‚¡/ç¾è‚¡/æ¸¯è‚¡ï¼‰

        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ•°æ®æºåˆ—è¡¨ï¼ˆä¸åŒ…å«MongoDBï¼Œå› ä¸ºMongoDBæ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼‰
        """
        # ğŸ”¥ è¯†åˆ«å¸‚åœºç±»å‹
        market_category = self._identify_market_category(symbol)

        try:
            # ğŸ”¥ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯ï¼‰
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()
            config_collection = db.system_configs

            # è·å–æœ€æ–°çš„æ¿€æ´»é…ç½®
            config_data = config_collection.find_one(
                {"is_active": True}, sort=[("version", -1)]
            )

            if config_data and config_data.get("data_source_configs"):
                data_source_configs = config_data.get("data_source_configs", [])

                # ğŸ”¥ è¿‡æ»¤å‡ºå¯ç”¨çš„æ•°æ®æºï¼Œå¹¶æŒ‰å¸‚åœºåˆ†ç±»è¿‡æ»¤
                enabled_sources = []
                for ds in data_source_configs:
                    if not ds.get("enabled", True):
                        continue

                    # æ£€æŸ¥æ•°æ®æºæ˜¯å¦å±äºå½“å‰å¸‚åœºåˆ†ç±»
                    market_categories = ds.get("market_categories", [])
                    if market_categories and market_category:
                        # å¦‚æœæ•°æ®æºé…ç½®äº†å¸‚åœºåˆ†ç±»ï¼Œåªé€‰æ‹©åŒ¹é…çš„æ•°æ®æº
                        if market_category not in market_categories:
                            continue

                    enabled_sources.append(ds)

                # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
                enabled_sources.sort(key=lambda x: x.get("priority", 0), reverse=True)

                # è½¬æ¢ä¸º ChinaDataSource æšä¸¾ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼–ç ï¼‰
                source_mapping = {
                    DataSourceCode.TUSHARE: ChinaDataSource.TUSHARE,
                    DataSourceCode.AKSHARE: ChinaDataSource.AKSHARE,
                    DataSourceCode.BAOSTOCK: ChinaDataSource.BAOSTOCK,
                }

                result = []
                for ds in enabled_sources:
                    ds_type = ds.get("type", "").lower()
                    if ds_type in source_mapping:
                        source = source_mapping[ds_type]
                        # æ’é™¤ MongoDBï¼ˆMongoDB æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸å‚ä¸é™çº§ï¼‰
                        if (
                            source != ChinaDataSource.MONGODB
                            and source in self.available_sources
                        ):
                            result.append(source)

                if result:
                    logger.info(
                        f"âœ… [æ•°æ®æºä¼˜å…ˆçº§] å¸‚åœº={market_category or 'å…¨éƒ¨'}, ä»æ•°æ®åº“è¯»å–: {[s.value for s in result]}"
                    )
                    return result
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] å¸‚åœº={market_category or 'å…¨éƒ¨'}, æ•°æ®åº“é…ç½®ä¸­æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº"
                    )
            else:
                logger.warning("âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
        except Exception as e:
            logger.warning(f"âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # ğŸ”¥ å›é€€åˆ°é»˜è®¤é¡ºåºï¼ˆå…¼å®¹æ€§ï¼‰
        # é»˜è®¤é¡ºåºï¼šAKShare > Tushare > BaoStock
        default_order = [
            ChinaDataSource.AKSHARE,
            ChinaDataSource.TUSHARE,
            ChinaDataSource.BAOSTOCK,
        ]
        # åªè¿”å›å¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _identify_market_category(self, symbol: Optional[str]) -> Optional[str]:
        """
        è¯†åˆ«è‚¡ç¥¨ä»£ç æ‰€å±çš„å¸‚åœºåˆ†ç±»

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            å¸‚åœºåˆ†ç±»IDï¼ˆa_shares/us_stocks/hk_stocksï¼‰ï¼Œå¦‚æœæ— æ³•è¯†åˆ«åˆ™è¿”å›None
        """
        if not symbol:
            return None

        try:
            from tradingagents.utils.stock_utils import StockMarket, StockUtils

            market = StockUtils.identify_stock_market(symbol)

            # æ˜ å°„åˆ°å¸‚åœºåˆ†ç±»ID
            market_mapping = {
                StockMarket.CHINA_A: "a_shares",
                StockMarket.US: "us_stocks",
                StockMarket.HONG_KONG: "hk_stocks",
            }

            category = market_mapping.get(market)
            if category:
                logger.debug(f"ğŸ” [å¸‚åœºè¯†åˆ«] {symbol} â†’ {category}")
            return category
        except Exception as e:
            logger.warning(f"âš ï¸ [å¸‚åœºè¯†åˆ«] è¯†åˆ«å¤±è´¥: {e}")
            return None

    def _get_default_source(self) -> ChinaDataSource:
        """è·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return ChinaDataSource.MONGODB

        # ä»ç¯å¢ƒå˜é‡è·å–ï¼Œé»˜è®¤ä½¿ç”¨AKShareä½œä¸ºç¬¬ä¸€ä¼˜å…ˆçº§æ•°æ®æº
        env_source = os.getenv(
            "DEFAULT_CHINA_DATA_SOURCE", DataSourceCode.AKSHARE
        ).lower()

        # æ˜ å°„åˆ°æšä¸¾ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼–ç ï¼‰
        source_mapping = {
            DataSourceCode.TUSHARE: ChinaDataSource.TUSHARE,
            DataSourceCode.AKSHARE: ChinaDataSource.AKSHARE,
            DataSourceCode.BAOSTOCK: ChinaDataSource.BAOSTOCK,
        }

        return source_mapping.get(env_source, ChinaDataSource.AKSHARE)

    # ==================== Tushareæ•°æ®æ¥å£ ====================

    def get_china_stock_data_tushare(
        self, symbol: str, start_date: str, end_date: str
    ) -> str:
        """
        ä½¿ç”¨Tushareè·å–ä¸­å›½Aè‚¡å†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        # ä¸´æ—¶åˆ‡æ¢åˆ°Tushareæ•°æ®æº
        original_source = self.current_source
        self.current_source = ChinaDataSource.TUSHARE

        try:
            result = self._get_tushare_data(symbol, start_date, end_date)
            return result
        finally:
            # æ¢å¤åŸå§‹æ•°æ®æº
            self.current_source = original_source

    def get_fundamentals_data(self, symbol: str) -> str:
        """
        è·å–åŸºæœ¬é¢æ•°æ®ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ ç”Ÿæˆåˆ†æ

        Tushare æ•°æ®æºä¼šè·å–å®Œæ•´çš„è´¢åŠ¡æ•°æ®ï¼š
        1. ä¼°å€¼æŒ‡æ ‡ (PE, PB, PS) - daily_basic
        2. è´¢åŠ¡æŒ‡æ ‡ (ROE, ROA ç­‰) - fina_indicator
        3. è´¢åŠ¡æŠ¥è¡¨ (åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨) - income/balancesheet/cashflow

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
        """
        logger.info(
            f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–åŸºæœ¬é¢æ•°æ®: {symbol}",
            extra={
                "symbol": symbol,
                "data_source": self.current_source.value,
                "event_type": "fundamentals_fetch_start",
            },
        )

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_fundamentals(symbol)
            elif self.current_source == ChinaDataSource.TUSHARE:
                # ğŸ”¥ ä½¿ç”¨ Tushare è·å–å®Œæ•´çš„åŸºæœ¬é¢æ•°æ®
                # 1. ä¼°å€¼æŒ‡æ ‡ (PE, PB, PS)
                result = self._get_tushare_fundamentals(symbol)

                # 2. é™„åŠ è´¢åŠ¡æŒ‡æ ‡ (ROE, ROA ç­‰)
                indicators = self._get_tushare_financial_indicators(symbol)
                if indicators and "âŒ" not in indicators:
                    result += indicators

                # 3. é™„åŠ è´¢åŠ¡æŠ¥è¡¨ (åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨)
                reports = self._get_tushare_financial_reports(symbol)
                if reports and "âŒ" not in reports:
                    result += reports
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_fundamentals(symbol)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒåŸºæœ¬é¢æ•°æ®ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ
                result = self._generate_fundamentals_analysis(symbol)

            # æ£€æŸ¥ç»“æœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0

            if result and "âŒ" not in result:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸè·å–åŸºæœ¬é¢æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "event_type": "fundamentals_fetch_success",
                    },
                )
                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] åŸºæœ¬é¢æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§: {symbol}",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "event_type": "fundamentals_fetch_fallback",
                    },
                )
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol} - {e}",
                extra={
                    "symbol": symbol,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "fundamentals_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_fundamentals(symbol)

    def get_china_stock_fundamentals_tushare(self, symbol: str) -> str:
        """
        ä½¿ç”¨Tushareè·å–ä¸­å›½è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
        """
        # é‡å®šå‘åˆ°ç»Ÿä¸€æ¥å£
        return self._get_tushare_fundamentals(symbol)

    def get_news_data(
        self, symbol: str = None, hours_back: int = 24, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        è·å–æ–°é—»æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™è·å–å¸‚åœºæ–°é—»
            hours_back: å›æº¯å°æ—¶æ•°
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            List[Dict]: æ–°é—»æ•°æ®åˆ—è¡¨
        """
        logger.info(
            f"ğŸ“° [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}, å›æº¯{hours_back}å°æ—¶",
            extra={
                "symbol": symbol,
                "hours_back": hours_back,
                "limit": limit,
                "data_source": self.current_source.value,
                "event_type": "news_fetch_start",
            },
        )

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.TUSHARE:
                result = self._get_tushare_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_news(symbol, hours_back, limit)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒæ–°é—»æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®æº {self.current_source.value} ä¸æ”¯æŒæ–°é—»æ•°æ®")
                result = []

            # æ£€æŸ¥ç»“æœ
            duration = time.time() - start_time
            result_count = len(result) if result else 0

            if result and result_count > 0:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸè·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'} ({result_count}æ¡, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "news_count": result_count,
                        "duration": duration,
                        "event_type": "news_fetch_success",
                    },
                )
                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] æœªè·å–åˆ°æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œå°è¯•é™çº§",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "event_type": "news_fetch_fallback",
                    },
                )
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–æ–°é—»æ•°æ®å¤±è´¥: {symbol or 'å¸‚åœºæ–°é—»'} - {e}",
                extra={
                    "symbol": symbol,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "news_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_news(symbol, hours_back, limit)

    def _check_available_sources(self) -> List[ChinaDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        æ£€æŸ¥é€»è¾‘ï¼š
        1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…ï¼ˆæŠ€æœ¯å¯ç”¨æ€§ï¼‰
        2. æ£€æŸ¥æ•°æ®åº“é…ç½®ä¸­æ˜¯å¦å¯ç”¨ï¼ˆä¸šåŠ¡å¯ç”¨æ€§ï¼‰

        Returns:
            å¯ç”¨ä¸”å·²å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨
        """
        available = []

        # ğŸ”¥ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼Œè·å–å¯ç”¨çŠ¶æ€
        enabled_sources_in_db = set()
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()
            config_collection = db.system_configs

            # è·å–æœ€æ–°çš„æ¿€æ´»é…ç½®
            config_data = config_collection.find_one(
                {"is_active": True}, sort=[("version", -1)]
            )

            if config_data and config_data.get("data_source_configs"):
                data_source_configs = config_data.get("data_source_configs", [])

                # æå–å·²å¯ç”¨çš„æ•°æ®æºç±»å‹
                for ds in data_source_configs:
                    if ds.get("enabled", True):
                        ds_type = ds.get("type", "").lower()
                        enabled_sources_in_db.add(ds_type)

                logger.info(
                    f"âœ… [æ•°æ®æºé…ç½®] ä»æ•°æ®åº“è¯»å–åˆ°å·²å¯ç”¨çš„æ•°æ®æº: {enabled_sources_in_db}"
                )
            else:
                logger.warning(
                    "âš ï¸ [æ•°æ®æºé…ç½®] æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº"
                )
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
                enabled_sources_in_db = {"mongodb", "tushare", "akshare", "baostock"}
        except Exception as e:
            logger.warning(
                f"âš ï¸ [æ•°æ®æºé…ç½®] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº"
            )
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
            enabled_sources_in_db = {"mongodb", "tushare", "akshare", "baostock"}

        # æ£€æŸ¥MongoDBï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if self.use_mongodb_cache and "mongodb" in enabled_sources_in_db:
            try:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                    get_mongodb_cache_adapter,
                )

                adapter = get_mongodb_cache_adapter()
                if adapter.use_app_cache and adapter.db is not None:
                    available.append(ChinaDataSource.MONGODB)
                    logger.info("âœ… MongoDBæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰")
                else:
                    logger.warning("âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: æ•°æ®åº“æœªè¿æ¥")
            except Exception as e:
                logger.warning(f"âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: {e}")
        elif self.use_mongodb_cache and "mongodb" not in enabled_sources_in_db:
            logger.info("â„¹ï¸ MongoDBæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥Tushare
        if "tushare" in enabled_sources_in_db:
            try:
                import tushare as ts

                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                token = datasource_configs.get("tushare", {}).get(
                    "api_key"
                ) or os.getenv("TUSHARE_TOKEN")
                if token:
                    available.append(ChinaDataSource.TUSHARE)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("tushare", {}).get("api_key")
                        else "ç¯å¢ƒå˜é‡"
                    )
                    logger.info(f"âœ… Tushareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning(
                        "âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except ImportError:
                logger.warning("âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ Tushareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥AKShare
        if "akshare" in enabled_sources_in_db:
            try:
                import akshare as ak

                available.append(ChinaDataSource.AKSHARE)
                logger.info("âœ… AKShareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ AKShareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ AKShareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥BaoStock
        if "baostock" in enabled_sources_in_db:
            try:
                import baostock as bs

                available.append(ChinaDataSource.BAOSTOCK)
                logger.info(f"âœ… BaoStockæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning(f"âš ï¸ BaoStockæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ BaoStockæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # TDX (é€šè¾¾ä¿¡) å·²ç§»é™¤
        # ä¸å†æ£€æŸ¥å’Œæ”¯æŒ TDX æ•°æ®æº

        return available

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä» system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get("data_source_configs", [])

            # æ„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get("name", "").lower()
                result[name] = {
                    "api_key": ds_config.get("api_key", ""),
                    "api_secret": ds_config.get("api_secret", ""),
                    "config_params": ds_config.get("config_params", {}),
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> ChinaDataSource:
        """è·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: ChinaDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False

    def get_data_adapter(self):
        """è·å–å½“å‰æ•°æ®æºçš„é€‚é…å™¨"""
        if self.current_source == ChinaDataSource.MONGODB:
            return self._get_mongodb_adapter()
        elif self.current_source == ChinaDataSource.TUSHARE:
            return self._get_tushare_adapter()
        elif self.current_source == ChinaDataSource.AKSHARE:
            return self._get_akshare_adapter()
        elif self.current_source == ChinaDataSource.BAOSTOCK:
            return self._get_baostock_adapter()
        # TDX å·²ç§»é™¤
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source}")

    def _get_mongodb_adapter(self):
        """è·å–MongoDBé€‚é…å™¨"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            return get_mongodb_cache_adapter()
        except ImportError as e:
            logger.error(f"âŒ MongoDBé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_tushare_adapter(self):
        """è·å–Tushareæä¾›å™¨ï¼ˆåŸadapterå·²åºŸå¼ƒï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨providerï¼‰"""
        try:
            from .providers.china.tushare import get_tushare_provider

            return get_tushare_provider()
        except ImportError as e:
            logger.error(f"âŒ Tushareæä¾›å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_akshare_adapter(self):
        """è·å–AKShareé€‚é…å™¨"""
        try:
            from .providers.china.akshare import get_akshare_provider

            return get_akshare_provider()
        except ImportError as e:
            logger.error(f"âŒ AKShareé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_baostock_adapter(self):
        """è·å–BaoStocké€‚é…å™¨"""
        try:
            from .providers.china.baostock import get_baostock_provider

            return get_baostock_provider()
        except ImportError as e:
            logger.error(f"âŒ BaoStocké€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    # TDX é€‚é…å™¨å·²ç§»é™¤
    # def _get_tdx_adapter(self):
    #     """è·å–TDXé€‚é…å™¨ (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return None

    def _get_cached_data(
        self,
        symbol: str,
        start_date: str = None,
        end_date: str = None,
        max_age_hours: int = 24,
    ) -> Optional[pd.DataFrame]:
        """
        ä»ç¼“å­˜è·å–æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_age_hours: æœ€å¤§ç¼“å­˜æ—¶é—´ï¼ˆå°æ—¶ï¼‰

        Returns:
            DataFrame: ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        if not self.cache_enabled or not self.cache_manager:
            return None

        try:
            cache_key = self.cache_manager.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                max_age_hours=max_age_hours,
            )

            if cache_key:
                cached_data = self.cache_manager.load_stock_data(cache_key)
                if (
                    cached_data is not None
                    and hasattr(cached_data, "empty")
                    and not cached_data.empty
                ):
                    logger.debug(f"ğŸ“¦ ä»ç¼“å­˜è·å–{symbol}æ•°æ®: {len(cached_data)}æ¡")
                    return cached_data
        except Exception as e:
            logger.warning(f"âš ï¸ ä»ç¼“å­˜è¯»å–æ•°æ®å¤±è´¥: {e}")

        return None

    def _save_to_cache(
        self,
        symbol: str,
        data: pd.DataFrame,
        start_date: str = None,
        end_date: str = None,
    ):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        if not self.cache_enabled or not self.cache_manager:
            return

        try:
            if data is not None and hasattr(data, "empty") and not data.empty:
                self.cache_manager.save_stock_data(symbol, data, start_date, end_date)
                logger.debug(f"ğŸ’¾ ä¿å­˜{symbol}æ•°æ®åˆ°ç¼“å­˜: {len(data)}æ¡")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜æ•°æ®åˆ°ç¼“å­˜å¤±è´¥: {e}")

    def _get_volume_safely(self, data: pd.DataFrame) -> float:
        """
        å®‰å…¨è·å–æˆäº¤é‡æ•°æ®

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame

        Returns:
            float: æˆäº¤é‡ï¼ˆè‚¡ï¼‰ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›0

        æ•°æ®æµç¨‹è¯´æ˜ï¼š
        1. Tushare daily æ¥å£è¿”å› vol å­—æ®µï¼Œå•ä½æ˜¯"æ‰‹"ï¼ˆ1æ‰‹=100è‚¡ï¼‰
        2. TushareAdapter.standardize_quotes å°† vol * 100 è½¬æ¢ä¸º"è‚¡"
        3. MongoDB stock_daily_quotes ä¸­å­˜å‚¨çš„ volume å·²ç»æ˜¯"è‚¡"
        4. å› æ­¤è¿™é‡Œä¸éœ€è¦å†è¿›è¡Œå•ä½è½¬æ¢ï¼Œç›´æ¥è¿”å›å³å¯

        ä¿®å¤å†å²é—®é¢˜ï¼š
        ä¹‹å‰çš„ä»£ç é”™è¯¯åœ°å‡è®¾MongoDBä¸­çš„volumeå•ä½æ˜¯"ä¸‡"ï¼Œå¯¼è‡´æˆäº¤é‡è¢«æ”¾å¤§100å€
        å®é™…ä¸ŠTushareAdapterå·²ç»åœ¨è·å–æ•°æ®æ—¶å®Œæˆäº†"æ‰‹â†’è‚¡"çš„è½¬æ¢
        """
        try:
            if "volume" in data.columns:
                volume_raw = data["volume"].iloc[-1]
                # ğŸ”§ FIX: MongoDBä¸­çš„volumeå·²ç»æ˜¯"è‚¡"ï¼Œä¸éœ€è¦å†ä¹˜ä»¥100
                # TushareAdapterå·²ç»åœ¨standardize_quotesä¸­å®Œæˆäº†"æ‰‹â†’è‚¡"çš„è½¬æ¢
                return float(volume_raw) if volume_raw else 0
            elif "vol" in data.columns:
                volume_raw = data["vol"].iloc[-1]
                # å¦‚æœæ•°æ®åˆ—åæ˜¯volè€Œä¸æ˜¯volumeï¼Œå¯èƒ½æ˜¯åŸå§‹æ•°æ®ï¼Œéœ€è¦è½¬æ¢
                # å‡è®¾volå•ä½æ˜¯"æ‰‹"ï¼Œè½¬æ¢ä¸º"è‚¡"
                return float(volume_raw) * 100 if volume_raw else 0
            else:
                return 0
        except Exception:
            return 0

    def _format_stock_data_response(
        self,
        data: pd.DataFrame,
        symbol: str,
        stock_name: str,
        start_date: str,
        end_date: str,
        realtime_price: float = None,  # ğŸ†• æ–°å¢ï¼šå®æ—¶ä»·æ ¼
    ) -> str:
        """
        æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®å“åº”ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame
            symbol: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„æ•°æ®æŠ¥å‘Šï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰
        """
        try:
            original_data_count = len(data)
            logger.info(
                f"ğŸ“Š [æŠ€æœ¯æŒ‡æ ‡] å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ŒåŸå§‹æ•°æ®: {original_data_count}æ¡"
            )

            # ğŸ”§ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆä½¿ç”¨å®Œæ•´æ•°æ®ï¼‰
            # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
            # ğŸ”§ FIX: Handle both 'date' and 'trade_date' columns
            date_col = None
            if "date" in data.columns:
                date_col = "date"
            elif "trade_date" in data.columns:
                date_col = "trade_date"
                # Create 'date' column from 'trade_date' for consistency
                # MongoDB stores trade_date as YYYY-MM-DD string format
                if not pd.api.types.is_datetime64_any_dtype(data["trade_date"]):
                    data["date"] = pd.to_datetime(
                        data["trade_date"], format="%Y-%m-%d", errors="coerce"
                    )
                    date_col = "date"

            if date_col:
                if not pd.api.types.is_datetime64_any_dtype(data[date_col]):
                    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
                data = data.sort_values(date_col)

            # ğŸ”¥ ç»Ÿä¸€ä»·æ ¼ç¼“å­˜å¤„ç†ï¼šåœ¨è®¡ç®—æŒ‡æ ‡å‰ä¿®æ­£æ•°æ®
            try:
                from tradingagents.utils.price_cache import get_price_cache

                cache = get_price_cache()
                cached_price = cache.get_price(symbol)

                if cached_price is not None and not data.empty:
                    # è·å–æœ€åä¸€è¡Œæ•°æ®çš„åŸå§‹ä»·æ ¼
                    last_idx = data.index[-1]
                    original_price = data.at[last_idx, "close"]

                    # åªæœ‰å½“å·®å¼‚å­˜åœ¨æ—¶æ‰ä¿®æ­£
                    if abs(original_price - cached_price) > 0.0001:
                        logger.info(
                            f"ğŸ”„ [ä»·æ ¼ç»Ÿä¸€] ä¿®æ­£DataFrameæ•°æ®: {symbol} Â¥{original_price:.2f} -> Â¥{cached_price:.2f}"
                        )
                        data.at[last_idx, "close"] = cached_price
                        # åŒæ—¶ä¿®æ­£ high/low å¦‚æœå®ƒä»¬ä¸ new close å†²çª
                        if cached_price > data.at[last_idx, "high"]:
                            data.at[last_idx, "high"] = cached_price
                        if cached_price < data.at[last_idx, "low"]:
                            data.at[last_idx, "low"] = cached_price
            except Exception as e:
                logger.warning(f"âš ï¸ [ä»·æ ¼ç»Ÿä¸€] DataFrameä¿®æ­£å¤±è´¥: {e}")

            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            data["ma5"] = data["close"].rolling(window=5, min_periods=1).mean()
            data["ma10"] = data["close"].rolling(window=10, min_periods=1).mean()
            data["ma20"] = data["close"].rolling(window=20, min_periods=1).mean()
            data["ma60"] = data["close"].rolling(window=60, min_periods=1).mean()

            # è®¡ç®—RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰- åŒèŠ±é¡ºé£æ ¼ï¼šä½¿ç”¨ä¸­å›½å¼SMAï¼ˆEMA with adjust=Trueï¼‰
            # å‚è€ƒï¼šhttps://blog.csdn.net/u011218867/article/details/117427927
            # åŒèŠ±é¡º/é€šè¾¾ä¿¡çš„RSIä½¿ç”¨SMAå‡½æ•°ï¼Œç­‰ä»·äºpandasçš„ewm(com=N-1, adjust=True)
            delta = data["close"].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)

            # RSI6 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain6 = gain.ewm(com=5, adjust=True).mean()  # com = N - 1
            avg_loss6 = loss.ewm(com=5, adjust=True).mean()
            rs6 = avg_gain6 / avg_loss6.replace(0, np.nan)
            data["rsi6"] = 100 - (100 / (1 + rs6))

            # RSI12 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain12 = gain.ewm(com=11, adjust=True).mean()
            avg_loss12 = loss.ewm(com=11, adjust=True).mean()
            rs12 = avg_gain12 / avg_loss12.replace(0, np.nan)
            data["rsi12"] = 100 - (100 / (1 + rs12))

            # RSI24 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain24 = gain.ewm(com=23, adjust=True).mean()
            avg_loss24 = loss.ewm(com=23, adjust=True).mean()
            rs24 = avg_gain24 / avg_loss24.replace(0, np.nan)
            data["rsi24"] = 100 - (100 / (1 + rs24))

            # ä¿ç•™RSI14ä½œä¸ºå›½é™…æ ‡å‡†å‚è€ƒï¼ˆä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡ï¼‰
            gain14 = gain.rolling(window=14, min_periods=1).mean()
            loss14 = loss.rolling(window=14, min_periods=1).mean()
            rs14 = gain14 / loss14.replace(0, np.nan)
            data["rsi14"] = 100 - (100 / (1 + rs14))

            # è®¡ç®—MACD
            ema12 = data["close"].ewm(span=12, adjust=False).mean()
            ema26 = data["close"].ewm(span=26, adjust=False).mean()
            data["macd_dif"] = ema12 - ema26
            data["macd_dea"] = data["macd_dif"].ewm(span=9, adjust=False).mean()
            data["macd"] = (data["macd_dif"] - data["macd_dea"]) * 2

            # è®¡ç®—å¸ƒæ—å¸¦
            data["boll_mid"] = data["close"].rolling(window=20, min_periods=1).mean()
            std = data["close"].rolling(window=20, min_periods=1).std()
            data["boll_upper"] = data["boll_mid"] + 2 * std
            data["boll_lower"] = data["boll_mid"] - 2 * std

            logger.info(f"âœ… [æŠ€æœ¯æŒ‡æ ‡] æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")

            # ğŸ”§ åªä¿ç•™æœ€å3-5å¤©çš„æ•°æ®ç”¨äºå±•ç¤ºï¼ˆå‡å°‘tokenæ¶ˆè€—ï¼‰
            display_rows = min(5, len(data))
            display_data = data.tail(display_rows)
            latest_data = data.iloc[-1]

            # ğŸ” [è°ƒè¯•æ—¥å¿—] æ‰“å°æœ€è¿‘5å¤©çš„åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
            logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥æ•°æ® =====")
            for i, (idx, row) in enumerate(display_data.iterrows(), 1):
                logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ç¬¬{i}å¤© ({row.get('date', 'N/A')}):")
                logger.info(
                    f"   ä»·æ ¼: å¼€={row.get('open', 0):.2f}, é«˜={row.get('high', 0):.2f}, ä½={row.get('low', 0):.2f}, æ”¶={row.get('close', 0):.2f}"
                )
                logger.info(
                    f"   MA: MA5={row.get('ma5', 0):.2f}, MA10={row.get('ma10', 0):.2f}, MA20={row.get('ma20', 0):.2f}, MA60={row.get('ma60', 0):.2f}"
                )
                logger.info(
                    f"   MACD: DIF={row.get('macd_dif', 0):.4f}, DEA={row.get('macd_dea', 0):.4f}, MACD={row.get('macd', 0):.4f}"
                )
                logger.info(
                    f"   RSI: RSI6={row.get('rsi6', 0):.2f}, RSI12={row.get('rsi12', 0):.2f}, RSI24={row.get('rsi24', 0):.2f} (åŒèŠ±é¡ºé£æ ¼)"
                )
                logger.info(f"   RSI14: {row.get('rsi14', 0):.2f} (å›½é™…æ ‡å‡†)")
                logger.info(
                    f"   BOLL: ä¸Š={row.get('boll_upper', 0):.2f}, ä¸­={row.get('boll_mid', 0):.2f}, ä¸‹={row.get('boll_lower', 0):.2f}"
                )

            logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æ•°æ®è¯¦æƒ…ç»“æŸ =====")

            # è®¡ç®—æœ€æ–°ä»·æ ¼å’Œæ¶¨è·Œå¹…
            # ğŸ†• ä¼˜å…ˆä½¿ç”¨å®æ—¶ä»·æ ¼
            if realtime_price is not None and realtime_price > 0:
                latest_price = realtime_price
                price_source = "å®æ—¶"
                logger.info(f"âœ… [ä»·æ ¼ç­–ç•¥] ä½¿ç”¨å®æ—¶ä»·æ ¼: Â¥{latest_price:.2f}")
            else:
                latest_price = latest_data.get("close", 0)
                price_source = "å†å²"
                logger.info(f"â„¹ï¸ [ä»·æ ¼ç­–ç•¥] ä½¿ç”¨å†å²ä»·æ ¼: Â¥{latest_price:.2f}")

            # ğŸ”¥ ç¼“å­˜æ›´æ–°ï¼šç¡®ä¿å½“å‰ä»·æ ¼è¢«ç¼“å­˜ï¼ˆä½œä¸ºçœŸç†æ¥æºï¼‰
            try:
                from tradingagents.utils.price_cache import get_price_cache

                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼ˆæˆ–è€…æˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªè·å–æ•°æ®çš„ï¼‰ï¼Œæ›´æ–°ç¼“å­˜
                cache = get_price_cache()
                if cache.get_price(symbol) is None:
                    cache.update(symbol, latest_price)
            except Exception as e:
                logger.warning(f"âš ï¸ [ä»·æ ¼ç»Ÿä¸€] ç¼“å­˜æ›´æ–°å¤±è´¥: {e}")

            prev_close = (
                data.iloc[-2].get("close", latest_price)
                if len(data) > 1
                else latest_price
            )

            change = latest_price - prev_close
            change_pct = (change / prev_close * 100) if prev_close != 0 else 0

            # è·å–æœ€æ–°æ•°æ®çš„å®é™…æ—¥æœŸ
            latest_data_date = latest_data.get("date", "N/A")
            if isinstance(latest_data_date, pd.Timestamp):
                latest_data_date = latest_data_date.strftime("%Y-%m-%d")
            elif isinstance(latest_data_date, str):
                # å¦‚æœæ˜¯YYYYMMDDæ ¼å¼ï¼Œè½¬æ¢ä¸ºYYYY-MM-DD
                if len(latest_data_date) == 8 and latest_data_date.isdigit():
                    latest_data_date = f"{latest_data_date[:4]}-{latest_data_date[4:6]}-{latest_data_date[6:8]}"
                # å¦‚æœå·²ç»æ˜¯YYYY-MM-DDæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                elif "-" in latest_data_date:
                    pass  # Already in correct format

            logger.info(
                f"ğŸ“… [æœ€æ–°æ•°æ®æ—¥æœŸ] å®é™…æ•°æ®æ—¥æœŸ: {latest_data_date}, è¯·æ±‚ç»“æŸæ—¥æœŸ: {end_date}"
            )

            # âš ï¸ æ™ºèƒ½æ£€æŸ¥æ•°æ®æ—¥æœŸæ˜¯å¦ä¸ºæœ€æ–°
            from datetime import datetime

            # åˆ¤æ–­ end_date æ˜¯å¦æ˜¯éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰
            def _is_weekend(date_str: str) -> bool:
                """æ£€æŸ¥æ—¥æœŸæ˜¯å¦æ˜¯å‘¨æœ«"""
                try:
                    date_obj = datetime.strptime(date_str, "%Y-%m-%d")
                    return date_obj.weekday() >= 5  # 5=å‘¨å…­, 6=å‘¨æ—¥
                except:
                    return False

            is_end_date_weekend = _is_weekend(end_date)

            # åˆå§‹åŒ–å˜é‡
            result = ""
            date_warning = ""

            if latest_data_date != "N/A" and latest_data_date != end_date:
                if is_end_date_weekend:
                    # end_date æ˜¯å‘¨æœ«ï¼ˆå‘¨å…­/å‘¨æ—¥ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸åº”è¯¥è­¦å‘Š
                    logger.info(
                        f"ğŸ“… [æ•°æ®æ—¥æœŸæ£€æŸ¥] end_date={end_date} æ˜¯éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰ï¼Œ"
                        f"ä½¿ç”¨æœ€æ–°æ•°æ®æ—¥æœŸ {latest_data_date}ï¼Œè¿™æ˜¯æ­£å¸¸è¡Œä¸º"
                    )
                    # æ›´æ–° end_date æ˜¾ç¤ºä¸ºå®é™…ä½¿ç”¨çš„äº¤æ˜“æ—¥
                    result = f"ğŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†ææ•°æ®\n"
                    result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {latest_data_date} (å®é™…ä½¿ç”¨äº¤æ˜“æ—¥)\n"
                    result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"
                else:
                    # end_date æ˜¯å·¥ä½œæ—¥ä½†æ•°æ®ä¸æ–°é²œï¼Œå¯èƒ½æ˜¯å»¶è¿Ÿ
                    logger.warning(
                        f"âš ï¸ [æ•°æ®å»¶è¿Ÿè­¦å‘Š] æœ€æ–°æ•°æ®æ—¥æœŸ({latest_data_date})ä¸è¯·æ±‚æ—¥æœŸ({end_date})ä¸ä¸€è‡´ï¼Œå¯èƒ½æ˜¯æ•°æ®æœªæ›´æ–°"
                    )
                    date_warning = f"âš ï¸ æ³¨æ„ï¼šæœ€æ–°æ•°æ®æ—¥æœŸä¸º {latest_data_date}ï¼Œéå½“å‰åˆ†ææ—¥æœŸ {end_date}\n"
                    result = f"ğŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†ææ•°æ®\n"
                    result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}\n"
                    result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"
            else:
                result = f"ğŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†ææ•°æ®\n"
                result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}\n"
                result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"

            result += (
                f"æ•°æ®æ¡æ•°: {original_data_count}æ¡ (å±•ç¤ºæœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥)\n"
            )
            if date_warning:
                result += f"\n{date_warning}"
            result += f"\n"

            result += (
                f"ğŸ’° æœ€æ–°ä»·æ ¼: Â¥{latest_price:.2f} (æ•°æ®æ—¥æœŸ: {latest_data_date})\n"
            )
            # ğŸ”§ FIX: æ˜ç¡®æ ‡æ³¨å•ä½ï¼Œé¿å…æ¶¨è·Œé¢ï¼ˆå…ƒï¼‰å’Œæ¶¨è·Œå¹…ï¼ˆ%ï¼‰æ··æ·†
            result += f"ğŸ“ˆ æ¶¨è·Œé¢: {change:+.2f}å…ƒ (æ¶¨è·Œå¹…: {change_pct:+.2f}%)\n\n"

            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            result += f"ğŸ“Š ç§»åŠ¨å¹³å‡çº¿ (MA):\n"
            result += f"   MA5:  Â¥{latest_data['ma5']:.2f}"
            if latest_price > latest_data["ma5"]:
                result += " (ä»·æ ¼åœ¨MA5ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA5ä¸‹æ–¹ â†“)\n"

            result += f"   MA10: Â¥{latest_data['ma10']:.2f}"
            if latest_price > latest_data["ma10"]:
                result += " (ä»·æ ¼åœ¨MA10ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA10ä¸‹æ–¹ â†“)\n"

            result += f"   MA20: Â¥{latest_data['ma20']:.2f}"
            if latest_price > latest_data["ma20"]:
                result += " (ä»·æ ¼åœ¨MA20ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA20ä¸‹æ–¹ â†“)\n"

            result += f"   MA60: Â¥{latest_data['ma60']:.2f}"
            if latest_price > latest_data["ma60"]:
                result += " (ä»·æ ¼åœ¨MA60ä¸Šæ–¹ â†‘)\n\n"
            else:
                result += " (ä»·æ ¼åœ¨MA60ä¸‹æ–¹ â†“)\n\n"

            # MACDæŒ‡æ ‡
            result += f"ğŸ“ˆ MACDæŒ‡æ ‡:\n"
            result += f"   DIF:  {latest_data['macd_dif']:.3f}\n"
            result += f"   DEA:  {latest_data['macd_dea']:.3f}\n"
            result += f"   MACD: {latest_data['macd']:.3f}"
            if latest_data["macd"] > 0:
                result += " (å¤šå¤´ â†‘)\n"
            else:
                result += " (ç©ºå¤´ â†“)\n"

            # åˆ¤æ–­é‡‘å‰/æ­»å‰
            if len(data) > 1:
                prev_dif = data.iloc[-2]["macd_dif"]
                prev_dea = data.iloc[-2]["macd_dea"]
                curr_dif = latest_data["macd_dif"]
                curr_dea = latest_data["macd_dea"]

                if prev_dif <= prev_dea and curr_dif > curr_dea:
                    result += "   âš ï¸ MACDé‡‘å‰ä¿¡å·ï¼ˆDIFä¸Šç©¿DEAï¼‰\n\n"
                elif prev_dif >= prev_dea and curr_dif < curr_dea:
                    result += "   âš ï¸ MACDæ­»å‰ä¿¡å·ï¼ˆDIFä¸‹ç©¿DEAï¼‰\n\n"
                else:
                    result += "\n"
            else:
                result += "\n"

            # RSIæŒ‡æ ‡ - åŒèŠ±é¡ºé£æ ¼ (6, 12, 24)
            rsi6 = latest_data["rsi6"]
            rsi12 = latest_data["rsi12"]
            rsi24 = latest_data["rsi24"]
            result += f"ğŸ“‰ RSIæŒ‡æ ‡ (åŒèŠ±é¡ºé£æ ¼):\n"
            result += f"   RSI6:  {rsi6:.2f}"
            if rsi6 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi6 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI12: {rsi12:.2f}"
            if rsi12 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi12 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI24: {rsi24:.2f}"
            if rsi24 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi24 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            # åˆ¤æ–­RSIè¶‹åŠ¿
            if rsi6 > rsi12 > rsi24:
                result += "   è¶‹åŠ¿: å¤šå¤´æ’åˆ— â†‘\n\n"
            elif rsi6 < rsi12 < rsi24:
                result += "   è¶‹åŠ¿: ç©ºå¤´æ’åˆ— â†“\n\n"
            else:
                result += "   è¶‹åŠ¿: éœ‡è¡æ•´ç† â†”\n\n"

            # å¸ƒæ—å¸¦
            result += f"ğŸ“Š å¸ƒæ—å¸¦ (BOLL):\n"
            result += f"   ä¸Šè½¨: Â¥{latest_data['boll_upper']:.2f}\n"
            result += f"   ä¸­è½¨: Â¥{latest_data['boll_mid']:.2f}\n"
            result += f"   ä¸‹è½¨: Â¥{latest_data['boll_lower']:.2f}\n"

            # åˆ¤æ–­ä»·æ ¼åœ¨å¸ƒæ—å¸¦çš„ä½ç½®
            boll_position = (
                (latest_price - latest_data["boll_lower"])
                / (latest_data["boll_upper"] - latest_data["boll_lower"])
                * 100
            )
            result += f"   ä»·æ ¼ä½ç½®: {boll_position:.1f}%"
            if boll_position >= 100:
                result += " (å·²çªç ´ä¸Šè½¨ï¼Œå¤šå¤´ç¡®è®¤ä¿¡å·ï¼ğŸ”´)"
            elif boll_position >= 80:
                result += " (æ¥è¿‘ä¸Šè½¨ï¼Œå¯èƒ½è¶…ä¹° âš ï¸)"
            else:
                result += " (ä¸­æ€§åŒºåŸŸ)"

            # ä»·æ ¼ç»Ÿè®¡
            result += f"ğŸ“Š ä»·æ ¼ç»Ÿè®¡ (æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥):\n"
            result += f"   æœ€é«˜ä»·: Â¥{display_data['high'].max():.2f}\n"
            result += f"   æœ€ä½ä»·: Â¥{display_data['low'].min():.2f}\n"
            result += f"   å¹³å‡ä»·: Â¥{display_data['close'].mean():.2f}\n"

            # é˜²å¾¡æ€§è·å–æˆäº¤é‡æ•°æ®
            volume_value = self._get_volume_safely(display_data)
            result += f"   å¹³å‡æˆäº¤é‡: {volume_value:,.0f}è‚¡\n"

            return result

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–æ•°æ®å“åº”å¤±è´¥: {e}", exc_info=True)
            return f"âŒ æ ¼å¼åŒ–{symbol}æ•°æ®å¤±è´¥: {e}"

    def get_stock_dataframe(
        self,
        symbol: str,
        start_date: str = None,
        end_date: str = None,
        period: str = "daily",
    ) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨æ•°æ®çš„ DataFrame æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily

        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ® DataFrameï¼Œåˆ—æ ‡å‡†ï¼šopen, high, low, close, vol, amount, date
        """
        logger.info(
            f"ğŸ“Š [DataFrameæ¥å£] è·å–è‚¡ç¥¨æ•°æ®: {symbol} ({start_date} åˆ° {end_date})"
        )

        try:
            # å°è¯•å½“å‰æ•°æ®æº
            df = None
            if self.current_source == ChinaDataSource.MONGODB:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                    get_mongodb_cache_adapter,
                )

                adapter = get_mongodb_cache_adapter()
                df = adapter.get_historical_data(
                    symbol, start_date, end_date, period=period
                )
            elif self.current_source == ChinaDataSource.TUSHARE:
                from .providers.china.tushare import get_tushare_provider

                provider = get_tushare_provider()
                df = provider.get_daily_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.AKSHARE:
                from .providers.china.akshare import get_akshare_provider

                provider = get_akshare_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                from .providers.china.baostock import get_baostock_provider

                provider = get_baostock_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)

            if df is not None and not df.empty:
                logger.info(
                    f"âœ… [DataFrameæ¥å£] ä» {self.current_source.value} è·å–æˆåŠŸ: {len(df)}æ¡"
                )
                return self._standardize_dataframe(df)

            # é™çº§åˆ°å…¶ä»–æ•°æ®æº
            logger.warning(
                f"âš ï¸ [DataFrameæ¥å£] {self.current_source.value} å¤±è´¥ï¼Œå°è¯•é™çº§"
            )
            for source in self.available_sources:
                if source == self.current_source:
                    continue
                try:
                    if source == ChinaDataSource.MONGODB:
                        from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                            get_mongodb_cache_adapter,
                        )

                        adapter = get_mongodb_cache_adapter()
                        df = adapter.get_historical_data(
                            symbol, start_date, end_date, period=period
                        )
                    elif source == ChinaDataSource.TUSHARE:
                        from .providers.china.tushare import get_tushare_provider

                        provider = get_tushare_provider()
                        df = provider.get_daily_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.AKSHARE:
                        from .providers.china.akshare import get_akshare_provider

                        provider = get_akshare_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.BAOSTOCK:
                        from .providers.china.baostock import get_baostock_provider

                        provider = get_baostock_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)

                    if df is not None and not df.empty:
                        logger.info(
                            f"âœ… [DataFrameæ¥å£] é™çº§åˆ° {source.value} æˆåŠŸ: {len(df)}æ¡"
                        )
                        return self._standardize_dataframe(df)
                except Exception as e:
                    logger.warning(f"âš ï¸ [DataFrameæ¥å£] {source.value} å¤±è´¥: {e}")
                    continue

            logger.error(f"âŒ [DataFrameæ¥å£] æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥: {symbol}")
            return pd.DataFrame()

        except Exception as e:
            logger.error(f"âŒ [DataFrameæ¥å£] è·å–å¤±è´¥: {e}", exc_info=True)
            return pd.DataFrame()

    def _standardize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ– DataFrame åˆ—åå’Œæ ¼å¼

        Args:
            df: åŸå§‹ DataFrame

        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–åçš„ DataFrame
        """
        if df is None or df.empty:
            return pd.DataFrame()

        out = df.copy()

        # åˆ—åæ˜ å°„
        colmap = {
            # English
            "Open": "open",
            "High": "high",
            "Low": "low",
            "Close": "close",
            "Volume": "vol",
            "Amount": "amount",
            "symbol": "code",
            "Symbol": "code",
            # Already lower
            "open": "open",
            "high": "high",
            "low": "low",
            "close": "close",
            "vol": "vol",
            "volume": "vol",
            "amount": "amount",
            "code": "code",
            "date": "date",
            "trade_date": "date",
            # Chinese (AKShare common)
            "æ—¥æœŸ": "date",
            "å¼€ç›˜": "open",
            "æœ€é«˜": "high",
            "æœ€ä½": "low",
            "æ”¶ç›˜": "close",
            "æˆäº¤é‡": "vol",
            "æˆäº¤é¢": "amount",
            "æ¶¨è·Œå¹…": "pct_change",
            "æ¶¨è·Œé¢": "change",
        }
        out = out.rename(columns={c: colmap.get(c, c) for c in out.columns})

        # ç¡®ä¿æ—¥æœŸæ’åº
        if "date" in out.columns:
            try:
                # ç¡®ä¿æ—¥æœŸæ˜¯datetimeç±»å‹ï¼Œä»¥ä¾¿æ­£ç¡®æ’åº
                if not pd.api.types.is_datetime64_any_dtype(out["date"]):
                    out["date"] = pd.to_datetime(out["date"])
                out = out.sort_values("date")
            except Exception:
                pass

        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        if "pct_change" not in out.columns and "close" in out.columns:
            out["pct_change"] = out["close"].pct_change() * 100.0

        return out

    def get_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """
        è·å–å®æ—¶è¡Œæƒ…æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            Dict: å®æ—¶è¡Œæƒ…æ•°æ®ï¼ŒåŒ…å«price, change, change_pct, volumeç­‰
        """
        logger.info(f"ğŸ“Š [å®æ—¶è¡Œæƒ…] è·å–å®æ—¶è¡Œæƒ…: {symbol}")

        try:
            # ä¼˜å…ˆä½¿ç”¨MongoDBç¼“å­˜çš„å®æ—¶è¡Œæƒ…
            if self.use_mongodb_cache:
                try:
                    from tradingagents.dataflows.cache.app_adapter import (
                        get_market_quote_dataframe,
                    )

                    df = get_market_quote_dataframe(symbol)
                    if df is not None and not df.empty:
                        row = df.iloc[-1]
                        quote = {
                            "symbol": symbol,
                            "price": row.get("close"),
                            "open": row.get("open"),
                            "high": row.get("high"),
                            "low": row.get("low"),
                            "volume": row.get("volume"),
                            "amount": row.get("amount"),
                            "change": row.get("change"),
                            "change_pct": row.get("pct_chg"),
                            "date": row.get("date"),
                            "time": row.get("time"),
                            "source": "mongodb_realtime",
                            "is_realtime": True,
                        }

                        # ğŸ”¥ ç»Ÿä¸€ä»·æ ¼ç¼“å­˜æ›´æ–°
                        try:
                            from tradingagents.utils.price_cache import get_price_cache

                            get_price_cache().update(symbol, quote["price"])
                        except Exception as e:
                            logger.warning(f"âš ï¸ [å®æ—¶è¡Œæƒ…] ç¼“å­˜æ›´æ–°å¤±è´¥: {e}")

                        logger.info(
                            f"âœ… [å®æ—¶è¡Œæƒ…-MongoDB] {symbol} ä»·æ ¼={quote['price']:.2f}"
                        )
                        return quote
                except Exception as e:
                    logger.debug(f"MongoDBå®æ—¶è¡Œæƒ…è·å–å¤±è´¥: {e}")

            # ä½¿ç”¨å½“å‰æ•°æ®æºçš„å®æ—¶è¡Œæƒ…æ¥å£
            quote = None
            if self.current_source == ChinaDataSource.TUSHARE:
                quote = self._get_tushare_realtime_quote(symbol)
            elif self.current_source == ChinaDataSource.AKSHARE:
                quote = self._get_akshare_realtime_quote(symbol)
            else:
                logger.warning(f"âš ï¸ {self.current_source.value}ä¸æ”¯æŒå®æ—¶è¡Œæƒ…")
                return None

            if quote:
                # ğŸ”¥ ç»Ÿä¸€ä»·æ ¼ç¼“å­˜æ›´æ–°
                try:
                    from tradingagents.utils.price_cache import get_price_cache

                    get_price_cache().update(symbol, quote["price"])
                except Exception as e:
                    logger.warning(f"âš ï¸ [å®æ—¶è¡Œæƒ…] ç¼“å­˜æ›´æ–°å¤±è´¥: {e}")

            return quote

        except Exception as e:
            logger.error(f"âŒ è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {e}", exc_info=True)
            return None

    def _get_tushare_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Tushareè·å–å®æ—¶è¡Œæƒ…"""
        try:
            provider = self._get_tushare_adapter()
            if not provider:
                return None

            # Tushareçš„å®æ—¶è¡Œæƒ…æ¥å£
            import asyncio

            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # ä½¿ç”¨Tushareçš„å®æ—¶è¡Œæƒ…æ¥å£ï¼ˆéœ€è¦é«˜çº§æƒé™ï¼‰
            # è¿™é‡Œå…ˆè¿”å›Noneï¼Œå› ä¸ºTushareå®æ—¶è¡Œæƒ…éœ€è¦ç‰¹æ®Šæƒé™
            logger.warning("âš ï¸ Tushareå®æ—¶è¡Œæƒ…éœ€è¦é«˜çº§æƒé™ï¼Œæš‚ä¸æ”¯æŒ")
            return None

        except Exception as e:
            logger.error(f"âŒ Tushareå®æ—¶è¡Œæƒ…è·å–å¤±è´¥: {e}")
            return None

    def _get_akshare_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨AKShareè·å–å®æ—¶è¡Œæƒ…"""
        try:
            import akshare as ak

            # AKShareçš„å®æ—¶è¡Œæƒ…æ¥å£
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if symbol.startswith("6"):
                ak_symbol = f"sh{symbol}"
            elif symbol.startswith(("0", "3", "2")):
                ak_symbol = f"sz{symbol}"
            elif symbol.startswith(("8", "4")):
                ak_symbol = f"bj{symbol}"
            else:
                ak_symbol = symbol

            # è·å–å®æ—¶è¡Œæƒ…
            df = ak.stock_zh_a_spot_em()
            stock_data = df[df["ä»£ç "] == symbol]

            if not stock_data.empty:
                row = stock_data.iloc[0]
                # ğŸ”¥ æˆäº¤é‡å•ä½è½¬æ¢ï¼šAKShare è¿”å›çš„æˆäº¤é‡å•ä½æ˜¯"æ‰‹"ï¼Œéœ€è¦ä¹˜ä»¥100è½¬æ¢ä¸º"è‚¡"
                # ä¾‹å¦‚ï¼š22,482.8æ‰‹ = 2,248,280è‚¡ï¼Œä½†åŒèŠ±é¡ºæ˜¾ç¤ºçš„æ˜¯22,483,000è‚¡
                # è¿™é‡Œéœ€è¦éªŒè¯æ•°æ®çš„å‡†ç¡®æ€§
                volume_raw = float(row["æˆäº¤é‡"]) if row["æˆäº¤é‡"] else 0
                # AKShare è¿”å›çš„æˆäº¤é‡å•ä½æ˜¯"æ‰‹"ï¼Œè½¬æ¢ä¸º"è‚¡"
                volume_in_shares = volume_raw * 100

                quote = {
                    "symbol": symbol,
                    "price": float(row["æœ€æ–°ä»·"]),
                    "open": float(row["ä»Šå¼€"]),
                    "high": float(row["æœ€é«˜"]),
                    "low": float(row["æœ€ä½"]),
                    "volume": volume_in_shares,  # ğŸ”¥ å·²è½¬æ¢ä¸ºè‚¡
                    "amount": float(row["æˆäº¤é¢"]),
                    "change": float(row["æ¶¨è·Œé¢"]),
                    "change_pct": float(row["æ¶¨è·Œå¹…"]),
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "time": datetime.now().strftime("%H:%M:%S"),
                    "source": "akshare_realtime",
                    "is_realtime": True,
                }
                logger.info(
                    f"âœ… [å®æ—¶è¡Œæƒ…-AKShare] {symbol} ä»·æ ¼={quote['price']:.2f}, æˆäº¤é‡={volume_in_shares:,.0f}è‚¡"
                )
                return quote
            else:
                logger.warning(f"âš ï¸ AKShareæœªæ‰¾åˆ°{symbol}çš„å®æ—¶è¡Œæƒ…")
                return None

        except Exception as e:
            logger.error(f"âŒ AKShareå®æ—¶è¡Œæƒ…è·å–å¤±è´¥: {e}", exc_info=True)
            return None

    def get_stock_data(
        self,
        symbol: str,
        start_date: str = None,
        end_date: str = None,
        period: str = "daily",
    ) -> str:
        """
        è·å–è‚¡ç¥¨æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šå‘¨æœŸæ•°æ®

        ğŸ”¥ é‡è¦æ›´æ–°ï¼šç›˜ä¸­äº¤æ˜“æ—¶é—´è‡ªåŠ¨ä½¿ç”¨å®æ—¶è¡Œæƒ…

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
        """
        # ğŸ”¥ è·å–å®æ—¶ä»·æ ¼ï¼ˆå§‹ç»ˆå°è¯•ï¼Œä¸ä»…ä»…æ˜¯ç›˜ä¸­ï¼‰
        realtime_price = None
        try:
            from tradingagents.utils.market_time import MarketTimeUtils

            should_use_rt, reason = MarketTimeUtils.should_use_realtime_quote(symbol)
            logger.info(f"ğŸ“Š [å®æ—¶è¡Œæƒ…æ£€æŸ¥] {symbol}: {reason}")

            # å§‹ç»ˆå°è¯•è·å–å®æ—¶ä»·æ ¼ï¼ˆç›˜ä¸­ç”¨å®æ—¶ï¼Œç›˜åç”¨æœ€æ–°æ”¶ç›˜ä»·ï¼‰
            realtime_quote = self.get_realtime_quote(symbol)
            if realtime_quote and realtime_quote.get("price"):
                realtime_price = realtime_quote["price"]
                logger.info(f"âœ… [å®æ—¶ä»·æ ¼] è·å–æˆåŠŸ: Â¥{realtime_price:.2f}")
            else:
                logger.warning(f"âš ï¸ [å®æ—¶ä»·æ ¼] è·å–å¤±è´¥ï¼Œå°†ä½¿ç”¨å†å²æ•°æ®ä¸­çš„ä»·æ ¼")
        except Exception as e:
            logger.debug(f"å®æ—¶è¡Œæƒ…è·å–å¤±è´¥ï¼ˆä½¿ç”¨å†å²æ•°æ®ï¼‰: {e}")
            realtime_quote = None

        # è®°å½•è¯¦ç»†çš„è¾“å…¥å‚æ•°
        logger.info(
            f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–{period}æ•°æ®: {symbol}",
            extra={
                "symbol": symbol,
                "start_date": start_date,
                "end_date": end_date,
                "period": period,
                "data_source": self.current_source.value,
                "event_type": "data_fetch_start",
            },
        )

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(
            f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] DataSourceManager.get_stock_data æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})"
        )
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] å½“å‰æ•°æ®æº: {self.current_source.value}")

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            actual_source = None  # å®é™…ä½¿ç”¨çš„æ•°æ®æº

            if self.current_source == ChinaDataSource.MONGODB:
                result, actual_source = self._get_mongodb_data(
                    symbol, start_date, end_date, period, realtime_price
                )
            elif self.current_source == ChinaDataSource.TUSHARE:
                logger.info(
                    f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ Tushare æ•°æ®æºï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', period='{period}'"
                )
                result = self._get_tushare_data(symbol, start_date, end_date, period)
                actual_source = "tushare"
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_data(symbol, start_date, end_date, period)
                actual_source = "akshare"
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                result = self._get_baostock_data(symbol, start_date, end_date, period)
                actual_source = "baostock"
            # TDX å·²ç§»é™¤
            else:
                result = f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source.value}"
                actual_source = None

            # è®°å½•è¯¦ç»†çš„è¾“å‡ºç»“æœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0
            is_success = result and "âŒ" not in result and "é”™è¯¯" not in result

            # ä½¿ç”¨å®é™…æ•°æ®æºåç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ current_source
            display_source = actual_source or self.current_source.value

            if is_success:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {display_source}] æˆåŠŸè·å–è‚¡ç¥¨æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "start_date": start_date,
                        "end_date": end_date,
                        "data_source": display_source,
                        "actual_source": actual_source,
                        "requested_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "result_preview": result[:200] + "..."
                        if result_length > 200
                        else result,
                        "event_type": "data_fetch_success",
                    },
                )

                # ğŸ”¥ å¦‚æœæœ‰å®æ—¶è¡Œæƒ…ï¼Œæ›¿æ¢æœ€æ–°ä»·æ ¼
                if should_use_rt and realtime_quote:
                    result = self._merge_realtime_quote_to_result(
                        result, realtime_quote, symbol
                    )

                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº: {symbol}",
                    extra={
                        "symbol": symbol,
                        "start_date": start_date,
                        "end_date": end_date,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "result_preview": result[:200] + "..."
                        if result_length > 200
                        else result,
                        "event_type": "data_fetch_warning",
                    },
                )

                # æ•°æ®è´¨é‡å¼‚å¸¸æ—¶ä¹Ÿå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº
                fallback_result = self._try_fallback_sources(
                    symbol, start_date, end_date
                )
                if (
                    fallback_result
                    and "âŒ" not in fallback_result
                    and "é”™è¯¯" not in fallback_result
                ):
                    logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–æ•°æ®: {symbol}")
                    return fallback_result
                else:
                    logger.error(
                        f"âŒ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–æœ‰æ•ˆæ•°æ®: {symbol}"
                    )
                    return result  # è¿”å›åŸå§‹ç»“æœï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯ï¼‰

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®è·å–] å¼‚å¸¸å¤±è´¥: {e}",
                extra={
                    "symbol": symbol,
                    "start_date": start_date,
                    "end_date": end_date,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "data_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_sources(
                symbol, start_date, end_date, realtime_price=realtime_price
            )

    def _merge_realtime_quote_to_result(
        self, historical_result: str, realtime_quote: Dict, symbol: str
    ) -> str:
        """
        å°†å®æ—¶è¡Œæƒ…æ•°æ®åˆå¹¶åˆ°å†å²æ•°æ®ç»“æœä¸­

        Args:
            historical_result: å†å²æ•°æ®æ ¼å¼åŒ–ç»“æœ
            realtime_quote: å®æ—¶è¡Œæƒ…æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åˆå¹¶åçš„ç»“æœ
        """
        try:
            # ğŸ”§ å®‰å…¨æå–å®æ—¶è¡Œæƒ…æ•°æ®ï¼Œå¤„ç† None å€¼
            price = realtime_quote.get("price")
            change = realtime_quote.get("change")
            change_pct = realtime_quote.get("change_pct")
            open_price = realtime_quote.get("open")
            high_price = realtime_quote.get("high")
            low_price = realtime_quote.get("low")
            quote_date = realtime_quote.get("date", "")
            quote_time = realtime_quote.get("time", "å®æ—¶")

            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
            if price is None:
                logger.warning(f"âš ï¸ å®æ—¶è¡Œæƒ…ç¼ºå°‘ä»·æ ¼æ•°æ®: {symbol}")
                return historical_result

            # æ ¼å¼åŒ–æ•°å€¼ï¼Œå¤„ç† None å€¼
            price_str = f"Â¥{price:.2f}" if price is not None else "N/A"
            change_str = f"{change:+.2f}" if change is not None else "N/A"
            change_pct_str = f"{change_pct:+.2f}%" if change_pct is not None else "N/A"
            open_str = f"Â¥{open_price:.2f}" if open_price is not None else "N/A"
            high_str = f"Â¥{high_price:.2f}" if high_price is not None else "N/A"
            low_str = f"Â¥{low_price:.2f}" if low_price is not None else "N/A"

            # åœ¨ç»“æœå¼€å¤´æ·»åŠ å®æ—¶è¡Œæƒ…æ ‡è¯†
            realtime_notice = f"""
âš¡ å®æ—¶è¡Œæƒ…ï¼ˆç›˜ä¸­ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’° å®æ—¶ä»·æ ¼: {price_str}
ğŸ“ˆ æ¶¨è·Œ: {change_str} ({change_pct_str})
ğŸ“Š ä»Šå¼€: {open_str}  |  æœ€é«˜: {high_str}  |  æœ€ä½: {low_str}
ğŸ• æ›´æ–°æ—¶é—´: {quote_date} {quote_time}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            # æ›¿æ¢åŸæœ‰çš„æœ€æ–°ä»·æ ¼éƒ¨åˆ†
            lines = historical_result.split("\n")
            new_lines = []
            skip_next_price_lines = False

            for i, line in enumerate(lines):
                # åœ¨æ ‡é¢˜åæ’å…¥å®æ—¶è¡Œæƒ…
                if i == 0 and "æŠ€æœ¯åˆ†ææ•°æ®" in line:
                    new_lines.append(line)
                    # æ‰¾åˆ°æ•°æ®æœŸé—´è¡Œåæ’å…¥
                    continue
                elif "æ•°æ®æœŸé—´:" in line:
                    new_lines.append(line)
                    # æ’å…¥å®æ—¶è¡Œæƒ…é€šçŸ¥
                    new_lines.append(realtime_notice)
                    continue
                # è·³è¿‡åŸæœ‰çš„æœ€æ–°ä»·æ ¼è¡Œï¼Œå› ä¸ºå®æ—¶è¡Œæƒ…å·²åŒ…å«
                elif "ğŸ’° æœ€æ–°ä»·æ ¼:" in line and not skip_next_price_lines:
                    skip_next_price_lines = True
                    continue
                elif skip_next_price_lines and "ğŸ“ˆ æ¶¨è·Œé¢:" in line:
                    skip_next_price_lines = False
                    continue
                elif skip_next_price_lines:
                    continue
                else:
                    new_lines.append(line)

            return "\n".join(new_lines)

        except Exception as e:
            logger.error(f"âŒ åˆå¹¶å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
            return historical_result

    def _get_mongodb_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_price: float = None,
    ) -> tuple[str, str | None]:
        """
        ä»MongoDBè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

        Returns:
            tuple[str, str | None]: (ç»“æœå­—ç¬¦ä¸², å®é™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.debug(
            f"ğŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä»MongoDBè·å–æŒ‡å®šå‘¨æœŸçš„å†å²æ•°æ®
            df = adapter.get_historical_data(
                symbol, start_date, end_date, period=period
            )

            if df is not None and not df.empty:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: MongoDBç¼“å­˜] æˆåŠŸè·å–{period}æ•°æ®: {symbol} ({len(df)}æ¡è®°å½•)"
                )

                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # è·å–è‚¡ç¥¨åç§°ï¼ˆä»DataFrameä¸­æå–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                stock_name = f"è‚¡ç¥¨{symbol}"
                if "name" in df.columns and not df["name"].empty:
                    stock_name = df["name"].iloc[0]

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼Œä¼ å…¥å®æ—¶ä»·æ ¼ï¼‰
                result = self._format_stock_data_response(
                    df, symbol, stock_name, start_date, end_date, realtime_price
                )

                logger.info(
                    f"âœ… [MongoDB] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL"
                )
                return result, "mongodb"
            else:
                # MongoDBæ²¡æœ‰æ•°æ®ï¼ˆadapterå†…éƒ¨å·²è®°å½•è¯¦ç»†çš„æ•°æ®æºä¿¡æ¯ï¼‰ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                logger.info(
                    f"ğŸ”„ [MongoDB] æœªæ‰¾åˆ°{period}æ•°æ®: {symbol}ï¼Œå¼€å§‹å°è¯•å¤‡ç”¨æ•°æ®æº"
                )
                return self._try_fallback_sources(
                    symbol, start_date, end_date, period, realtime_price
                )

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–{period}æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}"
            )
            # MongoDBå¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_sources(
                symbol, start_date, end_date, period, realtime_price
            )

    def _get_tushare_data(
        self, symbol: str, start_date: str, end_date: str, period: str = "daily"
    ) -> str:
        """ä½¿ç”¨Tushareè·å–å¤šå‘¨æœŸæ•°æ® - ä½¿ç”¨provider + ç»Ÿä¸€ç¼“å­˜"""
        logger.debug(
            f"ğŸ“Š [Tushare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(
            f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] _get_tushare_data æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})"
        )
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] _get_tushare_data å¼€å§‹æ‰§è¡Œ")
        logger.info(
            f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å½“å‰æ•°æ®æº: {self.current_source.value}"
        )

        start_time = time.time()
        try:
            # 1. å…ˆå°è¯•ä»ç¼“å­˜è·å–
            cached_data = self._get_cached_data(
                symbol, start_date, end_date, max_age_hours=24
            )
            if cached_data is not None and not cached_data.empty:
                logger.info(f"âœ… [ç¼“å­˜å‘½ä¸­] ä»ç¼“å­˜è·å–{symbol}æ•°æ®")
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                provider = self._get_tushare_adapter()
                if provider:
                    import asyncio

                    try:
                        loop = asyncio.get_event_loop()
                        if loop.is_closed():
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                    except RuntimeError:
                        # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)

                    stock_info = loop.run_until_complete(
                        provider.get_stock_basic_info(symbol)
                    )
                    stock_name = (
                        stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                        if stock_info
                        else f"è‚¡ç¥¨{symbol}"
                    )
                else:
                    stock_name = f"è‚¡ç¥¨{symbol}"

                # æ ¼å¼åŒ–è¿”å›
                return self._format_stock_data_response(
                    cached_data,
                    symbol,
                    stock_name,
                    start_date,
                    end_date,
                    realtime_price,
                )

            # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œä»providerè·å–
            logger.info(
                f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ tushare_providerï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}'"
            )
            logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼€å§‹è°ƒç”¨tushare_provider...")

            provider = self._get_tushare_adapter()
            if not provider:
                return f"âŒ Tushareæä¾›å™¨ä¸å¯ç”¨"

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
            import asyncio

            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            data = loop.run_until_complete(
                provider.get_historical_data(symbol, start_date, end_date)
            )

            if data is not None and not data.empty:
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_cache(symbol, data, start_date, end_date)

                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰
                stock_info = loop.run_until_complete(
                    provider.get_stock_basic_info(symbol)
                )
                stock_name = (
                    stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                    if stock_info
                    else f"è‚¡ç¥¨{symbol}"
                )

                # æ ¼å¼åŒ–è¿”å›
                result = self._format_stock_data_response(
                    data, symbol, stock_name, start_date, end_date, realtime_price
                )

                duration = time.time() - start_time
                logger.info(
                    f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {duration:.3f}ç§’"
                )
                logger.info(
                    f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœå‰200å­—ç¬¦: {result[:200] if result else 'None'}"
                )
                logger.debug(
                    f"ğŸ“Š [Tushare] è°ƒç”¨å®Œæˆ: è€—æ—¶={duration:.2f}s, ç»“æœé•¿åº¦={len(result) if result else 0}"
                )

                return result
            else:
                result = f"âŒ æœªè·å–åˆ°{symbol}çš„æœ‰æ•ˆæ•°æ®"
                duration = time.time() - start_time
                logger.warning(f"âš ï¸ [Tushare] æœªè·å–åˆ°æ•°æ®ï¼Œè€—æ—¶={duration:.2f}s")
                return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [Tushare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True
            )
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ä¿¡æ¯: {str(e)}")
            import traceback

            logger.error(
                f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}"
            )
            raise

    def _get_akshare_data(
        self, symbol: str, start_date: str, end_date: str, period: str = "daily"
    ) -> str:
        """ä½¿ç”¨AKShareè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        logger.debug(
            f"ğŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        start_time = time.time()
        try:
            # ä½¿ç”¨AKShareçš„ç»Ÿä¸€æ¥å£
            from .providers.china.akshare import get_akshare_provider

            provider = get_akshare_provider()

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
            import asyncio

            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            data = loop.run_until_complete(
                provider.get_historical_data(symbol, start_date, end_date, period)
            )

            duration = time.time() - start_time

            if data is not None and not data.empty:
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                stock_info = loop.run_until_complete(
                    provider.get_stock_basic_info(symbol)
                )
                stock_name = (
                    stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                    if stock_info
                    else f"è‚¡ç¥¨{symbol}"
                )

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
                result = self._format_stock_data_response(
                    data, symbol, stock_name, start_date, end_date, realtime_price
                )

                logger.debug(
                    f"ğŸ“Š [AKShare] è°ƒç”¨æˆåŠŸ: è€—æ—¶={duration:.2f}s, æ•°æ®æ¡æ•°={len(data)}, ç»“æœé•¿åº¦={len(result)}"
                )
                logger.info(
                    f"âœ… [AKShare] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL"
                )
                return result
            else:
                result = f"âŒ æœªèƒ½è·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"
                logger.warning(f"âš ï¸ [AKShare] æ•°æ®ä¸ºç©º: è€—æ—¶={duration:.2f}s")
                return result

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [AKShare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True
            )
            return f"âŒ AKShareè·å–{symbol}æ•°æ®å¤±è´¥: {e}"

    def _get_baostock_data(
        self, symbol: str, start_date: str, end_date: str, period: str = "daily"
    ) -> str:
        """ä½¿ç”¨BaoStockè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        # ä½¿ç”¨BaoStockçš„ç»Ÿä¸€æ¥å£
        from .providers.china.baostock import get_baostock_provider

        provider = get_baostock_provider()

        # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
        import asyncio

        try:
            loop = asyncio.get_event_loop()
            if loop.is_closed():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
        except RuntimeError:
            # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        data = loop.run_until_complete(
            provider.get_historical_data(symbol, start_date, end_date, period)
        )

        if data is not None and not data.empty:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))
            stock_name = (
                stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                if stock_info
                else f"è‚¡ç¥¨{symbol}"
            )

            # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
            result = self._format_stock_data_response(
                data, symbol, stock_name, start_date, end_date, realtime_price
            )

            logger.info(f"âœ… [BaoStock] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL")
            return result
        else:
            return f"âŒ æœªèƒ½è·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"

    # TDX æ•°æ®è·å–æ–¹æ³•å·²ç§»é™¤
    # def _get_tdx_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
    #     """ä½¿ç”¨TDXè·å–å¤šå‘¨æœŸæ•°æ® (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ"

    # ğŸ”§ FIX: åˆ é™¤é‡å¤çš„ _get_volume_safely æ–¹æ³•å®šä¹‰
    # æ­£ç¡®çš„ç‰ˆæœ¬åœ¨ç¬¬769è¡Œï¼Œä½¿ç”¨ iloc[-1] è·å–æœ€åä¸€å¤©çš„æˆäº¤é‡
    # è¿™é‡Œçš„ç‰ˆæœ¬ä½¿ç”¨ sum() æ˜¯é”™è¯¯çš„ï¼Œä¼šå¯¼è‡´æˆäº¤é‡æ•°æ®ä¸ä¸€è‡´
    # è¯¦è§: docs/reports/report_optimization_plan.md

    def _try_fallback_sources(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_price: float = None,
    ) -> tuple[str, str | None]:
        """
        å°è¯•å¤‡ç”¨æ•°æ®æº - é¿å…é€’å½’è°ƒç”¨

        Returns:
            tuple[str, str | None]: (ç»“æœå­—ç¬¦ä¸², å®é™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.info(
            f"ğŸ”„ [{self.current_source.value}] å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–{period}æ•°æ®: {symbol}"
        )

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        # æ³¨æ„ï¼šä¸åŒ…å«MongoDBï¼Œå› ä¸ºMongoDBæ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œå¦‚æœå¤±è´¥äº†å°±ä¸å†å°è¯•
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(
                        f"ğŸ”„ [å¤‡ç”¨æ•°æ®æº] å°è¯• {source.value} è·å–{period}æ•°æ®: {symbol}"
                    )

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_data(
                            symbol, start_date, end_date, period
                        )
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_data(
                            symbol, start_date, end_date, period
                        )
                    elif source == ChinaDataSource.BAOSTOCK:
                        result = self._get_baostock_data(
                            symbol, start_date, end_date, period
                        )
                    # TDX å·²ç§»é™¤
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥æ•°æ®æº: {source.value}")
                        continue

                    if "âŒ" not in result:
                        logger.info(
                            f"âœ… [å¤‡ç”¨æ•°æ®æº-{source.value}] æˆåŠŸè·å–{period}æ•°æ®: {symbol}"
                        )
                        return result, source.value  # è¿”å›ç»“æœå’Œå®é™…ä½¿ç”¨çš„æ•°æ®æº
                    else:
                        logger.warning(
                            f"âš ï¸ [å¤‡ç”¨æ•°æ®æº-{source.value}] è¿”å›é”™è¯¯ç»“æœ: {symbol}"
                        )

                except Exception as e:
                    logger.error(
                        f"âŒ [å¤‡ç”¨æ•°æ®æº-{source.value}] è·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}"
                    )
                    continue

        logger.error(f"âŒ [æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•è·å–{period}æ•°æ®: {symbol}")
        return f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–{symbol}çš„{period}æ•°æ®", None

    def get_stock_info(self, symbol: str) -> Dict:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ BaoStock
        """
        logger.info(
            f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–è‚¡ç¥¨ä¿¡æ¯: {symbol}"
        )

        # ä¼˜å…ˆä½¿ç”¨ App Mongo ç¼“å­˜ï¼ˆå½“ ta_use_app_cache=Trueï¼‰
        try:
            from tradingagents.config.runtime_settings import (
                use_app_cache_enabled,  # type: ignore
            )

            use_cache = use_app_cache_enabled(False)
            logger.info(f"ğŸ”§ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è¿”å›å€¼: {use_cache}")
        except Exception as e:
            logger.error(
                f"âŒ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è°ƒç”¨å¤±è´¥: {e}", exc_info=True
            )
            use_cache = False

        logger.info(
            f"ğŸ”§ [é…ç½®] ta_use_app_cache={use_cache}, current_source={self.current_source.value}"
        )

        if use_cache:
            try:
                from .cache.app_adapter import (
                    get_basics_from_cache,
                    get_market_quote_dataframe,
                )

                doc = get_basics_from_cache(symbol)
                if doc:
                    # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                    data_source = doc.get("data_source", "app_cache")
                    standardized_data = standardize_stock_basic(doc, data_source)

                    # ä»æ ‡å‡†åŒ–æ•°æ®ä¸­æå–å­—æ®µ
                    name = standardized_data.get("name") or f"è‚¡ç¥¨{symbol}"

                    # è§„èŒƒåŒ–è¡Œä¸šä¸æ¿å—ï¼ˆé¿å…æŠŠ"ä¸­å°æ¿/åˆ›ä¸šæ¿"ç­‰æ¿å—å€¼è¯¯ä½œè¡Œä¸šï¼‰
                    board_labels = {"ä¸»æ¿", "ä¸­å°æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"}
                    raw_industry = standardized_data.get("industry", "") or ""
                    market_val = standardized_data.get("market", "") or ""

                    if raw_industry in board_labels:
                        if not market_val:
                            market_val = raw_industry
                        # ä½¿ç”¨æ›´ç»†åˆ†ç±»ï¼ˆå¦‚æœæœ‰ï¼‰
                        if standardized_data.get("industry_gn"):
                            industry_val = standardized_data.get("industry_gn")
                        elif standardized_data.get("industry_sw"):
                            industry_val = standardized_data.get("industry_sw")
                        else:
                            industry_val = "æœªçŸ¥"
                    else:
                        industry_val = raw_industry or "æœªçŸ¥"

                    result = {
                        "symbol": standardized_data.get("code", symbol),
                        "name": name,
                        "area": standardized_data.get("area", "æœªçŸ¥"),
                        "industry": industry_val,
                        "market": market_val or standardized_data.get("market", "æœªçŸ¥"),
                        "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                        # è´¢åŠ¡æŒ‡æ ‡
                        "pe": standardized_data.get("pe"),
                        "pb": standardized_data.get("pb"),
                        "ps": standardized_data.get("ps"),
                        "pe_ttm": standardized_data.get("pe_ttm"),
                        "total_mv": standardized_data.get("total_mv"),
                        "circ_mv": standardized_data.get("circ_mv"),
                        # è¡Œæƒ…æ•°æ®
                        "current_price": None,
                        "change_pct": None,
                        "volume": None,
                        # å…ƒæ•°æ®
                        "source": "app_cache",
                        "data_source": data_source,
                    }

                    # è¿½åŠ å¿«ç…§è¡Œæƒ…ï¼ˆè‹¥å­˜åœ¨ï¼‰
                    try:
                        df = get_market_quote_dataframe(symbol)
                        if df is not None and not df.empty:
                            row = df.iloc[-1]
                            result["current_price"] = row.get("close")
                            result["change_pct"] = row.get("pct_chg")
                            # market_quotes ä¸­çš„ volume å·²ç»æ˜¯"è‚¡"å•ä½ï¼Œæ— éœ€å†è½¬æ¢
                            result["volume"] = row.get("volume")
                            result["quote_date"] = row.get("date")
                            result["quote_source"] = "market_quotes"
                            logger.info(
                                f"âœ… [è‚¡ç¥¨ä¿¡æ¯] é™„åŠ è¡Œæƒ… | price={result['current_price']} pct={result['change_pct']} vol={result['volume']} code={symbol}"
                            )
                    except Exception as _e:
                        logger.debug(f"é™„åŠ è¡Œæƒ…å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{_e}")

                    if name and name != f"è‚¡ç¥¨{symbol}":
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: MongoDB-stock_basic_info] æˆåŠŸè·å–: {symbol}"
                        )
                        return result
                    else:
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æœ‰æ•ˆåç§°: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                        )
            except Exception as e:
                logger.error(
                    f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}", exc_info=True
                )

        # é¦–å…ˆå°è¯•å½“å‰æ•°æ®æº
        try:
            if self.current_source == ChinaDataSource.TUSHARE:
                from .interface import get_china_stock_info_tushare

                info_str = get_china_stock_info_tushare(symbol)
                raw_result = self._parse_stock_info_string(info_str, symbol)

                # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                standardized_data = standardize_stock_basic(raw_result, "tushare")

                # æ„å»ºæ ‡å‡†åŒ–ç»“æœ
                result = {
                    "symbol": standardized_data.get("code", symbol),
                    "name": standardized_data.get("name", f"è‚¡ç¥¨{symbol}"),
                    "area": standardized_data.get("area", "æœªçŸ¥"),
                    "industry": standardized_data.get("industry", "æœªçŸ¥"),
                    "market": standardized_data.get("market", "æœªçŸ¥"),
                    "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                    # è´¢åŠ¡æŒ‡æ ‡
                    "pe": standardized_data.get("pe"),
                    "pb": standardized_data.get("pb"),
                    "ps": standardized_data.get("ps"),
                    "pe_ttm": standardized_data.get("pe_ttm"),
                    "total_mv": standardized_data.get("total_mv"),
                    "circ_mv": standardized_data.get("circ_mv"),
                    # è¡Œæƒ…æ•°æ®ï¼ˆä»åŸå§‹æ•°æ®è·å–ï¼‰
                    "current_price": raw_result.get("current_price"),
                    "change_pct": raw_result.get("change_pct"),
                    "volume": raw_result.get("volume"),
                    # å…ƒæ•°æ®
                    "source": "tushare",
                    "data_source": "tushare",
                }

                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                    logger.info(f"âœ… [æ•°æ®æ¥æº: Tushare-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸè·å–: {symbol}")
                    return result
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: Tushareå¤±è´¥] è¿”å›æ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}"
                    )
                    return self._try_fallback_stock_info(symbol)
            else:
                adapter = self.get_data_adapter()
                if adapter and hasattr(adapter, "get_stock_info"):
                    raw_result = adapter.get_stock_info(symbol)

                    # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                    data_source_name = self.current_source.value
                    standardized_data = standardize_stock_basic(
                        raw_result, data_source_name
                    )

                    # æ„å»ºæ ‡å‡†åŒ–ç»“æœ
                    result = {
                        "symbol": standardized_data.get("code", symbol),
                        "name": standardized_data.get("name", f"è‚¡ç¥¨{symbol}"),
                        "area": standardized_data.get("area", "æœªçŸ¥"),
                        "industry": standardized_data.get("industry", "æœªçŸ¥"),
                        "market": standardized_data.get("market", "æœªçŸ¥"),
                        "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                        # è´¢åŠ¡æŒ‡æ ‡
                        "pe": standardized_data.get("pe"),
                        "pb": standardized_data.get("pb"),
                        "ps": standardized_data.get("ps"),
                        "pe_ttm": standardized_data.get("pe_ttm"),
                        "total_mv": standardized_data.get("total_mv"),
                        "circ_mv": standardized_data.get("circ_mv"),
                        # è¡Œæƒ…æ•°æ®
                        "current_price": raw_result.get("current_price"),
                        "change_pct": raw_result.get("change_pct"),
                        "volume": raw_result.get("volume"),
                        # å…ƒæ•°æ®
                        "source": data_source_name,
                        "data_source": data_source_name,
                    }

                    if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸè·å–: {symbol}"
                        )
                        return result
                    else:
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] è¿”å›æ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}"
                        )
                        return self._try_fallback_stock_info(symbol)
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯è·å–ï¼Œå°è¯•é™çº§: {symbol}"
                    )
                    return self._try_fallback_stock_info(symbol)

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}",
                exc_info=True,
            )
            return self._try_fallback_stock_info(symbol)

    def get_stock_basic_info(self, stock_code: str = None) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœä¸º None åˆ™è¿”å›æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨

        Returns:
            Dict: è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼Œæˆ–åŒ…å« error å­—æ®µçš„é”™è¯¯å­—å…¸
        """
        if stock_code is None:
            # è¿”å›æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            logger.info("ğŸ“Š è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨")
            try:
                # å°è¯•ä» MongoDB è·å–
                from tradingagents.config.database_manager import get_database_manager

                db_manager = get_database_manager()
                if db_manager and db_manager.is_mongodb_available():
                    collection = db_manager.mongodb_db["stock_basic_info"]
                    stocks = list(collection.find({}, {"_id": 0}))
                    if stocks:
                        logger.info(f"âœ… ä»MongoDBè·å–æ‰€æœ‰è‚¡ç¥¨: {len(stocks)}æ¡")
                        return stocks
            except Exception as e:
                logger.warning(f"âš ï¸ ä»MongoDBè·å–æ‰€æœ‰è‚¡ç¥¨å¤±è´¥: {e}")

            # é™çº§ï¼šè¿”å›ç©ºåˆ—è¡¨
            return []

        # è·å–å•ä¸ªè‚¡ç¥¨ä¿¡æ¯
        try:
            result = self.get_stock_info(stock_code)
            if result and result.get("name"):
                return result
            else:
                return {"error": f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„ä¿¡æ¯"}
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}

    def get_stock_data_with_fallback(
        self, stock_code: str, start_date: str, end_date: str
    ) -> str:
        """
        è·å–è‚¡ç¥¨æ•°æ®ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        logger.info(f"ğŸ“Š è·å–è‚¡ç¥¨æ•°æ®: {stock_code} ({start_date} åˆ° {end_date})")

        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
            return self.get_stock_data(stock_code, start_date, end_date)
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}\n\nğŸ’¡ å»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®\n3. æ£€æŸ¥æ•°æ®æºé…ç½®"

    def _try_fallback_stock_info(self, symbol: str) -> Dict:
        """å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.error(
            f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨ä¿¡æ¯..."
        )

        # è·å–æ‰€æœ‰å¯ç”¨æ•°æ®æº
        available_sources = self.available_sources.copy()

        # ç§»é™¤å½“å‰æ•°æ®æº
        if self.current_source.value in available_sources:
            available_sources.remove(self.current_source.value)

        # å°è¯•æ‰€æœ‰å¤‡ç”¨æ•°æ®æº
        for source_name in available_sources:
            try:
                source = ChinaDataSource(source_name)
                logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}")

                # æ ¹æ®æ•°æ®æºç±»å‹è·å–è‚¡ç¥¨ä¿¡æ¯
                if source == ChinaDataSource.TUSHARE:
                    # ğŸ”¥ ç›´æ¥è°ƒç”¨ Tushare é€‚é…å™¨ï¼Œé¿å…å¾ªç¯è°ƒç”¨
                    result = self._get_tushare_stock_info(symbol)
                elif source == ChinaDataSource.AKSHARE:
                    result = self._get_akshare_stock_info(symbol)
                elif source == ChinaDataSource.BAOSTOCK:
                    result = self._get_baostock_stock_info(symbol)
                else:
                    # å°è¯•é€šç”¨é€‚é…å™¨
                    original_source = self.current_source
                    self.current_source = source
                    adapter = self.get_data_adapter()
                    self.current_source = original_source

                    if adapter and hasattr(adapter, "get_stock_info"):
                        result = adapter.get_stock_info(symbol)
                    else:
                        logger.warning(f"âš ï¸ [è‚¡ç¥¨ä¿¡æ¯] {source_name}ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯è·å–")
                        continue

                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}"
                    )
                    return result
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {source_name}] è¿”å›æ— æ•ˆä¿¡æ¯")

            except Exception as e:
                logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source_name}å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        logger.error(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–{symbol}çš„è‚¡ç¥¨ä¿¡æ¯")
        return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "unknown"}

    def _get_akshare_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨AKShareè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

        ğŸ”¥ é‡è¦ï¼šAKShare éœ€è¦åŒºåˆ†è‚¡ç¥¨å’ŒæŒ‡æ•°
        - å¯¹äº 000001ï¼Œå¦‚æœä¸åŠ åç¼€ï¼Œä¼šè¢«è¯†åˆ«ä¸º"æ·±åœ³æˆæŒ‡"ï¼ˆæŒ‡æ•°ï¼‰
        - å¯¹äºè‚¡ç¥¨ï¼Œéœ€è¦ä½¿ç”¨å®Œæ•´ä»£ç ï¼ˆå¦‚ sz000001 æˆ– sh600000ï¼‰
        """
        try:
            import akshare as ak

            # ğŸ”¥ è½¬æ¢ä¸º AKShare æ ¼å¼çš„è‚¡ç¥¨ä»£ç 
            # AKShare çš„ stock_individual_info_em éœ€è¦ä½¿ç”¨ "sz000001" æˆ– "sh600000" æ ¼å¼
            if symbol.startswith("6"):
                # ä¸Šæµ·è‚¡ç¥¨ï¼š600000 -> sh600000
                akshare_symbol = f"sh{symbol}"
            elif symbol.startswith(("0", "3", "2")):
                # æ·±åœ³è‚¡ç¥¨ï¼š000001 -> sz000001
                akshare_symbol = f"sz{symbol}"
            elif symbol.startswith(("8", "4")):
                # åŒ—äº¬è‚¡ç¥¨ï¼š830000 -> bj830000
                akshare_symbol = f"bj{symbol}"
            else:
                # å…¶ä»–æƒ…å†µï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ä»£ç 
                akshare_symbol = symbol

            logger.debug(
                f"ğŸ“Š [AKShareè‚¡ç¥¨ä¿¡æ¯] åŸå§‹ä»£ç : {symbol}, AKShareæ ¼å¼: {akshare_symbol}"
            )

            # å°è¯•è·å–ä¸ªè‚¡ä¿¡æ¯
            stock_info = ak.stock_individual_info_em(symbol=akshare_symbol)

            if stock_info is not None and not stock_info.empty:
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                info = {"symbol": symbol, "source": "akshare"}

                # æå–è‚¡ç¥¨åç§°
                name_row = stock_info[stock_info["item"] == "è‚¡ç¥¨ç®€ç§°"]
                if not name_row.empty:
                    stock_name = name_row["value"].iloc[0]
                    info["name"] = stock_name
                    logger.info(f"âœ… [AKShareè‚¡ç¥¨ä¿¡æ¯] {symbol} -> {stock_name}")
                else:
                    info["name"] = f"è‚¡ç¥¨{symbol}"
                    logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] æœªæ‰¾åˆ°è‚¡ç¥¨ç®€ç§°: {symbol}")

                # æå–å…¶ä»–ä¿¡æ¯
                info["area"] = "æœªçŸ¥"  # AKShareæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info["industry"] = "æœªçŸ¥"  # å¯ä»¥é€šè¿‡å…¶ä»–APIè·å–
                info["market"] = "æœªçŸ¥"  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æ¨æ–­
                info["list_date"] = "æœªçŸ¥"  # å¯ä»¥é€šè¿‡å…¶ä»–APIè·å–

                return info
            else:
                logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] è¿”å›ç©ºæ•°æ®: {symbol}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "akshare"}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] AKShareè·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": "akshare",
                "error": str(e),
            }

    def _get_baostock_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨BaoStockè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            import baostock as bs

            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if symbol.startswith("6"):
                bs_code = f"sh.{symbol}"
            else:
                bs_code = f"sz.{symbol}"

            # ç™»å½•BaoStock
            lg = bs.login()
            if lg.error_code != "0":
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

            # æŸ¥è¯¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            rs = bs.query_stock_basic(code=bs_code)
            if rs.error_code != "0":
                bs.logout()
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockæŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

            # è§£æç»“æœ
            data_list = []
            while (rs.error_code == "0") & rs.next():
                data_list.append(rs.get_row_data())

            # ç™»å‡º
            bs.logout()

            if data_list:
                # BaoStockè¿”å›æ ¼å¼: [code, code_name, ipoDate, outDate, type, status]
                info = {"symbol": symbol, "source": "baostock"}
                info["name"] = data_list[0][1]  # code_name
                info["area"] = "æœªçŸ¥"  # BaoStockæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info["industry"] = "æœªçŸ¥"  # BaoStockæ²¡æœ‰è¡Œä¸šä¿¡æ¯
                info["market"] = "æœªçŸ¥"  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æ¨æ–­
                info["list_date"] = data_list[0][2]  # ipoDate

                return info
            else:
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockè·å–å¤±è´¥: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": "baostock",
                "error": str(e),
            }

    def _parse_stock_info_string(self, info_str: str, symbol: str) -> Dict:
        """è§£æè‚¡ç¥¨ä¿¡æ¯å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        try:
            info = {"symbol": symbol, "source": self.current_source.value}
            lines = info_str.split("\n")

            for line in lines:
                if ":" in line:
                    key, value = line.split(":", 1)
                    key = key.strip()
                    value = value.strip()

                    if "è‚¡ç¥¨åç§°" in key:
                        info["name"] = value
                    elif "æ‰€å±è¡Œä¸š" in key:
                        info["industry"] = value
                    elif "æ‰€å±åœ°åŒº" in key:
                        info["area"] = value
                    elif "ä¸Šå¸‚å¸‚åœº" in key:
                        info["market"] = value
                    elif "ä¸Šå¸‚æ—¥æœŸ" in key:
                        info["list_date"] = value

            return info

        except Exception as e:
            logger.error(f"âš ï¸ è§£æè‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": self.current_source.value,
            }

    # ==================== åŸºæœ¬é¢æ•°æ®è·å–æ–¹æ³• ====================

    def _get_mongodb_fundamentals(self, symbol: str) -> str:
        """ä» MongoDB è·å–è´¢åŠ¡æ•°æ®"""
        logger.debug(f"ğŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            import pandas as pd

            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä» MongoDB è·å–è´¢åŠ¡æ•°æ®
            financial_data = adapter.get_financial_data(symbol)

            # æ£€æŸ¥æ•°æ®ç±»å‹å’Œå†…å®¹
            if financial_data is not None:
                # å¦‚æœæ˜¯ DataFrameï¼Œè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                if isinstance(financial_data, pd.DataFrame):
                    if not financial_data.empty:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)"
                        )
                        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                        financial_dict_list = financial_data.to_dict("records")
                        # æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š
                        return self._format_financial_data(symbol, financial_dict_list)
                    else:
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] è´¢åŠ¡æ•°æ®ä¸ºç©º: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                        )
                        return self._try_fallback_fundamentals(symbol)
                # å¦‚æœæ˜¯åˆ—è¡¨
                elif isinstance(financial_data, list) and len(financial_data) > 0:
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)"
                    )
                    return self._format_financial_data(symbol, financial_data)
                # å¦‚æœæ˜¯å•ä¸ªå­—å…¸ï¼ˆè¿™æ˜¯MongoDBå®é™…è¿”å›çš„æ ¼å¼ï¼‰
                elif isinstance(financial_data, dict):
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} (å•æ¡è®°å½•)"
                    )
                    # å°†å•ä¸ªå­—å…¸åŒ…è£…æˆåˆ—è¡¨
                    financial_dict_list = [financial_data]
                    return self._format_financial_data(symbol, financial_dict_list)
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                    )
                    return self._try_fallback_fundamentals(symbol)
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                )
                # MongoDB æ²¡æœ‰æ•°æ®ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}", exc_info=True
            )
            # MongoDB å¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_fundamentals(symbol)

    def _get_tushare_fundamentals(self, symbol: str) -> str:
        """ä» Tushare è·å–åŸºæœ¬é¢æ•°æ®"""
        try:
            from .providers.china.tushare import get_tushare_provider

            logger.info(f"ğŸ“Š [Tushare] å¼€å§‹è·å–åŸºæœ¬é¢æ•°æ®: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨ï¼Œæœªåˆå§‹åŒ–æˆ–æ—  Token")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸçš„æ¯æ—¥åŸºç¡€æ•°æ®
            # å¦‚æœä»Šå¤©æ²¡æœ‰äº¤æ˜“æ—¥æ•°æ®ï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
            from datetime import datetime, timedelta

            trade_date = datetime.now().strftime("%Y-%m-%d")
            logger.info(f"ğŸ“Š [Tushare] åˆå§‹æŸ¥è¯¢æ—¥æœŸ: {trade_date}")

            # è°ƒç”¨ get_daily_basic è·å– PEã€PBã€PS ç­‰æŒ‡æ ‡
            import asyncio

            try:
                # åˆ›å»ºæˆ–è·å–äº‹ä»¶å¾ªç¯
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_closed():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                # é¦–å…ˆå°è¯•ä»Šå¤©çš„æ•°æ®
                df = loop.run_until_complete(provider.get_daily_basic(trade_date))

                # å¦‚æœä»Šå¤©æ²¡æœ‰æ•°æ®ï¼Œå°è¯•æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
                if df is None or df.empty:
                    logger.info(
                        f"ğŸ“Š [Tushare] {trade_date} æ— æ•°æ®ï¼ŒæŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥..."
                    )
                    for delta in range(1, 10):  # æœ€å¤šå›æº¯ 10 å¤©
                        check_date = (datetime.now() - timedelta(days=delta)).strftime(
                            "%Y-%m-%d"
                        )
                        logger.info(f"ğŸ“Š [Tushare] å°è¯•æ—¥æœŸ: {check_date}")
                        df = loop.run_until_complete(
                            provider.get_daily_basic(check_date)
                        )
                        if df is not None and not df.empty:
                            trade_date = check_date
                            logger.info(f"âœ… [Tushare] æ‰¾åˆ°äº¤æ˜“æ—¥æ•°æ®: {trade_date}")
                            break

                if df is None or df.empty:
                    logger.warning(
                        f"âš ï¸ [Tushare] daily_basic è¿”å›ç©ºæ•°æ®ï¼ˆå°è¯•äº†æœ€è¿‘ 10 å¤©ï¼‰"
                    )
                    return f"âš ï¸ Tushare daily_basic æ¥å£æœªè¿”å›æ•°æ®ï¼Œå¯èƒ½éœ€è¦æ›´é«˜æƒé™çš„ Token"

                logger.info(f"âœ… [Tushare] daily_basic è¿”å› {len(df)} æ¡è®°å½•")

                # æŸ¥æ‰¾æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
                # éœ€è¦å°†ä»£ç è½¬æ¢ä¸º Tushare æ ¼å¼ (å¦‚ 605589 -> 605589.SH)
                ts_code = self._convert_to_tushare_code(symbol)
                logger.info(f"ğŸ” [Tushare] æŸ¥è¯¢ä»£ç : {ts_code}")

                stock_data = df[df["ts_code"] == ts_code]

                if stock_data.empty:
                    logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} ({ts_code}) çš„æ•°æ®")
                    # å°è¯•ç”¨åŸå§‹ä»£ç æŸ¥è¯¢
                    stock_data = df[df["ts_code"] == symbol]
                    if stock_data.empty:
                        return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„åŸºæœ¬é¢æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æˆ–æ•°æ®æºæƒé™"

                # è·å–ç¬¬ä¸€è¡Œæ•°æ®
                row = stock_data.iloc[0]

                # æ ¼å¼åŒ–è¾“å‡º
                report = f"ğŸ“Š {symbol} åŸºæœ¬é¢æ•°æ®ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"
                report += f"ğŸ“… æ•°æ®æ—¥æœŸ: {trade_date}\n"
                report += f"ğŸ“ˆ æ•°æ®æ¥æº: Tushare daily_basic æ¥å£\n\n"

                # ä¼°å€¼æŒ‡æ ‡
                report += "ğŸ’° ä¼°å€¼æŒ‡æ ‡:\n"

                pe = row.get("pe")
                if pe is not None and pd.notna(pe) and pe != 0:
                    report += f"   å¸‚ç›ˆç‡(PE): {pe:.2f}\n"

                pb = row.get("pb")
                if pb is not None and pd.notna(pb) and pb != 0:
                    report += f"   å¸‚å‡€ç‡(PB): {pb:.2f}\n"

                pe_ttm = row.get("pe_ttm")
                if pe_ttm is not None and pd.notna(pe_ttm) and pe_ttm != 0:
                    report += f"   å¸‚ç›ˆç‡TTM(PE_TTM): {pe_ttm:.2f}\n"

                pb_mrq = row.get("pb_mrq")
                if pb_mrq is not None and pd.notna(pb_mrq) and pb_mrq != 0:
                    report += f"   å¸‚å‡€ç‡MRQ(PB_MHQ): {pb_mrq:.2f}\n"

                total_mv = row.get("total_mv")
                if total_mv is not None and pd.notna(total_mv):
                    report += f"   æ€»å¸‚å€¼: {total_mv:.2f}äº¿å…ƒ\n"

                circ_mv = row.get("circ_mv")
                if circ_mv is not None and pd.notna(circ_mv):
                    report += f"   æµé€šå¸‚å€¼: {circ_mv:.2f}äº¿å…ƒ\n"

                turnover_rate = row.get("turnover_rate")
                if turnover_rate is not None and pd.notna(turnover_rate):
                    report += f"   æ¢æ‰‹ç‡: {turnover_rate:.2f}%\n"

                volume_ratio = row.get("volume_ratio")
                if volume_ratio is not None and pd.notna(volume_ratio):
                    report += f"   é‡æ¯”: {volume_ratio:.2f}\n"

                logger.info(f"âœ… [Tushare] æˆåŠŸè·å–åŸºæœ¬é¢æ•°æ®: {symbol}")
                logger.info(f"   PE={pe}, PB={pb}, PE_TTM={pe_ttm}")
                return report

            except asyncio.TimeoutError:
                logger.error(f"âŒ [Tushare] async æ“ä½œè¶…æ—¶")
                return f"âŒ Tushare æ•°æ®è·å–è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            except Exception as async_err:
                logger.error(f"âŒ [Tushare] async æ“ä½œå¤±è´¥: {async_err}")
                return f"âŒ Tushare æ•°æ®è·å–å¤±è´¥: {async_err}"

        except ImportError as e:
            logger.error(f"âŒ [Tushare] å¯¼å…¥å¤±è´¥: {e}")
            return f"âŒ Tushare æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…: {e}"
        except Exception as e:
            logger.error(f"âŒ [Tushare] è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ è·å– {symbol} åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}"

    def _convert_to_tushare_code(self, symbol: str) -> str:
        """
        å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸º Tushare æ ¼å¼

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¦‚ 605589, 605589.SH, 000001.SZ)

        Returns:
            str: Tushare æ ¼å¼ä»£ç  (å¦‚ 605589.SH)
        """
        # ç§»é™¤å·²æœ‰çš„åç¼€
        symbol = str(symbol).strip().upper()
        symbol = symbol.replace(".SH", "").replace(".SZ", "").replace(".BJ", "")

        # æ ¹æ®ä»£ç å‰ç¼€åˆ¤æ–­äº¤æ˜“æ‰€
        if symbol.startswith(("60", "68", "90")):
            return f"{symbol}.SH"  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
        elif symbol.startswith(("00", "30", "20")):
            return f"{symbol}.SZ"  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
        elif symbol.startswith(("8", "4")):
            return f"{symbol}.BJ"  # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€
        else:
            # æ— æ³•è¯†åˆ«çš„ä»£ç ï¼Œè¿”å›åŸå§‹ä»£ç 
            logger.warning(f"âš ï¸ [Tushare] æ— æ³•è¯†åˆ« {symbol} çš„äº¤æ˜“æ‰€ï¼Œè¿”å›åŸå§‹ä»£ç ")
            return symbol

    def _get_tushare_financial_indicators(self, symbol: str) -> str:
        """ä» Tushare è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®"""
        try:
            from .providers.china.tushare import get_tushare_provider
            import asyncio

            logger.info(f"ğŸ“Š [Tushare] å¼€å§‹è·å–è´¢åŠ¡æŒ‡æ ‡: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # åˆ›å»ºäº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # è°ƒç”¨ TushareProvider çš„è´¢åŠ¡æŒ‡æ ‡æ–¹æ³•
            result = loop.run_until_complete(
                provider.get_financial_indicators_only(symbol, limit=1)
            )

            if not result or not result.get("financial_indicators"):
                logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®")
                return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®"

            indicators = result["financial_indicators"][0]

            # æ ¼å¼åŒ–è¾“å‡º
            report = f"\nğŸ“Š {symbol} è´¢åŠ¡æŒ‡æ ‡ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"

            # ç›ˆåˆ©èƒ½åŠ›
            report += "ğŸ’¹ ç›ˆåˆ©èƒ½åŠ›:\n"
            roe = indicators.get("roe")
            if roe is not None and pd.notna(roe):
                report += f"   ROE(å‡€èµ„äº§æ”¶ç›Šç‡): {roe:.2f}%\n"

            roa = indicators.get("roa")
            if roa is not None and pd.notna(roa):
                report += f"   ROA(æ€»èµ„äº§æ”¶ç›Šç‡): {roa:.2f}%\n"

            gross_profit_margin = indicators.get("grossprofit_margin")
            if gross_profit_margin is not None and pd.notna(gross_profit_margin):
                report += f"   æ¯›åˆ©ç‡: {gross_profit_margin:.2f}%\n"

            net_profit_margin = indicators.get("netprofit_margin")
            if net_profit_margin is not None and pd.notna(net_profit_margin):
                report += f"   å‡€åˆ©ç‡: {net_profit_margin:.2f}%\n"

            # å¿å€ºèƒ½åŠ›
            report += "\nğŸ¦ å¿å€ºèƒ½åŠ›:\n"
            debt_to_assets = indicators.get("debt_to_assets")
            if debt_to_assets is not None and pd.notna(debt_to_assets):
                report += f"   èµ„äº§è´Ÿå€ºç‡: {debt_to_assets:.2f}%\n"

            current_ratio = indicators.get("current_ratio")
            if current_ratio is not None and pd.notna(current_ratio):
                report += f"   æµåŠ¨æ¯”ç‡: {current_ratio:.2f}\n"

            quick_ratio = indicators.get("quick_ratio")
            if quick_ratio is not None and pd.notna(quick_ratio):
                report += f"   é€ŸåŠ¨æ¯”ç‡: {quick_ratio:.2f}\n"

            # è¥è¿èƒ½åŠ›
            report += "\nğŸ”„ è¥è¿èƒ½åŠ›:\n"
            inv_turn = indicators.get("inv_turn")
            if inv_turn is not None and pd.notna(inv_turn):
                report += f"   å­˜è´§å‘¨è½¬ç‡: {inv_turn:.2f}æ¬¡\n"

            ar_turn = indicators.get("ar_turn")
            if ar_turn is not None and pd.notna(ar_turn):
                report += f"   åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡: {ar_turn:.2f}æ¬¡\n"

            ca_turn = indicators.get("ca_turn")
            if ca_turn is not None and pd.notna(ca_turn):
                report += f"   æµåŠ¨èµ„äº§å‘¨è½¬ç‡: {ca_turn:.2f}æ¬¡\n"

            # æˆé•¿èƒ½åŠ›
            report += "\nğŸ“ˆ æˆé•¿èƒ½åŠ›:\n"
            or_ratio = indicators.get("or_ratio")
            if or_ratio is not None and pd.notna(or_ratio):
                report += f"   è¥ä¸šæ”¶å…¥å¢é•¿ç‡: {or_ratio:.2f}%\n"

            op_profit_growth = indicators.get("op_profit_growth_rate_yoy")
            if op_profit_growth is not None and pd.notna(op_profit_growth):
                report += f"   è¥ä¸šåˆ©æ¶¦å¢é•¿ç‡: {op_profit_growth:.2f}%\n"

            logger.info(f"âœ… [Tushare] æˆåŠŸè·å–è´¢åŠ¡æŒ‡æ ‡: {symbol}")
            return report

        except Exception as e:
            logger.error(f"âŒ [Tushare] è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ è·å– {symbol} è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}"

    def _get_tushare_financial_reports(self, symbol: str) -> str:
        """ä» Tushare è·å–å®Œæ•´è´¢åŠ¡æŠ¥è¡¨"""
        try:
            from .providers.china.tushare import get_tushare_provider
            import asyncio

            logger.info(f"ğŸ“Š [Tushare] å¼€å§‹è·å–è´¢åŠ¡æŠ¥è¡¨: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # åˆ›å»ºäº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # è°ƒç”¨ TushareProvider çš„è´¢åŠ¡æ•°æ®æ–¹æ³•
            result = loop.run_until_complete(
                provider.get_financial_data(symbol, report_type="quarterly", limit=1)
            )

            if not result:
                logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®")
                return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®"

            # æ ¼å¼åŒ–è¾“å‡º
            report = f"\nğŸ“Š {symbol} è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"

            # åˆ©æ¶¦è¡¨æ•°æ®
            income_data = result.get("income_statement")
            if income_data and len(income_data) > 0:
                report += "ğŸ’° åˆ©æ¶¦è¡¨:\n"
                latest_income = income_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_income.get('end_date', 'æœªçŸ¥')}\n"
                report += (
                    f"   è¥ä¸šæ€»æ”¶å…¥: {latest_income.get('total_revenue', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   è¥ä¸šæ”¶å…¥: {latest_income.get('revenue', 0):,.2f}ä¸‡å…ƒ\n"
                report += (
                    f"   è¥ä¸šæˆæœ¬: {latest_income.get('operating_cost', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   å‡€åˆ©æ¶¦: {latest_income.get('n_income', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æ‰£éå‡€åˆ©æ¶¦: {latest_income.get('n_income_attr_p', 0):,.2f}ä¸‡å…ƒ\n"

            # èµ„äº§è´Ÿå€ºè¡¨æ•°æ®
            balance_data = result.get("balance_sheet")
            if balance_data and len(balance_data) > 0:
                report += "\nğŸ“¦ èµ„äº§è´Ÿå€ºè¡¨:\n"
                latest_balance = balance_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_balance.get('end_date', 'æœªçŸ¥')}\n"
                report += (
                    f"   æ€»èµ„äº§: {latest_balance.get('total_assets', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   æ€»è´Ÿå€º: {latest_balance.get('total_liab', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   è‚¡ä¸œæƒç›Š: {latest_balance.get('total_hldr_eqy_exc_min_int', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æµåŠ¨èµ„äº§: {latest_balance.get('total_cur_assets', 0):,.2f}ä¸‡å…ƒ\n"
                report += (
                    f"   æµåŠ¨è´Ÿå€º: {latest_balance.get('total_cur_liab', 0):,.2f}ä¸‡å…ƒ\n"
                )

            # ç°é‡‘æµé‡è¡¨æ•°æ®
            cashflow_data = result.get("cashflow_statement")
            if cashflow_data and len(cashflow_data) > 0:
                report += "\nğŸ’µ ç°é‡‘æµé‡è¡¨:\n"
                latest_cashflow = cashflow_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_cashflow.get('end_date', 'æœªçŸ¥')}\n"
                report += f"   ç»è¥æ´»åŠ¨ç°é‡‘æµ: {latest_cashflow.get('n_cashflow_act', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æŠ•èµ„æ´»åŠ¨ç°é‡‘æµ: {latest_cashflow.get('n_cashflow_inv_act', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   ç­¹èµ„æ´»åŠ¨ç°é‡‘æµ: {latest_cashflow.get('n_cash_flows_fnc_act', 0):,.2f}ä¸‡å…ƒ\n"

            logger.info(f"âœ… [Tushare] æˆåŠŸè·å–è´¢åŠ¡æŠ¥è¡¨: {symbol}")
            return report

        except Exception as e:
            logger.error(f"âŒ [Tushare] è·å–è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ è·å– {symbol} è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {e}"

    def _get_akshare_fundamentals(self, symbol: str) -> str:
        """ä» AKShare ç”ŸæˆåŸºæœ¬é¢åˆ†æ"""
        logger.debug(f"ğŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            # AKShare æ²¡æœ‰ç›´æ¥çš„åŸºæœ¬é¢æ•°æ®æ¥å£ï¼Œä½¿ç”¨ç”Ÿæˆåˆ†æ
            logger.info(f"ğŸ“Š [æ•°æ®æ¥æº: AKShare-ç”Ÿæˆåˆ†æ] ç”ŸæˆåŸºæœ¬é¢åˆ†æ: {symbol}")
            return self._generate_fundamentals_analysis(symbol)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShareå¼‚å¸¸] ç”ŸæˆåŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}"

    def _get_valuation_indicators(self, symbol: str) -> Dict:
        """ä»stock_basic_infoé›†åˆè·å–ä¼°å€¼æŒ‡æ ‡"""
        try:
            from tradingagents.config.database_manager import get_database_manager

            db_manager = get_database_manager()
            if not db_manager.is_mongodb_available():
                return {}

            client = db_manager.get_mongodb_client()
            db = client[db_manager.config.mongodb_config.database_name]

            # ä»stock_basic_infoé›†åˆè·å–ä¼°å€¼æŒ‡æ ‡
            collection = db["stock_basic_info"]
            result = collection.find_one({"ts_code": symbol})

            if result:
                return {
                    "pe": result.get("pe"),
                    "pb": result.get("pb"),
                    "pe_ttm": result.get("pe_ttm"),
                    "total_mv": result.get("total_mv"),
                    "circ_mv": result.get("circ_mv"),
                }
            return {}

        except Exception as e:
            logger.error(f"è·å–{symbol}ä¼°å€¼æŒ‡æ ‡å¤±è´¥: {e}")
            return {}

    def _format_financial_data(self, symbol: str, financial_data: List[Dict]) -> str:
        """æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š"""
        try:
            if not financial_data or len(financial_data) == 0:
                return f"âŒ æœªæ‰¾åˆ°{symbol}çš„è´¢åŠ¡æ•°æ®"

            # è·å–æœ€æ–°çš„è´¢åŠ¡æ•°æ®
            latest = financial_data[0]

            # æ„å»ºæŠ¥å‘Š
            report = f"ğŸ“Š {symbol} åŸºæœ¬é¢æ•°æ®ï¼ˆæ¥è‡ªMongoDBï¼‰\n\n"

            # åŸºæœ¬ä¿¡æ¯
            report += f"ğŸ“… æŠ¥å‘ŠæœŸ: {latest.get('report_period', latest.get('end_date', 'æœªçŸ¥'))}\n"
            report += f"ğŸ“ˆ æ•°æ®æ¥æº: MongoDBè´¢åŠ¡æ•°æ®åº“\n\n"

            # è´¢åŠ¡æŒ‡æ ‡
            report += "ğŸ’° è´¢åŠ¡æŒ‡æ ‡:\n"
            revenue = latest.get("revenue") or latest.get("total_revenue")
            if revenue is not None:
                report += f"   è¥ä¸šæ€»æ”¶å…¥: {revenue:,.2f}\n"

            net_profit = latest.get("net_profit") or latest.get("net_income")
            if net_profit is not None:
                report += f"   å‡€åˆ©æ¶¦: {net_profit:,.2f}\n"

            total_assets = latest.get("total_assets")
            if total_assets is not None:
                report += f"   æ€»èµ„äº§: {total_assets:,.2f}\n"

            total_liab = latest.get("total_liab")
            if total_liab is not None:
                report += f"   æ€»è´Ÿå€º: {total_liab:,.2f}\n"

            total_equity = latest.get("total_equity")
            if total_equity is not None:
                report += f"   è‚¡ä¸œæƒç›Š: {total_equity:,.2f}\n"

            # ä¼°å€¼æŒ‡æ ‡ - ä»stock_basic_infoé›†åˆè·å–
            report += "\nğŸ“Š ä¼°å€¼æŒ‡æ ‡:\n"
            valuation_data = self._get_valuation_indicators(symbol)
            if valuation_data:
                pe = valuation_data.get("pe")
                if pe is not None:
                    report += f"   å¸‚ç›ˆç‡(PE): {pe:.2f}\n"

                pb = valuation_data.get("pb")
                if pb is not None:
                    report += f"   å¸‚å‡€ç‡(PB): {pb:.2f}\n"

                pe_ttm = valuation_data.get("pe_ttm")
                if pe_ttm is not None:
                    report += f"   å¸‚ç›ˆç‡TTM(PE_TTM): {pe_ttm:.2f}\n"

                total_mv = valuation_data.get("total_mv")
                if total_mv is not None:
                    report += f"   æ€»å¸‚å€¼: {total_mv:.2f}äº¿å…ƒ\n"

                circ_mv = valuation_data.get("circ_mv")
                if circ_mv is not None:
                    report += f"   æµé€šå¸‚å€¼: {circ_mv:.2f}äº¿å…ƒ\n"
            else:
                # å¦‚æœæ— æ³•ä»stock_basic_infoè·å–ï¼Œå°è¯•ä»è´¢åŠ¡æ•°æ®è®¡ç®—
                pe = latest.get("pe")
                if pe is not None:
                    report += f"   å¸‚ç›ˆç‡(PE): {pe:.2f}\n"

                pb = latest.get("pb")
                if pb is not None:
                    report += f"   å¸‚å‡€ç‡(PB): {pb:.2f}\n"

                ps = latest.get("ps")
                if ps is not None:
                    report += f"   å¸‚é”€ç‡(PS): {ps:.2f}\n"

            # ç›ˆåˆ©èƒ½åŠ›
            report += "\nğŸ’¹ ç›ˆåˆ©èƒ½åŠ›:\n"
            roe = latest.get("roe")
            if roe is not None:
                report += f"   å‡€èµ„äº§æ”¶ç›Šç‡(ROE): {roe:.2f}%\n"

            roa = latest.get("roa")
            if roa is not None:
                report += f"   æ€»èµ„äº§æ”¶ç›Šç‡(ROA): {roa:.2f}%\n"

            gross_margin = latest.get("gross_margin")
            if gross_margin is not None:
                report += f"   æ¯›åˆ©ç‡: {gross_margin:.2f}%\n"

            netprofit_margin = latest.get("netprofit_margin") or latest.get(
                "net_margin"
            )
            if netprofit_margin is not None:
                report += f"   å‡€åˆ©ç‡: {netprofit_margin:.2f}%\n"

            # ç°é‡‘æµ
            n_cashflow_act = latest.get("n_cashflow_act")
            if n_cashflow_act is not None:
                report += "\nğŸ’° ç°é‡‘æµ:\n"
                report += f"   ç»è¥æ´»åŠ¨ç°é‡‘æµ: {n_cashflow_act:,.2f}\n"

                n_cashflow_inv_act = latest.get("n_cashflow_inv_act")
                if n_cashflow_inv_act is not None:
                    report += f"   æŠ•èµ„æ´»åŠ¨ç°é‡‘æµ: {n_cashflow_inv_act:,.2f}\n"

                c_cash_equ_end_period = latest.get("c_cash_equ_end_period")
                if c_cash_equ_end_period is not None:
                    report += f"   æœŸæœ«ç°é‡‘åŠç­‰ä»·ç‰©: {c_cash_equ_end_period:,.2f}\n"

            report += f"\nğŸ“ å…±æœ‰ {len(financial_data)} æœŸè´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return f"âŒ æ ¼å¼åŒ–{symbol}è´¢åŠ¡æ•°æ®å¤±è´¥: {e}"

    def _generate_fundamentals_analysis(self, symbol: str) -> str:
        """ç”ŸæˆåŸºæœ¬çš„åŸºæœ¬é¢åˆ†æ"""
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = self.get_stock_info(symbol)

            report = f"ğŸ“Š {symbol} åŸºæœ¬é¢åˆ†æï¼ˆç”Ÿæˆï¼‰\n\n"
            report += f"ğŸ“ˆ è‚¡ç¥¨åç§°: {stock_info.get('name', 'æœªçŸ¥')}\n"
            report += f"ğŸ¢ æ‰€å±è¡Œä¸š: {stock_info.get('industry', 'æœªçŸ¥')}\n"
            report += f"ğŸ“ æ‰€å±åœ°åŒº: {stock_info.get('area', 'æœªçŸ¥')}\n"
            report += f"ğŸ“… ä¸Šå¸‚æ—¥æœŸ: {stock_info.get('list_date', 'æœªçŸ¥')}\n"
            report += f"ğŸ›ï¸ äº¤æ˜“æ‰€: {stock_info.get('exchange', 'æœªçŸ¥')}\n\n"

            report += "âš ï¸ æ³¨æ„: è¯¦ç»†è´¢åŠ¡æ•°æ®éœ€è¦ä»æ•°æ®æºè·å–\n"
            report += "ğŸ’¡ å»ºè®®: å¯ç”¨MongoDBç¼“å­˜ä»¥è·å–å®Œæ•´çš„è´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆåŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}"

    def _try_fallback_fundamentals(self, symbol: str) -> str:
        """åŸºæœ¬é¢æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–åŸºæœ¬é¢...")

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–åŸºæœ¬é¢: {source.value}")

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_fundamentals(symbol)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_fundamentals(symbol)
                    else:
                        continue

                    if result and "âŒ" not in result:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–åŸºæœ¬é¢: {source.value}"
                        )
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}è¿”å›é”™è¯¯ç»“æœ")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ
        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: ç”Ÿæˆåˆ†æ] æ‰€æœ‰æ•°æ®æºå¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ: {symbol}")
        return self._generate_fundamentals_analysis(symbol)

    def _get_mongodb_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»MongoDBè·å–æ–°é—»æ•°æ®"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä»MongoDBè·å–æ–°é—»æ•°æ®
            news_data = adapter.get_news_data(
                symbol, hours_back=hours_back, limit=limit
            )

            if news_data and len(news_data) > 0:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: MongoDB-æ–°é—»] æˆåŠŸè·å–: {symbol or 'å¸‚åœºæ–°é—»'} ({len(news_data)}æ¡)"
                )
                return news_data
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                )
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDB] è·å–æ–°é—»å¤±è´¥: {e}")
            return self._try_fallback_news(symbol, hours_back, limit)

    def _get_tushare_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»Tushareè·å–æ–°é—»æ•°æ®"""
        try:
            # Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: Tushare] Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: Tushare] è·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _get_akshare_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»AKShareè·å–æ–°é—»æ•°æ®"""
        try:
            # AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: AKShare] AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShare] è·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _try_fallback_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """æ–°é—»æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–æ–°é—»...")

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–æ–°é—»: {source.value}")

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_news(symbol, hours_back, limit)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_news(symbol, hours_back, limit)
                    else:
                        continue

                    if result and len(result) > 0:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–æ–°é—»: {source.value}"
                        )
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}æœªè¿”å›æ–°é—»")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        logger.warning(
            f"âš ï¸ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•è·å–æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}"
        )
        return []

    # ========== æ•°æ®è´¨é‡è¯„åˆ†å’ŒéªŒè¯åŠŸèƒ½ ==========

    def get_data_quality_score(self, symbol: str, data: Dict[str, Any]) -> float:
        """
        è·å–æ•°æ®è´¨é‡è¯„åˆ† (0-100)

        è¯„åˆ†ç»´åº¦:
        - æ•°æ®å®Œæ•´æ€§ (30åˆ†): å¿…éœ€å­—æ®µæ˜¯å¦é½å…¨
        - æ•°æ®ä¸€è‡´æ€§ (30åˆ†): æŒ‡æ ‡é—´é€»è¾‘å…³ç³»æ˜¯å¦æ­£ç¡®
        - æ•°æ®æ—¶æ•ˆæ€§ (20åˆ†): æ•°æ®æ˜¯å¦æ˜¯æœ€æ–°çš„
        - æ•°æ®æºå¯é æ€§ (20åˆ†): æ•°æ®æºçš„å¯ä¿¡åº¦

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: å¾…è¯„åˆ†çš„æ•°æ®å­—å…¸

        Returns:
            float: è´¨é‡è¯„åˆ† (0-100)
        """
        score = 0.0
        max_score = 100.0

        # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ (30åˆ†)
        completeness_score = self._check_data_completeness(data)
        score += completeness_score * 0.3

        # 2. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ (30åˆ†)
        consistency_score = self._check_data_consistency(symbol, data)
        score += consistency_score * 0.3

        # 3. æ•°æ®æ—¶æ•ˆæ€§æ£€æŸ¥ (20åˆ†)
        timeliness_score = self._check_data_timeliness(data)
        score += timeliness_score * 0.2

        # 4. æ•°æ®æºå¯é æ€§ (20åˆ†)
        reliability_score = self._check_data_source_reliability()
        score += reliability_score * 0.2

        logger.debug(
            f"ğŸ“Š [æ•°æ®è´¨é‡è¯„åˆ†] {symbol}: {score:.1f}/100 "
            f"(å®Œæ•´:{completeness_score:.1f} ä¸€è‡´:{consistency_score:.1f} "
            f"æ—¶æ•ˆ:{timeliness_score:.1f} å¯é :{reliability_score:.1f})"
        )

        return min(score, max_score)

    def _check_data_completeness(self, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        required_fields = {
            # åŸºç¡€ä»·æ ¼æ•°æ®
            "current_price",
            "open",
            "high",
            "low",
            "volume",
            # åŸºæœ¬é¢æ•°æ®
            "market_cap",
            "PE",
            "PB",
        }

        optional_fields = {
            "MA5",
            "MA10",
            "MA20",
            "MA60",
            "RSI",
            "MACD",
            "turnover_rate",
            "ROE",
            "ROA",
        }

        score = 0.0
        total_weight = 1.0

        # å¿…éœ€å­—æ®µ (æƒé‡0.7)
        present_required = sum(
            1 for f in required_fields if f in data and data[f] is not None
        )
        if required_fields:
            required_score = (present_required / len(required_fields)) * 70
            score += required_score * 0.7

        # å¯é€‰å­—æ®µ (æƒé‡0.3)
        present_optional = sum(
            1 for f in optional_fields if f in data and data[f] is not None
        )
        if optional_fields:
            optional_score = (present_optional / len(optional_fields)) * 30
            score += optional_score * 0.3

        return score

    def _check_data_consistency(self, symbol: str, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        score = 100.0
        issues = []

        # æ£€æŸ¥1: high >= low
        if "high" in data and "low" in data:
            if data["high"] < data["low"]:
                issues.append("æœ€é«˜ä»· < æœ€ä½ä»·")
                score -= 20

        # æ£€æŸ¥2: current_price åœ¨ high å’Œ low ä¹‹é—´
        if all(k in data for k in ["current_price", "high", "low"]):
            price = data["current_price"]
            if not (data["low"] <= price <= data["high"]):
                issues.append(f"å½“å‰ä»·{price}ä¸åœ¨æœ€é«˜æœ€ä½ä»·èŒƒå›´å†…")
                score -= 15

        # æ£€æŸ¥3: å¸‚å€¼è®¡ç®—ä¸€è‡´æ€§
        if all(k in data for k in ["market_cap", "share_count", "current_price"]):
            try:
                market_cap = data["market_cap"]
                share_count = data["share_count"]
                price = data["current_price"]

                calculated_cap = (share_count * price) / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
                if market_cap > 0:
                    diff_pct = abs((calculated_cap - market_cap) / market_cap) * 100
                    if diff_pct > 15:  # è¶…è¿‡15%è¯¯å·®
                        issues.append(f"å¸‚å€¼è®¡ç®—ä¸ä¸€è‡´ (å·®å¼‚{diff_pct:.1f}%)")
                        score -= 10
            except (ValueError, TypeError, ZeroDivisionError):
                pass

        # æ£€æŸ¥4: PSæ¯”ç‡ä¸€è‡´æ€§
        if all(k in data for k in ["market_cap", "revenue", "PS"]):
            try:
                calculated_ps = data["market_cap"] / data["revenue"]
                if data["revenue"] > 0:
                    diff_pct = abs((calculated_ps - data["PS"]) / data["PS"]) * 100
                    if diff_pct > 10:  # è¶…è¿‡10%è¯¯å·®
                        issues.append(f"PSæ¯”ç‡è®¡ç®—ä¸ä¸€è‡´ (å·®å¼‚{diff_pct:.1f}%)")
                        score -= 15
            except (ValueError, TypeError, ZeroDivisionError):
                pass

        # æ£€æŸ¥5: MAåºåˆ—å…³ç³»
        if all(k in data for k in ["MA5", "MA10", "MA20"]):
            ma5, ma10, ma20 = data["MA5"], data["MA10"], data["MA20"]
            # ä¸Šå‡è¶‹åŠ¿: MA5 > MA10 > MA20
            # ä¸‹é™è¶‹åŠ¿: MA5 < MA10 < MA20
            # å¦‚æœMA5åœ¨MA10å’ŒMA20ä¹‹é—´,å¯èƒ½æœ‰é—®é¢˜
            if not (ma10 < ma5 < ma20 or ma20 < ma5 < ma10):
                issues.append(f"MAåºåˆ—å…³ç³»å¼‚å¸¸: MA5={ma5}, MA10={ma10}, MA20={ma20}")
                score -= 5

        if issues:
            logger.debug(f"ğŸ“Š [æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥] {symbol}: {', '.join(issues)}")

        return max(score, 0.0)

    def _check_data_timeliness(self, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®æ—¶æ•ˆæ€§"""
        score = 100.0

        # æ£€æŸ¥æ•°æ®ä¸­çš„æ—¥æœŸ
        data_date = data.get("date") or data.get("trade_date") or data.get("timestamp")
        if data_date:
            try:
                from datetime import datetime

                # å°è¯•è§£ææ—¥æœŸ
                if isinstance(data_date, str):
                    data_date = datetime.strptime(data_date.split()[0], "%Y-%m-%d")
                elif isinstance(data_date, (int, float)):
                    # å‡è®¾æ˜¯Unixæ—¶é—´æˆ³
                    data_date = datetime.fromtimestamp(data_date)

                if data_date:
                    now = datetime.now()
                    days_old = (now - data_date).days

                    # æ•°æ®è¶Šæ–°,åˆ†æ•°è¶Šé«˜
                    if days_old <= 1:
                        score = 100
                    elif days_old <= 7:
                        score = 80
                    elif days_old <= 30:
                        score = 60
                    else:
                        score = 40
            except Exception as e:
                logger.debug(f"æ—¥æœŸè§£æå¤±è´¥: {e}")
                score = 50  # æ— æ³•åˆ¤æ–­,ç»™ä¸­ç­‰åˆ†

        return score

    def _check_data_source_reliability(self) -> float:
        """æ£€æŸ¥æ•°æ®æºå¯é æ€§"""
        # æ•°æ®æºå¯é æ€§è¯„åˆ†
        reliability_scores = {
            ChinaDataSource.MONGODB: 95,  # ç¼“å­˜æ•°æ®,æœ€å¯é 
            ChinaDataSource.TUSHARE: 90,  # å®˜æ–¹æ•°æ®,é«˜è´¨é‡
            ChinaDataSource.BAOSTOCK: 75,  # å…è´¹ä½†ç¨³å®š
            ChinaDataSource.AKSHARE: 70,  # å¤šæºèšåˆ,è´¨é‡æ³¢åŠ¨
        }

        score = reliability_scores.get(self.current_source, 60)
        return float(score)

    def get_best_source_for_metric(self, metric: str) -> str:
        """
        è·å–æŒ‡å®šæŒ‡æ ‡çš„æœ€ä½³æ•°æ®æº

        é‡è¦ä¿®æ­£:
        - å®æ—¶è¡Œæƒ…æŒ‡æ ‡ä¼˜å…ˆä½¿ç”¨ AkShare (çœŸæ­£å®æ—¶)
        - åŸºæœ¬é¢æŒ‡æ ‡ä¼˜å…ˆä½¿ç”¨ Tushare (æœ€å‡†ç¡®)
        - æŠ€æœ¯æŒ‡æ ‡åŸºäºå†å²æ•°æ®, Tushare æ›´å¯é 

        Args:
            metric: æŒ‡æ ‡åç§°,å¦‚ 'PE', 'PB', 'PS', 'MA5', 'RSI', 'volume'

        Returns:
            str: æ¨èçš„æ•°æ®æºåç§°
        """
        # åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´ (éœ€è¦å®æ—¶æ•°æ®)
        is_trading_hours = self._is_trading_hours()

        # å®æ—¶è¡Œæƒ…æŒ‡æ ‡é›†åˆ
        realtime_metrics = {
            "current_price",
            "open",
            "high",
            "low",
            "volume",
            "turnover_rate",
        }

        # ä¸åŒæ•°æ®æºçš„ç‰¹é•¿
        source_specialties = {
            # åŸºæœ¬é¢æŒ‡æ ‡ - Tushareæœ€å‡†ç¡®
            "PE": ChinaDataSource.TUSHARE,
            "PB": ChinaDataSource.TUSHARE,
            "PS": ChinaDataSource.TUSHARE,
            "ROE": ChinaDataSource.TUSHARE,
            "ROA": ChinaDataSource.TUSHARE,
            "market_cap": ChinaDataSource.TUSHARE,
            "revenue": ChinaDataSource.TUSHARE,
            "total_assets": ChinaDataSource.TUSHARE,
            "net_profit": ChinaDataSource.TUSHARE,
            # æŠ€æœ¯æŒ‡æ ‡ - åŸºäºå†å²æ•°æ®,Tushareæ›´å¯é 
            "MA5": ChinaDataSource.TUSHARE,
            "MA10": ChinaDataSource.TUSHARE,
            "MA20": ChinaDataSource.TUSHARE,
            "MA60": ChinaDataSource.TUSHARE,
            "RSI": ChinaDataSource.TUSHARE,
            "RSI6": ChinaDataSource.TUSHARE,
            "RSI12": ChinaDataSource.TUSHARE,
            "MACD": ChinaDataSource.TUSHARE,
            "BOLL": ChinaDataSource.TUSHARE,
            "BOLL_UPPER": ChinaDataSource.TUSHARE,
            "BOLL_LOWER": ChinaDataSource.TUSHARE,
            "BOLL_MIDDLE": ChinaDataSource.TUSHARE,
            # å®æ—¶è¡Œæƒ… - æ ¹æ®æ—¶é—´é€‰æ‹©æ•°æ®æº
            # ç›˜ä¸­: AkShare (çœŸæ­£å®æ—¶,ç§’çº§æ›´æ–°)
            # ç›˜å: Tushare (å®Œæ•´æ•°æ®,ç»è¿‡æ¸…æ´—)
            "current_price": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "open": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "high": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "low": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "volume": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "turnover_rate": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            # é»˜è®¤
            "default": ChinaDataSource.TUSHARE,
        }

        best_source = source_specialties.get(metric, source_specialties["default"])

        # å¦‚æœæ˜¯å®æ—¶æŒ‡æ ‡ä¸”åœ¨ç›˜ä¸­,è®°å½•æ—¥å¿—
        if metric in realtime_metrics and is_trading_hours:
            logger.info(
                f"ğŸ“Š [ç›˜ä¸­å®æ—¶] {metric} ä½¿ç”¨ {best_source.value} "
                f"(åŸå› : {'ç›˜ä¸­éœ€è¦å®æ—¶æ•°æ®' if best_source == ChinaDataSource.AKSHARE else 'ç›˜åä½¿ç”¨å®Œæ•´æ•°æ®'})"
            )

        # å¦‚æœæœ€ä½³æ•°æ®æºä¸å¯ç”¨,ä½¿ç”¨å½“å‰å¯ç”¨æº
        if best_source not in self.available_sources:
            logger.warning(
                f"âš ï¸ {metric} çš„æœ€ä½³æ•°æ®æº {best_source.value} ä¸å¯ç”¨, "
                f"ä½¿ç”¨å½“å‰æ•°æ®æº {self.current_source.value}"
            )
            return self.current_source.value

        return best_source.value

    def _is_trading_hours(self) -> bool:
        """
        åˆ¤æ–­å½“å‰æ˜¯å¦æ˜¯Aè‚¡äº¤æ˜“æ—¶é—´

        Aè‚¡äº¤æ˜“æ—¶é—´:
        - ä¸Šåˆ: 9:30 - 11:30
        - ä¸‹åˆ: 13:00 - 15:00
        - å»¶å30åˆ†é’Ÿ: ç”¨äºæ”¶ç›˜åçš„åˆ†æ (15:00 - 15:30)

        Returns:
            bool: Trueè¡¨ç¤ºéœ€è¦å®æ—¶æ•°æ®
        """
        try:
            from datetime import datetime

            now = datetime.now()

            # å‘¨æœ«ä¸äº¤æ˜“
            if now.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                return False

            current_time = now.hour * 100 + now.minute  # è½¬æ¢ä¸ºHHMMæ ¼å¼,å¦‚930è¡¨ç¤º9:30

            # ä¸Šåˆæ—¶æ®µ: 9:30-11:30, åŠ ä¸Š30åˆ†é’Ÿç¼“å†²åˆ°12:00
            morning_start = 930
            morning_end = 1200

            # ä¸‹åˆæ—¶æ®µ: 13:00-15:30 (æ”¶ç›˜å30åˆ†é’Ÿ)
            afternoon_start = 1300
            afternoon_end = 1530

            is_morning = morning_start <= current_time <= morning_end
            is_afternoon = afternoon_start <= current_time <= afternoon_end

            return is_morning or is_afternoon

        except Exception as e:
            logger.warning(f"åˆ¤æ–­äº¤æ˜“æ—¶é—´å¤±è´¥: {e}, é»˜è®¤ä¸ºéäº¤æ˜“æ—¶é—´")
            return False

    def is_realtime_capable(self, source: ChinaDataSource) -> Dict[str, bool]:
        """
        åˆ¤æ–­æ•°æ®æºæ˜¯å¦æ”¯æŒå®æ—¶è¡Œæƒ…

        Args:
            source: æ•°æ®æºæšä¸¾

        Returns:
            Dict[str, bool]: å„é¡¹å®æ—¶èƒ½åŠ›çš„å­—å…¸
            {
                'realtime_quote': æ˜¯å¦æ”¯æŒå®æ—¶æŠ¥ä»·,
                'tick_data': æ˜¯å¦æ”¯æŒé€ç¬”æˆäº¤,
                'level2': æ˜¯å¦æ”¯æŒLevel-2è¡Œæƒ…,
                'delay_seconds': æ•°æ®å»¶è¿Ÿç§’æ•°
            }
        """
        capabilities = {
            ChinaDataSource.MONGODB: {
                "realtime_quote": False,  # ç¼“å­˜æ•°æ®,éå®æ—¶
                "tick_data": False,
                "level2": False,
                "delay_seconds": 0,
                "description": "ç¼“å­˜æ•°æ®,æ¥è‡ªå…¶ä»–æ•°æ®æºçš„å†å²å¿«ç…§",
            },
            ChinaDataSource.TUSHARE: {
                "realtime_quote": True,  # æ”¯æŒ,ä½†æœ‰å»¶è¿Ÿ
                "tick_data": True,  # éœ€è¦é«˜çº§ç§¯åˆ†
                "level2": False,  # ä¸æ”¯æŒ
                "delay_seconds": 900,  # çº¦15åˆ†é’Ÿå»¶è¿Ÿ
                "description": "å®˜æ–¹æ•°æ®,ä½†å®æ—¶è¡Œæƒ…æœ‰15åˆ†é’Ÿå»¶è¿Ÿ",
            },
            ChinaDataSource.AKSHARE: {
                "realtime_quote": True,  # âœ… çœŸæ­£å®æ—¶
                "tick_data": True,  # âœ… æ”¯æŒ
                "level2": True,  # âœ… éƒ¨åˆ†æ”¯æŒ
                "delay_seconds": 1,  # ç§’çº§å»¶è¿Ÿ
                "description": "âœ… æœ€ä½³å®æ—¶æ•°æ®æº,æ¥è‡ªä¸œæ–¹è´¢å¯Œ/è…¾è®¯",
            },
            ChinaDataSource.BAOSTOCK: {
                "realtime_quote": False,  # ä¸æ”¯æŒå®æ—¶
                "tick_data": False,
                "level2": False,
                "delay_seconds": 86400,  # T+1,æ¬¡æ—¥æ›´æ–°
                "description": "ä»…æä¾›å†å²æ•°æ®,ä¸æ”¯æŒå®æ—¶è¡Œæƒ…",
            },
        }

        return capabilities.get(
            source,
            {
                "realtime_quote": False,
                "tick_data": False,
                "level2": False,
                "delay_seconds": 999999,
                "description": "æœªçŸ¥æ•°æ®æº",
            },
        )

    async def get_data_with_validation(
        self, symbol: str, metric: str, period: str = "daily"
    ) -> tuple[Any, Dict]:
        """
        è·å–æ•°æ®å¹¶è‡ªåŠ¨éªŒè¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            metric: æŒ‡æ ‡åç§° ('current_price', 'PE', 'volume', etc.)
            period: æ•°æ®å‘¨æœŸ

        Returns:
            tuple[Any, Dict]: (æ•°æ®å€¼, éªŒè¯ç»“æœå­—å…¸)
        """
        # è·å–æœ€ä½³æ•°æ®æº
        best_source_name = self.get_best_source_for_metric(metric)
        logger.info(f"ğŸ“Š [éªŒè¯] ä¸º {metric} é€‰æ‹©æ•°æ®æº: {best_source_name}")

        # è·å–æ•°æ®
        data_str = self.get_stock_data(symbol, "2024-01-01", "2024-12-31", period)

        # è§£ææ•°æ®
        data = self._parse_data_string(data_str)

        if not data:
            return None, {"is_valid": False, "error": "æ— æ³•è·å–æ•°æ®"}

        # æå–è¯·æ±‚çš„æŒ‡æ ‡
        metric_value = data.get(metric)

        # è´¨é‡è¯„åˆ†
        quality_score = self.get_data_quality_score(symbol, data)

        validation_result = {
            "is_valid": quality_score >= 60,
            "quality_score": quality_score,
            "source": best_source_name,
            "metric": metric,
            "value": metric_value,
            "data": data,
            "warnings": [],
            "errors": [],
        }

        # æ ¹æ®è´¨é‡è¯„åˆ†æ·»åŠ è­¦å‘Š
        if quality_score < 70:
            validation_result["warnings"].append(
                f"æ•°æ®è´¨é‡è¾ƒä½ ({quality_score:.1f}/100)"
            )
        if quality_score < 60:
            validation_result["errors"].append(
                f"æ•°æ®è´¨é‡ä¸åˆæ ¼ ({quality_score:.1f}/100)"
            )

        return metric_value, validation_result

    async def cross_validate_metric(
        self, symbol: str, metric: str, sources: List[str] = None
    ) -> Dict:
        """
        å¤šæºäº¤å‰éªŒè¯æŒ‡æ ‡

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            metric: æŒ‡æ ‡åç§°
            sources: è¦éªŒè¯çš„æ•°æ®æºåˆ—è¡¨,å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨æº

        Returns:
            Dict: äº¤å‰éªŒè¯ç»“æœ
        """
        if sources is None:
            sources = [s.value for s in self.available_sources]

        logger.info(f"ğŸ“Š [äº¤å‰éªŒè¯] å¼€å§‹å¤šæºéªŒè¯ {symbol} çš„ {metric}")

        results = {}
        values = {}

        # ä¿å­˜å½“å‰æ•°æ®æº
        original_source = self.current_source

        try:
            for source in sources:
                try:
                    # åˆ‡æ¢æ•°æ®æº
                    source_enum = ChinaDataSource(source)
                    if source_enum in self.available_sources:
                        self.current_source = source_enum

                        # è·å–æ•°æ®
                        value, validation = await self.get_data_with_validation(
                            symbol, metric
                        )

                        if value is not None:
                            results[source] = {
                                "value": value,
                                "quality_score": validation.get("quality_score", 0),
                                "is_valid": validation.get("is_valid", False),
                            }
                            values[source] = value

                except Exception as e:
                    logger.warning(f"ä» {source} è·å– {metric} å¤±è´¥: {e}")
                    continue

        finally:
            # æ¢å¤åŸå§‹æ•°æ®æº
            self.current_source = original_source

        # åˆ†æä¸€è‡´æ€§
        cross_validation_result = self._analyze_cross_validation_results(
            symbol, metric, results, values
        )

        return cross_validation_result

    def _analyze_cross_validation_results(
        self, symbol: str, metric: str, results: Dict, values: Dict
    ) -> Dict:
        """åˆ†æäº¤å‰éªŒè¯ç»“æœ"""
        if not values:
            return {
                "symbol": symbol,
                "metric": metric,
                "is_valid": False,
                "error": "æ— æ³•ä»ä»»ä½•æ•°æ®æºè·å–æ•°æ®",
                "sources_checked": list(results.keys()),
            }

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        value_list = list(values.values())
        num_sources = len(value_list)

        # åŸºæœ¬ç»Ÿè®¡
        min_val = min(value_list)
        max_val = max(value_list)
        avg_val = sum(value_list) / num_sources

        # è®¡ç®—æ ‡å‡†å·®å’Œå˜å¼‚ç³»æ•°
        variance = sum((x - avg_val) ** 2 for x in value_list) / num_sources
        std_dev = variance**0.5
        cv = (std_dev / avg_val * 100) if avg_val != 0 else 0

        # åˆ¤æ–­ä¸€è‡´æ€§
        is_consistent = cv < 5  # å˜å¼‚ç³»æ•°å°äº5%è®¤ä¸ºä¸€è‡´

        # æ‰¾å‡ºæœ€å¯é çš„æ•°æ®æº
        best_source = (
            max(results.items(), key=lambda x: x[1]["quality_score"])[0]
            if results
            else None
        )

        # ä¸­ä½æ•°ä½œä¸ºæ¨èå€¼
        sorted_values = sorted(value_list)
        if num_sources % 2 == 0:
            median_value = (
                sorted_values[num_sources // 2 - 1] + sorted_values[num_sources // 2]
            ) / 2
        else:
            median_value = sorted_values[num_sources // 2]

        return {
            "symbol": symbol,
            "metric": metric,
            "is_valid": is_consistent,
            "is_consistent": is_consistent,
            "num_sources": num_sources,
            "sources_checked": list(results.keys()),
            "values_by_source": values,
            "quality_scores": {k: v["quality_score"] for k, v in results.items()},
            "statistics": {
                "min": min_val,
                "max": max_val,
                "avg": avg_val,
                "median": median_value,
                "std_dev": std_dev,
                "cv_percent": cv,
            },
            "recommendation": {
                "best_source": best_source,
                "suggested_value": median_value,
                "confidence": max(0, min(1, 1 - cv / 10)),  # CVè¶Šå°,ç½®ä¿¡åº¦è¶Šé«˜
            },
            "warnings": [] if is_consistent else [f"æ•°æ®æºé—´å˜å¼‚ç³»æ•°è¾ƒé«˜: {cv:.2f}%"],
            "errors": [] if num_sources > 0 else ["æ— æ³•è·å–ä»»ä½•æ•°æ®"],
        }

    def _parse_data_string(self, data_str: str) -> Dict[str, Any]:
        """
        è§£ææ•°æ®å­—ç¬¦ä¸²ä¸ºå­—å…¸

        è¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°,å®é™…åº”è¯¥æ ¹æ®æ•°æ®æ ¼å¼è§£æ
        """
        if not data_str or isinstance(data_str, dict):
            return data_str or {}

        # å°è¯•è§£æJSON
        if data_str.startswith("{"):
            import json

            try:
                return json.loads(data_str)
            except json.JSONDecodeError:
                pass

        # å¦‚æœæ˜¯è¡¨æ ¼æ ¼å¼,è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„è§£æ
        # æš‚æ—¶è¿”å›ç©ºå­—å…¸
        logger.debug("æ— æ³•è§£ææ•°æ®å­—ç¬¦ä¸²")
        return {}


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_data_source_manager = None


def get_data_source_manager() -> DataSourceManager:
    """è·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager


def get_china_stock_data_unified(symbol: str, start_date: str, end_date: str) -> str:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨æ•°æ®è·å–æ¥å£
    è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„æ•°æ®æºï¼Œæ”¯æŒå¤‡ç”¨æ•°æ®æº

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
    """
    from tradingagents.utils.logging_init import get_logger

    # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
    logger.info(
        f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] data_source_manager.get_china_stock_data_unified æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})"
    )
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")

    manager = get_data_source_manager()
    logger.info(
        f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ manager.get_stock_dataï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', start_date='{start_date}', end_date='{end_date}'"
    )
    result = manager.get_stock_data(symbol, start_date, end_date)
    # åˆ†æè¿”å›ç»“æœçš„è¯¦ç»†ä¿¡æ¯
    if result:
        lines = result.split("\n")
        data_lines = [line for line in lines if "2025-" in line and symbol in line]
        logger.info(
            f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœç»Ÿè®¡: æ€»è¡Œæ•°={len(lines)}, æ•°æ®è¡Œæ•°={len(data_lines)}, ç»“æœé•¿åº¦={len(result)}å­—ç¬¦"
        )
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœå‰500å­—ç¬¦: {result[:500]}")
        if len(data_lines) > 0:
            logger.info(
                f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] æ•°æ®è¡Œç¤ºä¾‹: ç¬¬1è¡Œ='{data_lines[0][:100]}', æœ€å1è¡Œ='{data_lines[-1][:100]}'"
            )
    else:
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœ: None")
    return result


def get_china_stock_info_unified(symbol: str) -> Dict:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨ä¿¡æ¯è·å–æ¥å£

    Args:
        symbol: è‚¡ç¥¨ä»£ç 

    Returns:
        Dict: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    """
    manager = get_data_source_manager()
    return manager.get_stock_info(symbol)


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_data_source_manager = None


def get_data_source_manager() -> DataSourceManager:
    """è·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager


# ==================== å…¼å®¹æ€§æ¥å£ ====================
# ä¸ºäº†å…¼å®¹ stock_data_serviceï¼Œæä¾›ç›¸åŒçš„æ¥å£


def get_stock_data_service() -> DataSourceManager:
    """
    è·å–è‚¡ç¥¨æ•°æ®æœåŠ¡å®ä¾‹ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

    âš ï¸ æ­¤å‡½æ•°ä¸ºå…¼å®¹æ€§æ¥å£ï¼Œå®é™…è¿”å› DataSourceManager å®ä¾‹
    æ¨èç›´æ¥ä½¿ç”¨ get_data_source_manager()
    """
    return get_data_source_manager()


# ==================== ç¾è‚¡æ•°æ®æºç®¡ç†å™¨ ====================


class USDataSourceManager:
    """
    ç¾è‚¡æ•°æ®æºç®¡ç†å™¨

    æ”¯æŒçš„æ•°æ®æºï¼š
    - yfinance: è‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼ˆå…è´¹ï¼‰
    - alpha_vantage: åŸºæœ¬é¢å’Œæ–°é—»æ•°æ®ï¼ˆéœ€è¦API Keyï¼‰
    - finnhub: å¤‡ç”¨æ•°æ®æºï¼ˆéœ€è¦API Keyï¼‰
    - mongodb: ç¼“å­˜æ•°æ®æºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    """

    def __init__(self):
        """åˆå§‹åŒ–ç¾è‚¡æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ MongoDB ç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        # æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº
        self.available_sources = self._check_available_sources()

        # è®¾ç½®é»˜è®¤æ•°æ®æº
        self.default_source = self._get_default_source()
        self.current_source = self.default_source

        logger.info(f"ğŸ“Š ç¾è‚¡æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(
            f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled

        return use_app_cache_enabled()

    def _get_data_source_priority_order(
        self, symbol: Optional[str] = None
    ) -> List[USDataSource]:
        """
        ä»æ•°æ®åº“è·å–ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºé™çº§ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ•°æ®æºåˆ—è¡¨ï¼ˆä¸åŒ…å«MongoDBï¼‰
        """
        try:
            # ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # æ–¹æ³•1: ä» datasource_groupings é›†åˆè¯»å–ï¼ˆæ¨èï¼‰
            groupings_collection = db.datasource_groupings
            groupings = list(
                groupings_collection.find(
                    {"market_category_id": "us_stocks", "enabled": True}
                ).sort("priority", -1)
            )  # é™åºæ’åºï¼Œä¼˜å…ˆçº§é«˜çš„åœ¨å‰

            if groupings:
                # è½¬æ¢ä¸º USDataSource æšä¸¾
                # ğŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ USDataSource æšä¸¾ï¼‰
                source_mapping = {
                    "yfinance": USDataSource.YFINANCE,
                    "yahoo_finance": USDataSource.YFINANCE,  # åˆ«å
                    "alpha_vantage": USDataSource.ALPHA_VANTAGE,
                    "finnhub": USDataSource.FINNHUB,
                }

                result = []
                for grouping in groupings:
                    ds_name = grouping.get("data_source_name", "").lower()
                    if ds_name in source_mapping:
                        source = source_mapping[ds_name]
                        # æ’é™¤ MongoDBï¼ˆMongoDB æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸å‚ä¸é™çº§ï¼‰
                        if (
                            source != USDataSource.MONGODB
                            and source in self.available_sources
                        ):
                            result.append(source)

                if result:
                    logger.info(
                        f"âœ… [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–: {[s.value for s in result]}"
                    )
                    return result

            logger.warning("âš ï¸ [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
        except Exception as e:
            logger.warning(f"âš ï¸ [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # å›é€€åˆ°é»˜è®¤é¡ºåº
        # é»˜è®¤é¡ºåºï¼šyfinance > Alpha Vantage > Finnhub
        default_order = [
            USDataSource.YFINANCE,
            USDataSource.ALPHA_VANTAGE,
            USDataSource.FINNHUB,
        ]
        # åªè¿”å›å¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _get_default_source(self) -> USDataSource:
        """è·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return USDataSource.MONGODB

        # ä»ç¯å¢ƒå˜é‡è·å–ï¼Œé»˜è®¤ä½¿ç”¨ yfinance
        env_source = os.getenv(
            "DEFAULT_US_DATA_SOURCE", DataSourceCode.YFINANCE
        ).lower()

        # æ˜ å°„åˆ°æšä¸¾
        source_mapping = {
            DataSourceCode.YFINANCE: USDataSource.YFINANCE,
            DataSourceCode.ALPHA_VANTAGE: USDataSource.ALPHA_VANTAGE,
            DataSourceCode.FINNHUB: USDataSource.FINNHUB,
        }

        return source_mapping.get(env_source, USDataSource.YFINANCE)

    def _check_available_sources(self) -> List[USDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        ä»æ•°æ®åº“è¯»å–å¯ç”¨çŠ¶æ€ï¼Œå¹¶æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
        """
        available = []

        # MongoDB ç¼“å­˜
        if self.use_mongodb_cache:
            available.append(USDataSource.MONGODB)
            logger.info("âœ… MongoDBç¼“å­˜æ•°æ®æºå¯ç”¨")

        # ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨å’Œé…ç½®
        enabled_sources_in_db = self._get_enabled_sources_from_db()
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥ yfinance
        if "yfinance" in enabled_sources_in_db:
            try:
                import yfinance

                available.append(USDataSource.YFINANCE)
                logger.info("âœ… yfinanceæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ yfinanceæ•°æ®æºä¸å¯ç”¨: æœªå®‰è£… yfinance åº“")
        else:
            logger.info("â„¹ï¸ yfinanceæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Alpha Vantage
        if "alpha_vantage" in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get("alpha_vantage", {}).get(
                    "api_key"
                ) or os.getenv("ALPHA_VANTAGE_API_KEY")
                if api_key:
                    available.append(USDataSource.ALPHA_VANTAGE)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("alpha_vantage", {}).get("api_key")
                        else "ç¯å¢ƒå˜é‡"
                    )
                    logger.info(
                        f"âœ… Alpha Vantageæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})"
                    )
                else:
                    logger.warning(
                        "âš ï¸ Alpha Vantageæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Alpha Vantageæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Alpha Vantageæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Finnhub
        if "finnhub" in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get("finnhub", {}).get(
                    "api_key"
                ) or os.getenv("FINNHUB_API_KEY")
                if api_key:
                    available.append(USDataSource.FINNHUB)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("finnhub", {}).get("api_key")
                        else "ç¯å¢ƒå˜é‡"
                    )
                    logger.info(f"âœ… Finnhubæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning(
                        "âš ï¸ Finnhubæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Finnhubæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Finnhubæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        return available

    def _get_enabled_sources_from_db(self) -> List[str]:
        """ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä» datasource_groupings é›†åˆè¯»å–
            groupings = list(
                db.datasource_groupings.find(
                    {"market_category_id": "us_stocks", "enabled": True}
                )
            )

            # ğŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ ä»£ç ä¸­ä½¿ç”¨çš„åç§°ï¼‰
            name_mapping = {
                "alpha vantage": "alpha_vantage",
                "yahoo finance": "yfinance",
                "finnhub": "finnhub",
            }

            result = []
            for g in groupings:
                db_name = g.get("data_source_name", "").lower()
                # ä½¿ç”¨æ˜ å°„è¡¨è½¬æ¢åç§°
                code_name = name_mapping.get(db_name, db_name)
                result.append(code_name)
                logger.debug(f"ğŸ”„ æ•°æ®æºåç§°æ˜ å°„: '{db_name}' â†’ '{code_name}'")

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºå¤±è´¥: {e}")
            # é»˜è®¤å…¨éƒ¨å¯ç”¨
            return ["yfinance", "alpha_vantage", "finnhub"]

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä» system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get("data_source_configs", [])

            # æ„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get("name", "").lower()
                result[name] = {
                    "api_key": ds_config.get("api_key", ""),
                    "api_secret": ds_config.get("api_secret", ""),
                    "config_params": ds_config.get("config_params", {}),
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> USDataSource:
        """è·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: USDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… ç¾è‚¡æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ ç¾è‚¡æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False


# å…¨å±€ç¾è‚¡æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_us_data_source_manager = None


def get_us_data_source_manager() -> USDataSourceManager:
    """è·å–å…¨å±€ç¾è‚¡æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _us_data_source_manager
    if _us_data_source_manager is None:
        _us_data_source_manager = USDataSourceManager()
    return _us_data_source_manager
