#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æºç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†ä¸­å›½è‚¡ç¥¨æ•°æ®æºçš„é€‰æ‹©å’Œåˆ‡æ¢ï¼Œæ”¯æŒTushareã€AKShareã€BaoStockç­‰
"""

import os
import time
import warnings
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger

logger = get_logger("agents")
warnings.filterwarnings("ignore")

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import setup_dataflow_logging

logger = setup_dataflow_logging()

# å¯¼å…¥ç»Ÿä¸€æ•°æ®æºç¼–ç 
from tradingagents.constants import DataSourceCode

# å¯¼å…¥æ•°æ®æ ‡å‡†åŒ–å™¨
from tradingagents.dataflows.standardizers.stock_basic_standardizer import (
    standardize_stock_basic,
)


class ChinaDataSource(Enum):
    """
    ä¸­å›½è‚¡ç¥¨æ•°æ®æºæžšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæžšä¸¾ä¸Ž tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """

    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    TUSHARE = DataSourceCode.TUSHARE
    AKSHARE = DataSourceCode.AKSHARE
    BAOSTOCK = DataSourceCode.BAOSTOCK


class USDataSource(Enum):
    """
    ç¾Žè‚¡æ•°æ®æºæžšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæžšä¸¾ä¸Ž tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """

    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    YFINANCE = DataSourceCode.YFINANCE  # Yahoo Financeï¼ˆå…è´¹ï¼Œè‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼‰
    ALPHA_VANTAGE = DataSourceCode.ALPHA_VANTAGE  # Alpha Vantageï¼ˆåŸºæœ¬é¢å’Œæ–°é—»ï¼‰
    FINNHUB = DataSourceCode.FINNHUB  # Finnhubï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰


class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        self.default_source = self._get_default_source()
        self.available_sources = self._check_available_sources()
        self.current_source = self.default_source

        # åˆå§‹åŒ–ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = None
        self.cache_enabled = False
        try:
            from .cache import get_cache

            self.cache_manager = get_cache()
            self.cache_enabled = True
            logger.info(f"âœ… ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨å·²å¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        logger.info(f"ðŸ“Š æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(
            f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(
            f"   ç»Ÿä¸€ç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.cache_enabled else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled

        return use_app_cache_enabled()

    def _get_data_source_priority_order(
        self, symbol: Optional[str] = None
    ) -> List[ChinaDataSource]:
        """
        ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºŽé™çº§ï¼‰

        ðŸ”¥ é‡æž„è¯´æ˜Ž (2026-02-01):
        - ä¸å†ä»Žæ•°æ®åº“è¯»å–é…ç½®ï¼Œå…¨éƒ¨ä»Ž .env æ–‡ä»¶èŽ·å–
        - é»˜è®¤ä¼˜å…ˆçº§ï¼šTushare > AKShare > BaoStock
        - MongoDB ä»…ç”¨äºŽä¿å­˜ï¼Œä¸ä½œä¸ºæŸ¥è¯¢ä¼˜å…ˆæº

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œç”¨äºŽè¯†åˆ«å¸‚åœºç±»åž‹ï¼ˆAè‚¡/ç¾Žè‚¡/æ¸¯è‚¡ï¼‰

        Returns:
            æŒ‰ä¼˜å…ˆçº§æŽ’åºçš„æ•°æ®æºåˆ—è¡¨
        """
        # ðŸ”¥ ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–é…ç½®
        env_priority = os.getenv(
            "HISTORICAL_DATA_SOURCE_PRIORITY", "tushare,akshare,baostock"
        )

        # è§£æžçŽ¯å¢ƒå˜é‡é…ç½®
        source_mapping = {
            "tushare": ChinaDataSource.TUSHARE,
            "akshare": ChinaDataSource.AKSHARE,
            "baostock": ChinaDataSource.BAOSTOCK,
        }

        result = []
        for source_name in env_priority.split(","):
            source_name = source_name.strip().lower()
            if source_name in source_mapping:
                source = source_mapping[source_name]
                if source in self.available_sources:
                    result.append(source)

        if result:
            logger.info(f"âœ… [æ•°æ®æºä¼˜å…ˆçº§] ä»Ž.envè¯»å–: {[s.value for s in result]}")
            return result

        # ðŸ”¥ å›žé€€åˆ°é»˜è®¤é¡ºåº
        # é»˜è®¤é¡ºåºï¼šTushare > AKShare > BaoStock
        default_order = [
            ChinaDataSource.TUSHARE,
            ChinaDataSource.AKSHARE,
            ChinaDataSource.BAOSTOCK,
        ]

        logger.warning(
            f"âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] .envé…ç½®æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤é¡ºåº: {[s.value for s in default_order if s in self.available_sources]}"
        )

        # åªè¿”å›žå¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _identify_market_category(self, symbol: Optional[str]) -> Optional[str]:
        """
        è¯†åˆ«è‚¡ç¥¨ä»£ç æ‰€å±žçš„å¸‚åœºåˆ†ç±»

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            å¸‚åœºåˆ†ç±»IDï¼ˆa_shares/us_stocks/hk_stocksï¼‰ï¼Œå¦‚æžœæ— æ³•è¯†åˆ«åˆ™è¿”å›žNone
        """
        if not symbol:
            return None

        try:
            from tradingagents.utils.stock_utils import StockMarket, StockUtils

            market = StockUtils.identify_stock_market(symbol)

            # æ˜ å°„åˆ°å¸‚åœºåˆ†ç±»ID
            market_mapping = {
                StockMarket.CHINA_A: "a_shares",
                StockMarket.US: "us_stocks",
                StockMarket.HONG_KONG: "hk_stocks",
            }

            category = market_mapping.get(market)
            if category:
                logger.debug(f"ðŸ” [å¸‚åœºè¯†åˆ«] {symbol} â†’ {category}")
            return category
        except Exception as e:
            logger.warning(f"âš ï¸ [å¸‚åœºè¯†åˆ«] è¯†åˆ«å¤±è´¥: {e}")
            return None

    def _get_default_source(self) -> ChinaDataSource:
        """èŽ·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æžœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return ChinaDataSource.MONGODB

        # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–ï¼Œé»˜è®¤ä½¿ç”¨AKShareä½œä¸ºç¬¬ä¸€ä¼˜å…ˆçº§æ•°æ®æº
        env_source = os.getenv(
            "DEFAULT_CHINA_DATA_SOURCE", DataSourceCode.AKSHARE
        ).lower()

        # æ˜ å°„åˆ°æžšä¸¾ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼–ç ï¼‰
        source_mapping: Dict[str, ChinaDataSource] = {
            DataSourceCode.TUSHARE.value: ChinaDataSource.TUSHARE,
            DataSourceCode.AKSHARE.value: ChinaDataSource.AKSHARE,
            DataSourceCode.BAOSTOCK.value: ChinaDataSource.BAOSTOCK,
        }

        return source_mapping.get(env_source, ChinaDataSource.AKSHARE)

    # ==================== Tushareæ•°æ®æŽ¥å£ ====================

    def get_china_stock_data_tushare(
        self, symbol: str, start_date: str, end_date: str
    ) -> str:
        """
        ä½¿ç”¨TushareèŽ·å–ä¸­å›½Aè‚¡åŽ†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        # ä¸´æ—¶åˆ‡æ¢åˆ°Tushareæ•°æ®æº
        original_source = self.current_source
        self.current_source = ChinaDataSource.TUSHARE

        try:
            result = self._get_tushare_data(symbol, start_date, end_date)
            return result
        finally:
            # æ¢å¤åŽŸå§‹æ•°æ®æº
            self.current_source = original_source

    def get_fundamentals_data(self, symbol: str) -> str:
        """
        èŽ·å–åŸºæœ¬é¢æ•°æ®ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ ç”Ÿæˆåˆ†æž

        Tushare æ•°æ®æºä¼šèŽ·å–å®Œæ•´çš„è´¢åŠ¡æ•°æ®ï¼š
        1. ä¼°å€¼æŒ‡æ ‡ (PE, PB, PS) - daily_basic
        2. è´¢åŠ¡æŒ‡æ ‡ (ROE, ROA ç­‰) - fina_indicator
        3. è´¢åŠ¡æŠ¥è¡¨ (åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€çŽ°é‡‘æµé‡è¡¨) - income/balancesheet/cashflow

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†æžæŠ¥å‘Š
        """
        logger.info(
            f"ðŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹èŽ·å–åŸºæœ¬é¢æ•°æ®: {symbol}",
            extra={
                "symbol": symbol,
                "data_source": self.current_source.value,
                "event_type": "fundamentals_fetch_start",
            },
        )

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„èŽ·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_fundamentals(symbol)
            elif self.current_source == ChinaDataSource.TUSHARE:
                # ðŸ”¥ ä½¿ç”¨ Tushare èŽ·å–å®Œæ•´çš„åŸºæœ¬é¢æ•°æ®
                # 1. ä¼°å€¼æŒ‡æ ‡ (PE, PB, PS)
                result = self._get_tushare_fundamentals(symbol)

                # 2. é™„åŠ è´¢åŠ¡æŒ‡æ ‡ (ROE, ROA ç­‰)
                indicators = self._get_tushare_financial_indicators(symbol)
                if indicators and "âŒ" not in indicators:
                    result += indicators

                # 3. é™„åŠ è´¢åŠ¡æŠ¥è¡¨ (åˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€çŽ°é‡‘æµé‡è¡¨)
                reports = self._get_tushare_financial_reports(symbol)
                if reports and "âŒ" not in reports:
                    result += reports
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_fundamentals(symbol)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒåŸºæœ¬é¢æ•°æ®ï¼Œç”ŸæˆåŸºæœ¬åˆ†æž
                result = self._generate_fundamentals_analysis(symbol)

            # æ£€æŸ¥ç»“æžœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0

            if result and "âŒ" not in result:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸèŽ·å–åŸºæœ¬é¢æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "event_type": "fundamentals_fetch_success",
                    },
                )
                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] åŸºæœ¬é¢æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§: {symbol}",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "event_type": "fundamentals_fetch_fallback",
                    },
                )
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] èŽ·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol} - {e}",
                extra={
                    "symbol": symbol,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "fundamentals_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_fundamentals(symbol)

    def get_china_stock_fundamentals_tushare(self, symbol: str) -> str:
        """
        ä½¿ç”¨TushareèŽ·å–ä¸­å›½è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ï¼ˆå…¼å®¹æ—§æŽ¥å£ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†æžæŠ¥å‘Š
        """
        # é‡å®šå‘åˆ°ç»Ÿä¸€æŽ¥å£
        return self._get_tushare_fundamentals(symbol)

    def get_news_data(
        self, symbol: Optional[str] = None, hours_back: int = 24, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        èŽ·å–æ–°é—»æ•°æ®çš„ç»Ÿä¸€æŽ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™èŽ·å–å¸‚åœºæ–°é—»
            hours_back: å›žæº¯å°æ—¶æ•°
            limit: è¿”å›žæ•°é‡é™åˆ¶

        Returns:
            List[Dict]: æ–°é—»æ•°æ®åˆ—è¡¨
        """
        logger.info(
            f"ðŸ“° [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹èŽ·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}, å›žæº¯{hours_back}å°æ—¶",
            extra={
                "symbol": symbol,
                "hours_back": hours_back,
                "limit": limit,
                "data_source": self.current_source.value,
                "event_type": "news_fetch_start",
            },
        )

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„èŽ·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.TUSHARE:
                result = self._get_tushare_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_news(symbol, hours_back, limit)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒæ–°é—»æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®æº {self.current_source.value} ä¸æ”¯æŒæ–°é—»æ•°æ®")
                result = []

            # æ£€æŸ¥ç»“æžœ
            duration = time.time() - start_time
            result_count = len(result) if result else 0

            if result and result_count > 0:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸèŽ·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'} ({result_count}æ¡, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "news_count": result_count,
                        "duration": duration,
                        "event_type": "news_fetch_success",
                    },
                )
                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] æœªèŽ·å–åˆ°æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œå°è¯•é™çº§",
                    extra={
                        "symbol": symbol,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "event_type": "news_fetch_fallback",
                    },
                )
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] èŽ·å–æ–°é—»æ•°æ®å¤±è´¥: {symbol or 'å¸‚åœºæ–°é—»'} - {e}",
                extra={
                    "symbol": symbol,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "news_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_news(symbol, hours_back, limit)

    def _check_available_sources(self) -> List[ChinaDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        æ£€æŸ¥é€»è¾‘ï¼š
        1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…ï¼ˆæŠ€æœ¯å¯ç”¨æ€§ï¼‰
        2. æ£€æŸ¥æ•°æ®åº“é…ç½®ä¸­æ˜¯å¦å¯ç”¨ï¼ˆä¸šåŠ¡å¯ç”¨æ€§ï¼‰

        Returns:
            å¯ç”¨ä¸”å·²å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨
        """
        available = []

        # ðŸ”¥ ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ŒèŽ·å–å¯ç”¨çŠ¶æ€
        enabled_sources_in_db = set()
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()
            config_collection = db.system_configs

            # èŽ·å–æœ€æ–°çš„æ¿€æ´»é…ç½®
            config_data = config_collection.find_one(
                {"is_active": True}, sort=[("version", -1)]
            )

            if config_data and config_data.get("data_source_configs"):
                data_source_configs = config_data.get("data_source_configs", [])

                # æå–å·²å¯ç”¨çš„æ•°æ®æºç±»åž‹
                for ds in data_source_configs:
                    if ds.get("enabled", True):
                        ds_type = ds.get("type", "").lower()
                        enabled_sources_in_db.add(ds_type)

                logger.info(
                    f"âœ… [æ•°æ®æºé…ç½®] ä»Žæ•°æ®åº“è¯»å–åˆ°å·²å¯ç”¨çš„æ•°æ®æº: {enabled_sources_in_db}"
                )
            else:
                logger.warning(
                    "âš ï¸ [æ•°æ®æºé…ç½®] æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº"
                )
                # å¦‚æžœæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
                enabled_sources_in_db = {"mongodb", "tushare", "akshare", "baostock"}
        except Exception as e:
            logger.warning(
                f"âš ï¸ [æ•°æ®æºé…ç½®] ä»Žæ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº"
            )
            # å¦‚æžœè¯»å–å¤±è´¥ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
            enabled_sources_in_db = {"mongodb", "tushare", "akshare", "baostock"}

        # æ£€æŸ¥MongoDBï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if self.use_mongodb_cache and "mongodb" in enabled_sources_in_db:
            try:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                    get_mongodb_cache_adapter,
                )

                adapter = get_mongodb_cache_adapter()
                if adapter.use_app_cache and adapter.db is not None:
                    available.append(ChinaDataSource.MONGODB)
                    logger.info("âœ… MongoDBæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰")
                else:
                    logger.warning("âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: æ•°æ®åº“æœªè¿žæŽ¥")
            except Exception as e:
                logger.warning(f"âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: {e}")
        elif self.use_mongodb_cache and "mongodb" not in enabled_sources_in_db:
            logger.info("â„¹ï¸ MongoDBæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥Tushare
        if "tushare" in enabled_sources_in_db:
            try:
                import tushare as ts

                # ä¼˜å…ˆä»Žæ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–
                token = datasource_configs.get("tushare", {}).get(
                    "api_key"
                ) or os.getenv("TUSHARE_TOKEN")
                if token:
                    available.append(ChinaDataSource.TUSHARE)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("tushare", {}).get("api_key")
                        else "çŽ¯å¢ƒå˜é‡"
                    )
                    logger.info(f"âœ… Tushareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning(
                        "âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’ŒçŽ¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except ImportError:
                logger.warning("âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ Tushareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥AKShare
        if "akshare" in enabled_sources_in_db:
            try:
                import akshare as ak

                available.append(ChinaDataSource.AKSHARE)
                logger.info("âœ… AKShareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ AKShareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ AKShareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥BaoStock
        if "baostock" in enabled_sources_in_db:
            try:
                import baostock as bs

                available.append(ChinaDataSource.BAOSTOCK)
                logger.info(f"âœ… BaoStockæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning(f"âš ï¸ BaoStockæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ BaoStockæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # TDX (é€šè¾¾ä¿¡) å·²ç§»é™¤
        # ä¸å†æ£€æŸ¥å’Œæ”¯æŒ TDX æ•°æ®æº

        return available

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä»Ž system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get("data_source_configs", [])

            # æž„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get("name", "").lower()
                result[name] = {
                    "api_key": ds_config.get("api_key", ""),
                    "api_secret": ds_config.get("api_secret", ""),
                    "config_params": ds_config.get("config_params", {}),
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> ChinaDataSource:
        """èŽ·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: ChinaDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False

    def get_data_adapter(self):
        """èŽ·å–å½“å‰æ•°æ®æºçš„é€‚é…å™¨"""
        if self.current_source == ChinaDataSource.MONGODB:
            return self._get_mongodb_adapter()
        elif self.current_source == ChinaDataSource.TUSHARE:
            return self._get_tushare_adapter()
        elif self.current_source == ChinaDataSource.AKSHARE:
            return self._get_akshare_adapter()
        elif self.current_source == ChinaDataSource.BAOSTOCK:
            return self._get_baostock_adapter()
        # TDX å·²ç§»é™¤
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source}")

    def _get_mongodb_adapter(self):
        """èŽ·å–MongoDBé€‚é…å™¨"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            return get_mongodb_cache_adapter()
        except ImportError as e:
            logger.error(f"âŒ MongoDBé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_tushare_adapter(self):
        """èŽ·å–Tushareæä¾›å™¨ï¼ˆåŽŸadapterå·²åºŸå¼ƒï¼ŒçŽ°åœ¨ç›´æŽ¥ä½¿ç”¨providerï¼‰"""
        try:
            from .providers.china.tushare import get_tushare_provider

            return get_tushare_provider()
        except ImportError as e:
            logger.error(f"âŒ Tushareæä¾›å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_akshare_adapter(self):
        """èŽ·å–AKShareé€‚é…å™¨"""
        try:
            from .providers.china.akshare import get_akshare_provider

            return get_akshare_provider()
        except ImportError as e:
            logger.error(f"âŒ AKShareé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_baostock_adapter(self):
        """èŽ·å–BaoStocké€‚é…å™¨"""
        try:
            from .providers.china.baostock import get_baostock_provider

            return get_baostock_provider()
        except ImportError as e:
            logger.error(f"âŒ BaoStocké€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    # TDX é€‚é…å™¨å·²ç§»é™¤
    # def _get_tdx_adapter(self):
    #     """èŽ·å–TDXé€‚é…å™¨ (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return None

    def _get_cached_data(
        self,
        symbol: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        max_age_hours: int = 24,
    ) -> Optional[pd.DataFrame]:
        """
        ä»Žç¼“å­˜èŽ·å–æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_age_hours: æœ€å¤§ç¼“å­˜æ—¶é—´ï¼ˆå°æ—¶ï¼‰

        Returns:
            DataFrame: ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æžœæ²¡æœ‰åˆ™è¿”å›žNone
        """
        if not self.cache_enabled or not self.cache_manager:
            return None

        try:
            cache_key = self.cache_manager.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                max_age_hours=max_age_hours,
            )

            if cache_key:
                cached_data = self.cache_manager.load_stock_data(cache_key)
                if (
                    cached_data is not None
                    and hasattr(cached_data, "empty")
                    and not cached_data.empty
                ):
                    logger.debug(f"ðŸ“¦ ä»Žç¼“å­˜èŽ·å–{symbol}æ•°æ®: {len(cached_data)}æ¡")
                    return cached_data
        except Exception as e:
            logger.warning(f"âš ï¸ ä»Žç¼“å­˜è¯»å–æ•°æ®å¤±è´¥: {e}")

        return None

    def _save_to_cache(
        self,
        symbol: str,
        data: pd.DataFrame,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        if not self.cache_enabled or not self.cache_manager:
            return

        try:
            if data is not None and hasattr(data, "empty") and not data.empty:
                self.cache_manager.save_stock_data(symbol, data, start_date, end_date)
                logger.debug(f"ðŸ’¾ ä¿å­˜{symbol}æ•°æ®åˆ°ç¼“å­˜: {len(data)}æ¡")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜æ•°æ®åˆ°ç¼“å­˜å¤±è´¥: {e}")

    def _get_smart_ttl(self, data_category: str) -> int:
        """
        èŽ·å–åˆ†çº§ç¼“å­˜TTLï¼ˆæ”¯æŒè´¢æŠ¥å‘å¸ƒæ—¥æœŸæ„ŸçŸ¥ï¼‰

        ä½¿ç”¨ SmartCache çš„åˆ†çº§ç¼“å­˜ç­–ç•¥ï¼š
        - L1ï¼ˆå®žæ—¶ï¼‰: ä¼°å€¼æŒ‡æ ‡ï¼Œ1å°æ—¶ç¼“å­˜
        - L2ï¼ˆå­£åº¦ï¼‰: è´¢æŠ¥æ•°æ®ï¼Œ7å¤©ç¼“å­˜ï¼ˆè´¢æŠ¥æ—¥1å°æ—¶ï¼‰
        - L3ï¼ˆé•¿æœŸï¼‰: åˆ†çº¢/åŸºæœ¬é¢ï¼Œ30å¤©ç¼“å­˜

        Args:
            data_category: æ•°æ®ç±»åˆ«ï¼ˆvaluation/financial/dividendç­‰ï¼‰

        Returns:
            int: ç¼“å­˜TTLï¼ˆç§’ï¼‰
        """
        from tradingagents.dataflows.cache.smart_cache import SmartCache

        cache = SmartCache(self.cache_manager)
        return cache.get_ttl_with_calendar(data_category)

    def _get_storage_location(self, data_category: str) -> str:
        """
        èŽ·å–æ•°æ®ç±»åž‹çš„å­˜å‚¨ä½ç½®

        Args:
            data_category: æ•°æ®ç±»åˆ«

        Returns:
            str: å­˜å‚¨ä½ç½®ï¼ˆredis/mongodbï¼‰
        """
        from tradingagents.dataflows.cache.smart_cache import SmartCache

        cache = SmartCache(self.cache_manager)
        return cache.get_storage_location(data_category)

    def _get_volume_safely(self, data: pd.DataFrame) -> float:
        """
        å®‰å…¨èŽ·å–æˆäº¤é‡æ•°æ®

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame

        Returns:
            float: æˆäº¤é‡ï¼ˆæ‰‹ï¼‰ï¼Œå¦‚æžœèŽ·å–å¤±è´¥è¿”å›ž0

        é‡è¦è¯´æ˜Ž - 2026-01-30 å•ä½æ ‡å‡†åŒ–ï¼š
        1. æ‰€æœ‰æ•°æ®æºï¼ˆTushare/AKShare/BaoStockï¼‰ç»Ÿä¸€è¿”å›ž"æ‰‹"å•ä½
        2. MongoDB ä¸­å­˜å‚¨çš„ volume å­—æ®µå•ä½æ˜¯"æ‰‹"ï¼ˆ2026-01-30å·²ä¿®å¤ï¼Œä¹‹å‰é”™è¯¯åœ°å­˜ä¸º"è‚¡"ï¼‰
        3. æ˜¾ç¤ºæ—¶ç›´æŽ¥æ ‡æ³¨ä¸º"æ‰‹"ï¼Œæ— éœ€è½¬æ¢

        åŽ†å²ä¿®å¤è®°å½•ï¼š
        - 2026-01-30 ä¿®å¤ï¼šAppå±‚ï¼ˆhistorical_data_service.py, tushare_adapter.py, akshare_adapter.pyï¼‰
          ç§»é™¤äº†æ‰‹â†’è‚¡çš„è½¬æ¢ï¼ŒçŽ°åœ¨ MongoDB æ­£ç¡®å­˜å‚¨"æ‰‹"å•ä½
        - ä¹‹å‰é—®é¢˜ï¼šAppå±‚æ›¾é”™è¯¯åœ°å°†"æ‰‹"Ã—100è½¬æ¢ä¸º"è‚¡"å­˜å…¥MongoDBï¼Œå¯¼è‡´æ˜¾ç¤ºæ”¾å¤§100å€
        - æ•°æ®æ¸…ç†ï¼šéœ€è¦æ¸…é™¤2026-01-30ä¹‹å‰çš„åŽ†å²æ•°æ®ï¼Œé‡æ–°å¯¼å…¥
        """
        try:
            if "volume" in data.columns:
                volume_raw = data["volume"].iloc[-1]
                # ðŸ”§ FIX: å•ä½ç»Ÿä¸€ä¸º"æ‰‹"ï¼Œç›´æŽ¥è¿”å›žåŽŸå§‹å€¼
                return float(volume_raw) if volume_raw else 0
            elif "vol" in data.columns:
                volume_raw = data["vol"].iloc[-1]
                # vol å­—æ®µåŒæ ·å·²ç»æ˜¯"æ‰‹"å•ä½
                return float(volume_raw) if volume_raw else 0
            else:
                return 0
        except Exception:
            return 0

    def _format_stock_data_response(
        self,
        data: pd.DataFrame,
        symbol: str,
        stock_name: str,
        start_date: str,
        end_date: str,
        realtime_quote: Dict[str, Any] = None,  # ðŸ†• ä¿®æ”¹ï¼šæŽ¥æ”¶å®Œæ•´å®žæ—¶è¡Œæƒ…å­—å…¸
    ) -> str:
        """
        æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®å“åº”ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame
            symbol: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            realtime_quote: å®žæ—¶è¡Œæƒ…å­—å…¸ï¼ŒåŒ…å« price, open, high, low, volume ç­‰

        Returns:
            str: æ ¼å¼åŒ–çš„æ•°æ®æŠ¥å‘Šï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰
        """
        try:
            # ðŸ”§ ç¡®ä¿æ•°æ®æœ‰æ—¥æœŸåˆ—
            if "date" not in data.columns and "trade_date" not in data.columns:
                logger.warning(f"âš ï¸ [æ•°æ®æ ¼å¼å¼‚å¸¸] {symbol} æ•°æ®ç¼ºå°‘æ—¥æœŸåˆ—ï¼Œå°è¯•ä¿®å¤...")
                if isinstance(data.index, pd.DatetimeIndex) and len(data) > 0:
                    data["date"] = data.index
                    logger.info(f"âœ… [æ—¥æœŸä¿®å¤] ä»Žç´¢å¼•æ¢å¤æ—¥æœŸåˆ—")
                else:
                    logger.error(
                        f"âŒ [æ•°æ®æ ¼å¼å¼‚å¸¸] æ— æ³•ä¿®å¤ï¼šæ•°æ®ä¸ºç©ºæˆ–ç´¢å¼•ä¸æ˜¯æ—¶é—´ç±»åž‹"
                    )
                    return f"âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘æ—¥æœŸåˆ—"

            # ðŸ”§ æ£€æŸ¥å¹¶åˆå¹¶å®žæ—¶è¡Œæƒ…æ•°æ®
            if realtime_quote and realtime_quote.get("date") == end_date:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å½“å¤©æ•°æ®
                    has_today_data = False
                    if not data.empty:
                        last_date = pd.to_datetime(
                            data.iloc[-1].get("date", data.iloc[-1].get("trade_date"))
                        ).strftime("%Y-%m-%d")
                        if last_date == end_date:
                            has_today_data = True
                            # å¦‚æžœå·²æœ‰å½“å¤©æ•°æ®ï¼ˆå¯èƒ½æ˜¯æ”¶ç›˜åŽçš„åŽ†å²æ•°æ®ï¼‰ï¼Œç”¨å®žæ—¶æ•°æ®è¦†ç›–ï¼ˆé€šå¸¸å®žæ—¶æ•°æ®æ›´æ–°ï¼‰
                            # æˆ–è€…å¦‚æžœæ˜¯ç›˜ä¸­ï¼ŒåŽ†å²æ•°æ®å¯èƒ½ä¸å®Œæ•´
                            pass

                    if not has_today_data:
                        logger.info(
                            f"ðŸ”„ [å®žæ—¶æ•°æ®åˆå¹¶] å°†å®žæ—¶è¡Œæƒ…è¿½åŠ åˆ°åŽ†å²æ•°æ®: {end_date}"
                        )

                        # æž„å»ºæ–°è¡Œ
                        new_row = {
                            "date": pd.to_datetime(end_date),
                            "trade_date": end_date,
                            "open": realtime_quote.get("open", 0.0),
                            "high": realtime_quote.get("high", 0.0),
                            "low": realtime_quote.get("low", 0.0),
                            "close": realtime_quote.get("price", 0.0),
                            "volume": realtime_quote.get("volume", 0),
                            "amount": realtime_quote.get("amount", 0.0),
                            "code": symbol,
                        }

                        # åˆ›å»ºDataFrameå¹¶åˆå¹¶
                        new_df = pd.DataFrame([new_row])
                        # ç¡®ä¿åˆ—ååŒ¹é…
                        for col in data.columns:
                            if col not in new_df.columns:
                                new_df[col] = (
                                    0
                                    if pd.api.types.is_numeric_dtype(data[col])
                                    else None
                                )

                        data = pd.concat([data, new_df], ignore_index=True)
                        logger.info(
                            f"âœ… [å®žæ—¶æ•°æ®åˆå¹¶] æˆåŠŸè¿½åŠ å½“å¤©æ•°æ®, æœ€æ–°ä»·æ ¼: {new_row['close']}"
                        )
                except Exception as e:
                    logger.warning(f"âš ï¸ [å®žæ—¶æ•°æ®åˆå¹¶] è¿½åŠ å¤±è´¥: {e}")

            original_data_count = len(data)
            logger.info(
                f"ðŸ“Š [æŠ€æœ¯æŒ‡æ ‡] å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ŒåŽŸå§‹æ•°æ®: {original_data_count}æ¡"
            )

            # ðŸ”§ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆä½¿ç”¨å®Œæ•´æ•°æ®ï¼‰
            # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæŽ’åº
            # ðŸ”§ FIX: Handle both 'date' and 'trade_date' columns
            # ðŸ”¥ FIX: é¦–å…ˆæ£€æŸ¥å¹¶è§£å†³ date åˆ—å’Œç´¢å¼•çš„æ­§ä¹‰é—®é¢˜
            if "date" in data.index.names and "date" in data.columns:
                logger.debug(
                    f"âš ï¸ [DataFrameä¿®å¤] {symbol} dateæ—¢æ˜¯ç´¢å¼•åˆæ˜¯åˆ—ï¼Œé‡ç½®ç´¢å¼•..."
                )
                data = data.reset_index(drop=True)

            date_col = None
            if "date" in data.columns:
                date_col = "date"
            elif "trade_date" in data.columns:
                date_col = "trade_date"
                # Create 'date' column from 'trade_date' for consistency
                # MongoDB stores trade_date as YYYY-MM-DD string format
                # ðŸ”¥ FIX: ç¡®ä¿æ²¡æœ‰ date ç´¢å¼•åŽå†åˆ›å»º date åˆ—
                if "date" in data.index.names:
                    data = data.reset_index(drop=True)
                if not pd.api.types.is_datetime64_any_dtype(data["trade_date"]):
                    data["date"] = pd.to_datetime(
                        data["trade_date"], format="%Y-%m-%d", errors="coerce"
                    )
                    date_col = "date"

            if date_col:
                if not pd.api.types.is_datetime64_any_dtype(data[date_col]):
                    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
                # ðŸ”¥ FIX: ç¡®ä¿æŽ’åºå‰æ²¡æœ‰ç´¢å¼•æ­§ä¹‰
                if date_col in data.index.names:
                    data = data.reset_index(drop=True)
                data = data.sort_values(by=date_col)

            # ðŸ”¥ ç»Ÿä¸€ä»·æ ¼ç¼“å­˜å¤„ç†ï¼šåœ¨è®¡ç®—æŒ‡æ ‡å‰ä¿®æ­£æ•°æ®
            try:
                from tradingagents.utils.price_cache import get_price_cache

                cache = get_price_cache()
                cached_price = cache.get_price(symbol)

                # å¦‚æžœæœ‰å®žæ—¶è¡Œæƒ…ï¼Œä¼˜å…ˆä½¿ç”¨
                if realtime_quote and realtime_quote.get("price"):
                    cached_price = realtime_quote.get("price")

                if cached_price is not None and not data.empty:
                    # èŽ·å–æœ€åŽä¸€è¡Œæ•°æ®çš„åŽŸå§‹ä»·æ ¼
                    last_idx = data.index[-1]
                    original_price = data.at[last_idx, "close"]

                    # åªæœ‰å½“å·®å¼‚å­˜åœ¨æ—¶æ‰ä¿®æ­£
                    if abs(original_price - cached_price) > 0.0001:
                        logger.info(
                            f"ðŸ”„ [ä»·æ ¼ç»Ÿä¸€] ä¿®æ­£DataFrameæ•°æ®: {symbol} Â¥{original_price:.2f} -> Â¥{cached_price:.2f}"
                        )
                        data.at[last_idx, "close"] = cached_price
                        # åŒæ—¶ä¿®æ­£ high/low å¦‚æžœå®ƒä»¬ä¸Ž new close å†²çª
                        if cached_price > data.at[last_idx, "high"]:
                            data.at[last_idx, "high"] = cached_price
                        if cached_price < data.at[last_idx, "low"]:
                            data.at[last_idx, "low"] = cached_price
            except Exception as e:
                logger.warning(f"âš ï¸ [ä»·æ ¼ç»Ÿä¸€] DataFrameä¿®æ­£å¤±è´¥: {e}")

            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            data["ma5"] = data["close"].rolling(window=5, min_periods=1).mean()
            data["ma10"] = data["close"].rolling(window=10, min_periods=1).mean()
            data["ma20"] = data["close"].rolling(window=20, min_periods=1).mean()
            data["ma60"] = data["close"].rolling(window=60, min_periods=1).mean()

            # è®¡ç®—RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰- åŒèŠ±é¡ºé£Žæ ¼ï¼šä½¿ç”¨ä¸­å›½å¼SMAï¼ˆEMA with adjust=Trueï¼‰
            # å‚è€ƒï¼šhttps://blog.csdn.net/u011218867/article/details/117427927
            # åŒèŠ±é¡º/é€šè¾¾ä¿¡çš„RSIä½¿ç”¨SMAå‡½æ•°ï¼Œç­‰ä»·äºŽpandasçš„ewm(com=N-1, adjust=True)
            delta = data["close"].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)

            # RSI6 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain6 = gain.ewm(com=5, adjust=True).mean()  # com = N - 1
            avg_loss6 = loss.ewm(com=5, adjust=True).mean()
            rs6 = avg_gain6 / avg_loss6.replace(0, np.nan)
            data["rsi6"] = 100 - (100 / (1 + rs6))

            # RSI12 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain12 = gain.ewm(com=11, adjust=True).mean()
            avg_loss12 = loss.ewm(com=11, adjust=True).mean()
            rs12 = avg_gain12 / avg_loss12.replace(0, np.nan)
            data["rsi12"] = 100 - (100 / (1 + rs12))

            # RSI24 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain24 = gain.ewm(com=23, adjust=True).mean()
            avg_loss24 = loss.ewm(com=23, adjust=True).mean()
            rs24 = avg_gain24 / avg_loss24.replace(0, np.nan)
            data["rsi24"] = 100 - (100 / (1 + rs24))

            # ä¿ç•™RSI14ä½œä¸ºå›½é™…æ ‡å‡†å‚è€ƒï¼ˆä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡ï¼‰
            gain14 = gain.rolling(window=14, min_periods=1).mean()
            loss14 = loss.rolling(window=14, min_periods=1).mean()
            rs14 = gain14 / loss14.replace(0, np.nan)
            data["rsi14"] = 100 - (100 / (1 + rs14))

            # è®¡ç®—MACD
            ema12 = data["close"].ewm(span=12, adjust=False).mean()
            ema26 = data["close"].ewm(span=26, adjust=False).mean()
            data["macd_dif"] = ema12 - ema26
            data["macd_dea"] = data["macd_dif"].ewm(span=9, adjust=False).mean()
            data["macd"] = (data["macd_dif"] - data["macd_dea"]) * 2

            # è®¡ç®—å¸ƒæž—å¸¦
            data["boll_mid"] = data["close"].rolling(window=20, min_periods=1).mean()
            std = data["close"].rolling(window=20, min_periods=1).std()
            data["boll_upper"] = data["boll_mid"] + 2 * std
            data["boll_lower"] = data["boll_mid"] - 2 * std

            logger.info(f"âœ… [æŠ€æœ¯æŒ‡æ ‡] æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")

            # ðŸ”§ åªä¿ç•™æœ€åŽ3-5å¤©çš„æ•°æ®ç”¨äºŽå±•ç¤ºï¼ˆå‡å°‘tokenæ¶ˆè€—ï¼‰
            display_rows = min(5, len(data))
            display_data = data.tail(display_rows)
            latest_data = data.iloc[-1]

            # ðŸ” [è°ƒè¯•æ—¥å¿—] æ‰“å°æœ€è¿‘5å¤©çš„åŽŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
            logger.info(f"ðŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥æ•°æ® =====")
            for i, (idx, row) in enumerate(display_data.iterrows(), 1):
                logger.info(f"ðŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ç¬¬{i}å¤© ({row.get('date', 'N/A')}):")
                logger.info(
                    f"   ä»·æ ¼: å¼€={row.get('open', 0):.2f}, é«˜={row.get('high', 0):.2f}, ä½Ž={row.get('low', 0):.2f}, æ”¶={row.get('close', 0):.2f}"
                )
                logger.info(
                    f"   MA: MA5={row.get('ma5', 0):.2f}, MA10={row.get('ma10', 0):.2f}, MA20={row.get('ma20', 0):.2f}, MA60={row.get('ma60', 0):.2f}"
                )
                logger.info(
                    f"   MACD: DIF={row.get('macd_dif', 0):.4f}, DEA={row.get('macd_dea', 0):.4f}, MACD={row.get('macd', 0):.4f}"
                )
                logger.info(
                    f"   RSI: RSI6={row.get('rsi6', 0):.2f}, RSI12={row.get('rsi12', 0):.2f}, RSI24={row.get('rsi24', 0):.2f} (åŒèŠ±é¡ºé£Žæ ¼)"
                )
                logger.info(f"   RSI14: {row.get('rsi14', 0):.2f} (å›½é™…æ ‡å‡†)")
                logger.info(
                    f"   BOLL: ä¸Š={row.get('boll_upper', 0):.2f}, ä¸­={row.get('boll_mid', 0):.2f}, ä¸‹={row.get('boll_lower', 0):.2f}"
                )

            logger.info(f"ðŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æ•°æ®è¯¦æƒ…ç»“æŸ =====")

            # è®¡ç®—æœ€æ–°ä»·æ ¼å’Œæ¶¨è·Œå¹…
            # ðŸ†• ä¼˜å…ˆä½¿ç”¨å®žæ—¶ä»·æ ¼
            if realtime_quote and realtime_quote.get("price"):
                latest_price = realtime_quote.get("price")
                price_source = "å®žæ—¶"
                logger.info(f"âœ… [ä»·æ ¼ç­–ç•¥] ä½¿ç”¨å®žæ—¶ä»·æ ¼: Â¥{latest_price:.2f}")
            else:
                latest_price = latest_data.get("close", 0)
                price_source = "åŽ†å²"
                logger.info(f"â„¹ï¸ [ä»·æ ¼ç­–ç•¥] ä½¿ç”¨åŽ†å²ä»·æ ¼: Â¥{latest_price:.2f}")

            # ðŸ”¥ ç¼“å­˜æ›´æ–°ï¼šç¡®ä¿å½“å‰ä»·æ ¼è¢«ç¼“å­˜ï¼ˆä½œä¸ºçœŸç†æ¥æºï¼‰
            try:
                from tradingagents.utils.price_cache import get_price_cache

                # å¦‚æžœç¼“å­˜ä¸­æ²¡æœ‰ï¼ˆæˆ–è€…æˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªèŽ·å–æ•°æ®çš„ï¼‰ï¼Œæ›´æ–°ç¼“å­˜
                cache = get_price_cache()
                if cache.get_price(symbol) is None:
                    cache.update(symbol, latest_price)
            except Exception as e:
                logger.warning(f"âš ï¸ [ä»·æ ¼ç»Ÿä¸€] ç¼“å­˜æ›´æ–°å¤±è´¥: {e}")

            prev_close = (
                data.iloc[-2].get("close", latest_price)
                if len(data) > 1
                else latest_price
            )

            change = latest_price - prev_close
            change_pct = (change / prev_close * 100) if prev_close != 0 else 0

            # èŽ·å–æœ€æ–°æ•°æ®çš„å®žé™…æ—¥æœŸ
            latest_data_date = latest_data.get("date", None)
            if (
                latest_data_date is None
                or latest_data_date == "N/A"
                or pd.isna(latest_data_date)
            ):
                if isinstance(data.index, pd.DatetimeIndex) and len(data) > 0:
                    latest_data_date = data.index[-1]
                    logger.info(f"ðŸ”§ [æ—¥æœŸä¿®å¤] ä»Žç´¢å¼•æ¢å¤æ—¥æœŸ: {latest_data_date}")
                else:
                    latest_data_date = "N/A"
                    logger.warning(
                        f"âš ï¸ [æ—¥æœŸå¼‚å¸¸] æ— æ³•èŽ·å–æ•°æ®æ—¥æœŸï¼Œdataä¸ºç©ºæˆ–ç´¢å¼•ä¸æ˜¯æ—¶é—´ç±»åž‹"
                    )

            if isinstance(latest_data_date, pd.Timestamp):
                latest_data_date = latest_data_date.strftime("%Y-%m-%d")
            elif isinstance(latest_data_date, str):
                if len(latest_data_date) == 8 and latest_data_date.isdigit():
                    latest_data_date = f"{latest_data_date[:4]}-{latest_data_date[4:6]}-{latest_data_date[6:8]}"
                elif "-" in latest_data_date:
                    pass  # Already in correct format

            logger.info(
                f"ðŸ“… [æœ€æ–°æ•°æ®æ—¥æœŸ] å®žé™…æ•°æ®æ—¥æœŸ: {latest_data_date}, è¯·æ±‚ç»“æŸæ—¥æœŸ: {end_date}"
            )

            # âš ï¸ æ™ºèƒ½æ£€æŸ¥æ•°æ®æ—¥æœŸæ˜¯å¦ä¸ºæœ€æ–°
            from datetime import datetime

            # åˆ¤æ–­ end_date æ˜¯å¦æ˜¯éžäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰
            def _is_weekend(date_str: str) -> bool:
                """æ£€æŸ¥æ—¥æœŸæ˜¯å¦æ˜¯å‘¨æœ«"""
                try:
                    date_obj = datetime.strptime(date_str, "%Y-%m-%d")
                    return date_obj.weekday() >= 5  # 5=å‘¨å…­, 6=å‘¨æ—¥
                except:
                    return False

            is_end_date_weekend = _is_weekend(end_date)

            # åˆå§‹åŒ–å˜é‡
            result = ""
            date_warning = ""

            if latest_data_date != "N/A" and latest_data_date != end_date:
                if is_end_date_weekend:
                    # end_date æ˜¯å‘¨æœ«ï¼ˆå‘¨å…­/å‘¨æ—¥ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸åº”è¯¥è­¦å‘Š
                    logger.info(
                        f"ðŸ“… [æ•°æ®æ—¥æœŸæ£€æŸ¥] end_date={end_date} æ˜¯éžäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰ï¼Œ"
                        f"ä½¿ç”¨æœ€æ–°æ•°æ®æ—¥æœŸ {latest_data_date}ï¼Œè¿™æ˜¯æ­£å¸¸è¡Œä¸º"
                    )
                    # æ›´æ–° end_date æ˜¾ç¤ºä¸ºå®žé™…ä½¿ç”¨çš„äº¤æ˜“æ—¥
                    result = f"ðŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†æžæ•°æ®\n"
                    result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {latest_data_date} (å®žé™…ä½¿ç”¨äº¤æ˜“æ—¥)\n"
                    result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"
                else:
                    # end_date æ˜¯å·¥ä½œæ—¥ä½†æ•°æ®ä¸æ–°é²œï¼Œå¯èƒ½æ˜¯å»¶è¿Ÿ
                    logger.warning(
                        f"âš ï¸ [æ•°æ®å»¶è¿Ÿè­¦å‘Š] æœ€æ–°æ•°æ®æ—¥æœŸ({latest_data_date})ä¸Žè¯·æ±‚æ—¥æœŸ({end_date})ä¸ä¸€è‡´ï¼Œå¯èƒ½æ˜¯æ•°æ®æœªæ›´æ–°"
                    )
                    date_warning = f"âš ï¸ æ³¨æ„ï¼šæœ€æ–°æ•°æ®æ—¥æœŸä¸º {latest_data_date}ï¼Œéžå½“å‰åˆ†æžæ—¥æœŸ {end_date}\n"
                    result = f"ðŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†æžæ•°æ®\n"
                    result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}\n"
                    result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"
            else:
                result = f"ðŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†æžæ•°æ®\n"
                result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}\n"
                result += f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_data_date}\n"

            result += (
                f"æ•°æ®æ¡æ•°: {original_data_count}æ¡ (å±•ç¤ºæœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥)\n"
            )
            if date_warning:
                result += f"\n{date_warning}"
            result += f"\n"

            result += (
                f"ðŸ’° æœ€æ–°ä»·æ ¼: Â¥{latest_price:.2f} (æ•°æ®æ—¥æœŸ: {latest_data_date})\n"
            )
            # ðŸ”§ FIX: æ˜Žç¡®æ ‡æ³¨å•ä½ï¼Œé¿å…æ¶¨è·Œé¢ï¼ˆå…ƒï¼‰å’Œæ¶¨è·Œå¹…ï¼ˆ%ï¼‰æ··æ·†
            result += f"ðŸ“ˆ æ¶¨è·Œé¢: {change:+.2f}å…ƒ (æ¶¨è·Œå¹…: {change_pct:+.2f}%)\n\n"

            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            result += f"ðŸ“Š ç§»åŠ¨å¹³å‡çº¿ (MA):\n"
            result += f"   MA5:  Â¥{latest_data['ma5']:.2f}"
            if latest_price > latest_data["ma5"]:
                result += " (ä»·æ ¼åœ¨MA5ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA5ä¸‹æ–¹ â†“)\n"

            result += f"   MA10: Â¥{latest_data['ma10']:.2f}"
            if latest_price > latest_data["ma10"]:
                result += " (ä»·æ ¼åœ¨MA10ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA10ä¸‹æ–¹ â†“)\n"

            result += f"   MA20: Â¥{latest_data['ma20']:.2f}"
            if latest_price > latest_data["ma20"]:
                result += " (ä»·æ ¼åœ¨MA20ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA20ä¸‹æ–¹ â†“)\n"

            result += f"   MA60: Â¥{latest_data['ma60']:.2f}"
            if latest_price > latest_data["ma60"]:
                result += " (ä»·æ ¼åœ¨MA60ä¸Šæ–¹ â†‘)\n\n"
            else:
                result += " (ä»·æ ¼åœ¨MA60ä¸‹æ–¹ â†“)\n\n"

            # MACDæŒ‡æ ‡
            result += f"ðŸ“ˆ MACDæŒ‡æ ‡:\n"
            result += f"   DIF:  {latest_data['macd_dif']:.3f}\n"
            result += f"   DEA:  {latest_data['macd_dea']:.3f}\n"
            result += f"   MACD: {latest_data['macd']:.3f}"
            if latest_data["macd"] > 0:
                result += " (å¤šå¤´ â†‘)\n"
            else:
                result += " (ç©ºå¤´ â†“)\n"

            # åˆ¤æ–­é‡‘å‰/æ­»å‰
            if len(data) > 1:
                prev_dif = data.iloc[-2]["macd_dif"]
                prev_dea = data.iloc[-2]["macd_dea"]
                curr_dif = latest_data["macd_dif"]
                curr_dea = latest_data["macd_dea"]

                if prev_dif <= prev_dea and curr_dif > curr_dea:
                    result += "   âš ï¸ MACDé‡‘å‰ä¿¡å·ï¼ˆDIFä¸Šç©¿DEAï¼‰\n\n"
                elif prev_dif >= prev_dea and curr_dif < curr_dea:
                    result += "   âš ï¸ MACDæ­»å‰ä¿¡å·ï¼ˆDIFä¸‹ç©¿DEAï¼‰\n\n"
                else:
                    result += "\n"
            else:
                result += "\n"

            # RSIæŒ‡æ ‡ - åŒèŠ±é¡ºé£Žæ ¼ (6, 12, 24)
            rsi6 = latest_data["rsi6"]
            rsi12 = latest_data["rsi12"]
            rsi24 = latest_data["rsi24"]
            result += f"ðŸ“‰ RSIæŒ‡æ ‡ (åŒèŠ±é¡ºé£Žæ ¼):\n"
            result += f"   RSI6:  {rsi6:.2f}"
            if rsi6 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi6 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI12: {rsi12:.2f}"
            if rsi12 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi12 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI24: {rsi24:.2f}"
            if rsi24 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi24 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            # åˆ¤æ–­RSIè¶‹åŠ¿
            if rsi6 > rsi12 > rsi24:
                result += "   è¶‹åŠ¿: å¤šå¤´æŽ’åˆ— â†‘\n\n"
            elif rsi6 < rsi12 < rsi24:
                result += "   è¶‹åŠ¿: ç©ºå¤´æŽ’åˆ— â†“\n\n"
            else:
                result += "   è¶‹åŠ¿: éœ‡è¡æ•´ç† â†”\n\n"

            # å¸ƒæž—å¸¦
            result += f"ðŸ“Š å¸ƒæž—å¸¦ (BOLL):\n"
            result += f"   ä¸Šè½¨: Â¥{latest_data['boll_upper']:.2f}\n"
            result += f"   ä¸­è½¨: Â¥{latest_data['boll_mid']:.2f}\n"
            result += f"   ä¸‹è½¨: Â¥{latest_data['boll_lower']:.2f}\n"

            # åˆ¤æ–­ä»·æ ¼åœ¨å¸ƒæž—å¸¦çš„ä½ç½®
            boll_position = (
                (latest_price - latest_data["boll_lower"])
                / (latest_data["boll_upper"] - latest_data["boll_lower"])
                * 100
            )
            result += f"   ä»·æ ¼ä½ç½®: {boll_position:.1f}%"
            if boll_position >= 100:
                result += " (å·²çªç ´ä¸Šè½¨ï¼Œå¤šå¤´ç¡®è®¤ä¿¡å·ï¼ðŸ”´)"
            elif boll_position >= 80:
                result += " (æŽ¥è¿‘ä¸Šè½¨ï¼Œå¯èƒ½è¶…ä¹° âš ï¸)"
            else:
                result += " (ä¸­æ€§åŒºåŸŸ)"

            # ä»·æ ¼ç»Ÿè®¡
            result += f"ðŸ“Š ä»·æ ¼ç»Ÿè®¡ (æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥):\n"
            result += f"   æœ€é«˜ä»·: Â¥{display_data['high'].max():.2f}\n"
            result += f"   æœ€ä½Žä»·: Â¥{display_data['low'].min():.2f}\n"
            result += f"   å¹³å‡ä»·: Â¥{display_data['close'].mean():.2f}\n"

            # ========== æˆäº¤é‡ç»Ÿè®¡ï¼ˆå¢žå¼ºï¼‰==========
            # å•æ—¥æˆäº¤é‡ï¼ˆæœ€æ–°ä¸€æ—¥ï¼‰
            volume_latest = self._get_volume_safely(display_data)

            # 5æ—¥å‡é‡å’Œ10æ—¥å‡é‡
            volume_avg_5 = display_data['volume'].tail(5).mean() if len(display_data) >= 5 else volume_latest
            volume_avg_10 = display_data['volume'].tail(10).mean() if len(display_data) >= 10 else volume_latest

            result += f"\nðŸ“Š æˆäº¤é‡åˆ†æž:\n"
            result += f"   å•æ—¥æˆäº¤é‡: {volume_latest:,.0f}æ‰‹\n"
            result += f"   5æ—¥å‡é‡: {volume_avg_5:,.0f}æ‰‹\n"
            result += f"   10æ—¥å‡é‡: {volume_avg_10:,.0f}æ‰‹\n"

            # é‡æ¯”åˆ†æžï¼ˆåˆ¤æ–­æ”¾é‡/ç¼©é‡ï¼‰
            if volume_avg_5 > 0:
                volume_ratio = volume_latest / volume_avg_5
                if volume_ratio >= 2.0:
                    level = "å·¨é‡"
                elif volume_ratio >= 1.5:
                    level = "æ”¾é‡"
                elif volume_ratio >= 0.8:
                    level = "å¹³é‡"
                else:
                    level = "ç¼©é‡"
                result += f"   é‡æ¯”: {volume_ratio:.2f}å€ ({level})\n"

            return result

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–æ•°æ®å“åº”å¤±è´¥: {e}", exc_info=True)
            return f"âŒ æ ¼å¼åŒ–{symbol}æ•°æ®å¤±è´¥: {e}"

    def get_stock_dataframe(
        self,
        symbol: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        period: str = "daily",
    ) -> pd.DataFrame:
        """
        èŽ·å–è‚¡ç¥¨æ•°æ®çš„ DataFrame æŽ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily

        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ® DataFrameï¼Œåˆ—æ ‡å‡†ï¼šopen, high, low, close, vol, amount, date
        """
        logger.info(
            f"ðŸ“Š [DataFrameæŽ¥å£] èŽ·å–è‚¡ç¥¨æ•°æ®: {symbol} ({start_date} åˆ° {end_date})"
        )

        try:
            # å°è¯•å½“å‰æ•°æ®æº
            df = None
            if self.current_source == ChinaDataSource.MONGODB:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                    get_mongodb_cache_adapter,
                )

                adapter = get_mongodb_cache_adapter()
                df = adapter.get_historical_data(
                    symbol, start_date, end_date, period=period
                )
            elif self.current_source == ChinaDataSource.TUSHARE:
                from .providers.china.tushare import get_tushare_provider

                provider = get_tushare_provider()
                df = provider.get_daily_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.AKSHARE:
                from .providers.china.akshare import get_akshare_provider

                provider = get_akshare_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                from .providers.china.baostock import get_baostock_provider

                provider = get_baostock_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)

            if df is not None and not df.empty:
                logger.info(
                    f"âœ… [DataFrameæŽ¥å£] ä»Ž {self.current_source.value} èŽ·å–æˆåŠŸ: {len(df)}æ¡"
                )
                return self._standardize_dataframe(df)

            # é™çº§åˆ°å…¶ä»–æ•°æ®æº
            logger.warning(
                f"âš ï¸ [DataFrameæŽ¥å£] {self.current_source.value} å¤±è´¥ï¼Œå°è¯•é™çº§"
            )
            for source in self.available_sources:
                if source == self.current_source:
                    continue
                try:
                    if source == ChinaDataSource.MONGODB:
                        from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                            get_mongodb_cache_adapter,
                        )

                        adapter = get_mongodb_cache_adapter()
                        df = adapter.get_historical_data(
                            symbol, start_date, end_date, period=period
                        )
                    elif source == ChinaDataSource.TUSHARE:
                        from .providers.china.tushare import get_tushare_provider

                        provider = get_tushare_provider()
                        df = provider.get_daily_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.AKSHARE:
                        from .providers.china.akshare import get_akshare_provider

                        provider = get_akshare_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.BAOSTOCK:
                        from .providers.china.baostock import get_baostock_provider

                        provider = get_baostock_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)

                    if df is not None and not df.empty:
                        logger.info(
                            f"âœ… [DataFrameæŽ¥å£] é™çº§åˆ° {source.value} æˆåŠŸ: {len(df)}æ¡"
                        )
                        return self._standardize_dataframe(df)
                except Exception as e:
                    logger.warning(f"âš ï¸ [DataFrameæŽ¥å£] {source.value} å¤±è´¥: {e}")
                    continue

            logger.error(f"âŒ [DataFrameæŽ¥å£] æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥: {symbol}")
            return pd.DataFrame()

        except Exception as e:
            logger.error(f"âŒ [DataFrameæŽ¥å£] èŽ·å–å¤±è´¥: {e}", exc_info=True)
            return pd.DataFrame()

    def _standardize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ– DataFrame åˆ—åå’Œæ ¼å¼

        Args:
            df: åŽŸå§‹ DataFrame

        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–åŽçš„ DataFrame
        """
        if df is None or df.empty:
            return pd.DataFrame()

        out = df.copy()

        # åˆ—åæ˜ å°„
        colmap = {
            # English
            "Open": "open",
            "High": "high",
            "Low": "low",
            "Close": "close",
            "Volume": "vol",
            "Amount": "amount",
            "symbol": "code",
            "Symbol": "code",
            # Already lower
            "open": "open",
            "high": "high",
            "low": "low",
            "close": "close",
            "vol": "vol",
            "volume": "vol",
            "amount": "amount",
            "code": "code",
            "date": "date",
            "trade_date": "date",
            # Chinese (AKShare common)
            "æ—¥æœŸ": "date",
            "å¼€ç›˜": "open",
            "æœ€é«˜": "high",
            "æœ€ä½Ž": "low",
            "æ”¶ç›˜": "close",
            "æˆäº¤é‡": "vol",
            "æˆäº¤é¢": "amount",
            "æ¶¨è·Œå¹…": "pct_change",
            "æ¶¨è·Œé¢": "change",
        }
        out = out.rename(columns={c: colmap.get(c, c) for c in out.columns})

        # ç¡®ä¿æ—¥æœŸæŽ’åº
        if "date" in out.columns:
            try:
                # ç¡®ä¿æ—¥æœŸæ˜¯datetimeç±»åž‹ï¼Œä»¥ä¾¿æ­£ç¡®æŽ’åº
                if not pd.api.types.is_datetime64_any_dtype(out["date"]):
                    out["date"] = pd.to_datetime(out["date"])
                out = out.sort_values("date")
            except Exception:
                pass

        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æžœç¼ºå¤±ï¼‰
        if "pct_change" not in out.columns and "close" in out.columns:
            out["pct_change"] = out["close"].pct_change() * 100.0

        return out

    def get_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """
        èŽ·å–å®žæ—¶è¡Œæƒ…æ•°æ® - åªä½¿ç”¨å¤–éƒ¨APIï¼Œä¸ä½¿ç”¨MongoDBç¼“å­˜

        æ”¯æŒé…ç½®ï¼š
        - REALTIME_QUOTE_ENABLED: æ˜¯å¦å¯ç”¨å®žæ—¶è¡Œæƒ…
        - REALTIME_QUOTE_TUSHARE_ENABLED: æ˜¯å¦å¯ç”¨Tushareä½œä¸ºå¤‡é€‰
        - REALTIME_QUOTE_MAX_RETRIES: æœ€å¤§é‡è¯•æ¬¡æ•°
        - REALTIME_QUOTE_RETRY_DELAY: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        - REALTIME_QUOTE_RETRY_BACKOFF: é‡è¯•å»¶è¿Ÿé€€é¿å€æ•°
        - REALTIME_QUOTE_AKSHARE_PRIORITY: AKShareä¼˜å…ˆçº§
        - REALTIME_QUOTE_TUSHARE_PRIORITY: Tushareä¼˜å…ˆçº§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            Dict: å®žæ—¶è¡Œæƒ…æ•°æ®ï¼ŒåŒ…å«price, change, change_pct, volumeç­‰
        """
        # è¯»å–é…ç½®
        config = self._get_realtime_quote_config()

        if not config["enabled"]:
            logger.info(f"ðŸ“Š [å®žæ—¶è¡Œæƒ…] å®žæ—¶è¡Œæƒ…èŽ·å–å·²ç¦ç”¨ï¼Œè·³è¿‡: {symbol}")
            return None

        logger.info(
            f"ðŸ“Š [å®žæ—¶è¡Œæƒ…] èŽ·å–å®žæ—¶è¡Œæƒ…: {symbol} (é‡è¯•æ¬¡æ•°: {config['max_retries']})"
        )

        try:
            # æ ¹æ®ä¼˜å…ˆçº§æŽ’åºæ•°æ®æº
            sources = []
            if config["akshare_priority"] == 1:
                sources.append(("akshare", self._get_akshare_realtime_quote_with_retry))
            if config["tushare_enabled"] and config["tushare_priority"] == 1:
                sources.append(("tushare", self._get_tushare_realtime_quote_with_retry))
            if config["akshare_priority"] == 2:
                sources.append(("akshare", self._get_akshare_realtime_quote_with_retry))
            if config["tushare_enabled"] and config["tushare_priority"] == 2:
                sources.append(("tushare", self._get_tushare_realtime_quote_with_retry))

            # ä¾æ¬¡å°è¯•å„ä¸ªæ•°æ®æº
            for source_name, source_func in sources:
                try:
                    quote = source_func(symbol, config)
                    if quote:
                        logger.info(
                            f"âœ… [å®žæ—¶è¡Œæƒ…-{source_name.upper()}] æˆåŠŸèŽ·å– {symbol} å®žæ—¶è¡Œæƒ…"
                        )
                        self._update_price_cache(symbol, quote.get("price"))
                        return quote
                except Exception as e:
                    logger.warning(f"âš ï¸ [å®žæ—¶è¡Œæƒ…-{source_name.upper()}] èŽ·å–å¤±è´¥: {e}")
                    continue

            # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
            logger.warning(
                f"âš ï¸ [å®žæ—¶è¡Œæƒ…] æ— æ³•èŽ·å– {symbol} çš„å®žæ—¶è¡Œæƒ…ï¼ˆæ‰€æœ‰å¤–éƒ¨APIå¤±è´¥ï¼‰"
            )
            return None

        except Exception as e:
            logger.error(f"âŒ èŽ·å–å®žæ—¶è¡Œæƒ…å¤±è´¥: {e}", exc_info=True)
            return None

    def _get_realtime_quote_config(self) -> Dict:
        """èŽ·å–å®žæ—¶è¡Œæƒ…é…ç½®"""
        return {
            "enabled": os.getenv("REALTIME_QUOTE_ENABLED", "true").lower() == "true",
            "tushare_enabled": os.getenv(
                "REALTIME_QUOTE_TUSHARE_ENABLED", "true"
            ).lower()
            == "true",
            "max_retries": int(os.getenv("REALTIME_QUOTE_MAX_RETRIES", "3")),
            "retry_delay": float(os.getenv("REALTIME_QUOTE_RETRY_DELAY", "1.0")),
            "retry_backoff": float(os.getenv("REALTIME_QUOTE_RETRY_BACKOFF", "2.0")),
            "akshare_priority": int(os.getenv("REALTIME_QUOTE_AKSHARE_PRIORITY", "1")),
            "tushare_priority": int(os.getenv("REALTIME_QUOTE_TUSHARE_PRIORITY", "2")),
        }

    def _get_akshare_realtime_quote_with_retry(
        self, symbol: str, config: Dict
    ) -> Optional[Dict]:
        """å¸¦é‡è¯•çš„AKShareå®žæ—¶è¡Œæƒ…èŽ·å–"""
        max_retries = config["max_retries"]
        retry_delay = config["retry_delay"]
        backoff = config["retry_backoff"]

        for attempt in range(max_retries):
            try:
                quote = self._get_akshare_realtime_quote(symbol)
                if quote:
                    return quote
            except Exception as e:
                logger.warning(
                    f"âš ï¸ [AKShare-é‡è¯•{attempt + 1}/{max_retries}] {symbol}: {e}"
                )
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= backoff

        return None

    def _get_tushare_realtime_quote_with_retry(
        self, symbol: str, config: Dict
    ) -> Optional[Dict]:
        """å¸¦é‡è¯•çš„Tushareå®žæ—¶è¡Œæƒ…èŽ·å–"""
        max_retries = config["max_retries"]
        retry_delay = config["retry_delay"]
        backoff = config["retry_backoff"]

        for attempt in range(max_retries):
            try:
                quote = self._get_tushare_realtime_quote(symbol)
                if quote:
                    return quote
            except Exception as e:
                logger.warning(
                    f"âš ï¸ [Tushare-é‡è¯•{attempt + 1}/{max_retries}] {symbol}: {e}"
                )
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= backoff

        return None

    def _update_price_cache(self, symbol: str, price: float):
        """æ›´æ–°ä»·æ ¼ç¼“å­˜"""
        if price is None:
            return
        try:
            from tradingagents.utils.price_cache import get_price_cache

            get_price_cache().update(symbol, price)
        except Exception as e:
            logger.warning(f"âš ï¸ [å®žæ—¶è¡Œæƒ…] ç¼“å­˜æ›´æ–°å¤±è´¥: {e}")

    def _get_tushare_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """
        ä½¿ç”¨TushareèŽ·å–å®žæ—¶è¡Œæƒ…

        ä½¿ç”¨ ts.get_realtime_quotes æŽ¥å£èŽ·å–ç§’çº§å®žæ—¶æ•°æ®
        è¯¥æŽ¥å£åŸºäºŽæ–°æµªè´¢ç»æ•°æ®ï¼Œæ— éœ€é«˜çº§æƒé™
        """
        try:
            import asyncio
            import tushare as ts
            from datetime import datetime

            # èŽ·å–6ä½è‚¡ç¥¨ä»£ç 
            code_6 = symbol.split(".")[0] if "." in symbol else symbol
            code_6 = code_6.zfill(6)

            logger.debug(f"ðŸ“Š [Tushareå®žæ—¶è¡Œæƒ…] å°è¯•èŽ·å– {symbol} (ä»£ç : {code_6})")

            # ä½¿ç”¨ ts.get_realtime_quotes èŽ·å–å®žæ—¶è¡Œæƒ…ï¼ˆåŸºäºŽæ–°æµªè´¢ç»ï¼‰
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„ tushare è°ƒç”¨
            df = loop.run_until_complete(
                asyncio.to_thread(ts.get_realtime_quotes, code_6)
            )

            if df is not None and not df.empty:
                row = df.iloc[0]

                # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                price = float(row.get("price", 0))
                if price > 0:
                    pre_close = float(row.get("pre_close", 0))
                    change = price - pre_close if pre_close > 0 else 0
                    change_pct = (change / pre_close * 100) if pre_close > 0 else 0

                    quote = {
                        "symbol": symbol,
                        "price": price,
                        "open": float(row.get("open", 0)),
                        "high": float(row.get("high", 0)),
                        "low": float(row.get("low", 0)),
                        "volume": int(
                            float(row.get("volume", 0))
                        ),  # å•ä½ï¼šæ‰‹ï¼ˆTushareæä¾›è€…å·²è½¬æ¢ï¼‰
                        "amount": float(row.get("amount", 0)),  # å•ä½ï¼šå…ƒ
                        "change": change,
                        "change_pct": change_pct,
                        "pre_close": pre_close,
                        "date": row.get("date", datetime.now().strftime("%Y-%m-%d")),
                        "time": row.get("time", datetime.now().strftime("%H:%M:%S")),
                        "source": "tushare_sina_realtime",
                        "is_realtime": True,
                    }

                    logger.info(
                        f"âœ… [å®žæ—¶è¡Œæƒ…-Tushare-Sina] {symbol} ä»·æ ¼={quote['price']:.2f}, "
                        f"æ¶¨è·Œ={quote['change']:.2f}({quote['change_pct']:.2f}%)"
                    )
                    return quote
                else:
                    logger.warning(f"âš ï¸ [å®žæ—¶è¡Œæƒ…-Tushare] {symbol} ä»·æ ¼æ•°æ®æ— æ•ˆ")
            else:
                logger.debug(f"ðŸ“Š [å®žæ—¶è¡Œæƒ…-Tushare] {symbol} æ— å®žæ—¶æ•°æ®è¿”å›ž")

            return None

        except Exception as e:
            logger.error(f"âŒ Tushareå®žæ—¶è¡Œæƒ…èŽ·å–å¤±è´¥: {e}")
            return None

    def _get_akshare_realtime_quote(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨AKShareèŽ·å–å®žæ—¶è¡Œæƒ…"""
        max_retries = 2
        last_error = None

        for attempt in range(max_retries):
            try:
                import akshare as ak
                import requests
                import time

                # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ä¸ºæ–°æµªæ ¼å¼ï¼ˆç”¨äºŽå¤‡ç”¨æŽ¥å£ï¼‰
                if symbol.startswith("6"):
                    sina_symbol = f"sh{symbol}"
                elif symbol.startswith(("0", "3", "2")):
                    sina_symbol = f"sz{symbol}"
                elif symbol.startswith(("8", "4")):
                    sina_symbol = f"bj{symbol}"
                else:
                    sina_symbol = symbol

                # ðŸ”¥ ä¼˜å…ˆå°è¯•æ–°æµªå®žæ—¶æŽ¥å£ï¼ˆå•ä¸ªè‚¡ç¥¨ï¼Œæ•°æ®é‡å°ï¼‰
                try:
                    url = f"http://hq.sinajs.cn/list={sina_symbol}"
                    headers = {
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    }

                    response = requests.get(url, headers=headers, timeout=10)
                    response.encoding = "gbk"

                    if response.status_code == 200:
                        data_str = response.text.strip()
                        if "var hq_str_" in data_str:
                            # è§£æžæ–°æµªæ•°æ®
                            start_idx = data_str.index('"') + 1
                            end_idx = data_str.rindex('"')
                            data_str = data_str[start_idx:end_idx]

                            data = data_str.split(",")
                            if len(data) >= 33:
                                price = float(data[3])
                                open_price = float(data[1])
                                high_price = float(data[4])
                                low_price = float(data[5])
                                volume = int(
                                    float(data[8])
                                )  # å•ä½ï¼šæ‰‹ï¼ˆç›´æŽ¥ä½¿ç”¨æ–°æµªè¿”å›žçš„æ‰‹æ•°ï¼‰

                                quote = {
                                    "symbol": symbol,
                                    "price": price,
                                    "open": open_price,
                                    "high": high_price,
                                    "low": low_price,
                                    "volume": volume,  # å•ä½ï¼šæ‰‹
                                    "amount": 0.0,  # å•ä½ï¼šå…ƒ
                                    "change": float(data[2]),
                                    "change_pct": float(data[2]) / float(data[1]) * 100
                                    if float(data[1]) > 0
                                    else 0.0,
                                    "date": datetime.now().strftime("%Y-%m-%d"),
                                    "time": datetime.now().strftime("%H:%M:%S"),
                                    "source": "sina_realtime",
                                    "is_realtime": True,
                                }
                                logger.info(
                                    f"âœ… [å®žæ—¶è¡Œæƒ…-æ–°æµª] {symbol} ä»·æ ¼={quote['price']:.2f}, æˆäº¤é‡={volume:,.0f}æ‰‹"
                                )
                                return quote
                except Exception as e:
                    logger.debug(f"æ–°æµªæŽ¥å£å¤±è´¥ï¼Œå°è¯•ä¸œæ–¹è´¢å¯Œ: {e}")
                    last_error = e

                # å¤‡ç”¨ï¼šä¸œæ–¹è´¢å¯Œå•è‚¡ç¥¨æŽ¥å£ï¼ˆå¦‚æžœæ–°æµªå¤±è´¥ï¼‰
                # ðŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨ stock_bid_ask_em èŽ·å–å•åªè‚¡ç¥¨ï¼Œè€Œä¸æ˜¯ stock_zh_a_spot_em èŽ·å–å…¨å¸‚åœº
                logger.info(
                    f"ðŸ”„ [AKShare] å°è¯•èŽ·å– {symbol} å•è‚¡ç¥¨å®žæ—¶è¡Œæƒ… (ç¬¬{attempt + 1}æ¬¡)"
                )
                df = ak.stock_bid_ask_em(symbol=symbol)

                if df is not None and not df.empty:
                    # å°† DataFrame è½¬æ¢ä¸ºå­—å…¸
                    data_dict = dict(zip(df["item"], df["value"]))

                    # æˆäº¤é‡å•ä½ï¼šæ‰‹ï¼ˆç›´æŽ¥ä½¿ç”¨AKShareè¿”å›žçš„"æ€»æ‰‹"å­—æ®µï¼‰
                    # æ³¨æ„ï¼š2026-01-30 ç»Ÿä¸€å•ä½ä¸º"æ‰‹"
                    volume_in_lots = int(data_dict.get("æ€»æ‰‹", 0))

                    quote = {
                        "symbol": symbol,
                        "price": float(data_dict.get("æœ€æ–°", 0)),
                        "open": float(data_dict.get("ä»Šå¼€", 0)),
                        "high": float(data_dict.get("æœ€é«˜", 0)),
                        "low": float(data_dict.get("æœ€ä½Ž", 0)),
                        "volume": volume_in_lots,  # å•ä½ï¼šæ‰‹
                        "amount": float(data_dict.get("é‡‘é¢", 0)),  # å•ä½ï¼šå…ƒ
                        "change": float(data_dict.get("æ¶¨è·Œ", 0)),
                        "change_pct": float(data_dict.get("æ¶¨å¹…", 0)),
                        "date": datetime.now().strftime("%Y-%m-%d"),
                        "time": datetime.now().strftime("%H:%M:%S"),
                        "source": "eastmoney_realtime",
                        "is_realtime": True,
                    }
                    logger.info(
                        f"âœ… [å®žæ—¶è¡Œæƒ…-ä¸œæ–¹è´¢å¯Œå•è‚¡ç¥¨] {symbol} ä»·æ ¼={quote['price']:.2f}, æˆäº¤é‡={volume_in_lots:,.0f}æ‰‹"
                    )
                    return quote
                else:
                    logger.warning(f"âš ï¸ AKShareæœªæ‰¾åˆ°{symbol}çš„å®žæ—¶è¡Œæƒ…")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                    continue

            except requests.exceptions.Timeout:
                last_error = "è¯·æ±‚è¶…æ—¶"
                logger.warning(f"âš ï¸ [AKShare] è¯·æ±‚è¶…æ—¶ (ç¬¬{attempt + 1}æ¬¡)")
                if attempt < max_retries - 1:
                    time.sleep(2)
                continue

            except requests.exceptions.ProxyError as e:
                last_error = f"ä»£ç†é”™è¯¯: {e}"
                logger.warning(f"âš ï¸ [AKShare] ä»£ç†è¿žæŽ¥å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                continue

            except requests.exceptions.ConnectionError as e:
                last_error = f"è¿žæŽ¥é”™è¯¯: {e}"
                logger.warning(f"âš ï¸ [AKShare] ç½‘ç»œè¿žæŽ¥å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                continue

            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ [AKShare] èŽ·å–å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                continue

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ AKShareå®žæ—¶è¡Œæƒ…èŽ·å–å¤±è´¥: {last_error}", exc_info=True)
        return None

    def get_stock_data(
        self,
        symbol: str,
        start_date: str = None,
        end_date: str = None,
        period: str = "daily",
        analysis_date: str = None,
    ) -> str:
        """
        èŽ·å–è‚¡ç¥¨æ•°æ®çš„ç»Ÿä¸€æŽ¥å£ï¼Œæ”¯æŒå¤šå‘¨æœŸæ•°æ®

        ðŸ”¥ é‡è¦æ›´æ–°ï¼šæ ¹æ®åˆ†æžæ—¥æœŸæ™ºèƒ½åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å®žæ—¶è¡Œæƒ…
        - åŽ†å²æ—¥æœŸï¼šä½¿ç”¨åŽ†å²æ•°æ®
        - ä»Šå¤©+ç›˜ä¸­ï¼šä½¿ç”¨å®žæ—¶è¡Œæƒ…
        - ä»Šå¤©+ç›˜å‰/ç›˜åŽï¼šä½¿ç”¨æ”¶ç›˜ä»·

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily
            analysis_date: ç”¨æˆ·æŒ‡å®šçš„åˆ†æžæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œç”¨äºŽåˆ¤æ–­å®žæ—¶è¡Œæƒ…

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
        """
        # ðŸ”¥ å¦‚æžœæœªæä¾› analysis_dateï¼Œå°è¯•ä»Ž Toolkit._config èŽ·å–
        if analysis_date is None:
            try:
                from tradingagents.agents.utils.agent_utils import Toolkit

                analysis_date = Toolkit._config.get("analysis_date")
                if analysis_date:
                    logger.info(
                        f"ðŸ“… [è‡ªåŠ¨èŽ·å–] ä»Ž Toolkit._config èŽ·å–åˆ†æžæ—¥æœŸ: {analysis_date}"
                    )
            except Exception:
                pass

        # ðŸ”¥ èŽ·å–å®žæ—¶ä»·æ ¼ï¼ˆæ ¹æ®åˆ†æžæ—¥æœŸæ™ºèƒ½åˆ¤æ–­ï¼‰
        realtime_price = None
        realtime_quote = None
        try:
            from tradingagents.utils.market_time import MarketTimeUtils

            should_use_rt, reason = MarketTimeUtils.should_use_realtime_quote(
                symbol, analysis_date=analysis_date
            )
            logger.info(f"ðŸ“Š [å®žæ—¶è¡Œæƒ…æ£€æŸ¥] {symbol}: {reason}")

            # å§‹ç»ˆå°è¯•èŽ·å–å®žæ—¶ä»·æ ¼ï¼ˆç›˜ä¸­ç”¨å®žæ—¶ï¼Œç›˜åŽç”¨æœ€æ–°æ”¶ç›˜ä»·ï¼‰
            realtime_quote = self.get_realtime_quote(symbol)
            if realtime_quote and realtime_quote.get("price"):
                realtime_price = realtime_quote["price"]
                logger.info(f"âœ… [å®žæ—¶ä»·æ ¼] èŽ·å–æˆåŠŸ: Â¥{realtime_price:.2f}")
            else:
                logger.warning(f"âš ï¸ [å®žæ—¶ä»·æ ¼] èŽ·å–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŽ†å²æ•°æ®ä¸­çš„ä»·æ ¼")
                # âœ… ä¸è¦†ç›– realtime_quoteï¼Œä¿ç•™å¯èƒ½çš„æˆåŠŸç»“æžœ
        except Exception as e:
            logger.debug(f"å®žæ—¶è¡Œæƒ…èŽ·å–å¤±è´¥ï¼ˆä½¿ç”¨åŽ†å²æ•°æ®ï¼‰: {e}")
            # âœ… ä¸è¦†ç›– realtime_quoteï¼Œä¿ç•™å¯èƒ½çš„æˆåŠŸç»“æžœ

        # è®°å½•è¯¦ç»†çš„è¾“å…¥å‚æ•°
        logger.info(
            f"ðŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹èŽ·å–{period}æ•°æ®: {symbol}",
            extra={
                "symbol": symbol,
                "start_date": start_date,
                "end_date": end_date,
                "period": period,
                "data_source": self.current_source.value,
                "event_type": "data_fetch_start",
            },
        )

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(
            f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] DataSourceManager.get_stock_data æŽ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»åž‹: {type(symbol)})"
        )
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] å½“å‰æ•°æ®æº: {self.current_source.value}")

        start_time = time.time()

        # ðŸ”¥ æ£€æŸ¥æ˜¯å¦è·³è¿‡ MongoDB ç¼“å­˜ï¼ˆç›´æŽ¥ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–ï¼‰
        skip_mongodb = (
            os.getenv("SKIP_MONGODB_CACHE_ON_QUERY", "true").lower() == "true"
        )

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„èŽ·å–æ–¹æ³•
            actual_source = None  # å®žé™…ä½¿ç”¨çš„æ•°æ®æº

            if self.current_source == ChinaDataSource.MONGODB:
                if skip_mongodb:
                    # ðŸ”¥ è·³è¿‡ MongoDBï¼Œç›´æŽ¥ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–
                    logger.info(f"ðŸ”„ [é…ç½®è·³è¿‡MongoDB] ç›´æŽ¥ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–: {symbol}")
                    result, actual_source = self._try_fallback_sources_with_save(
                        symbol, start_date, end_date, period, realtime_quote
                    )
                else:
                    result, actual_source = self._get_mongodb_data(
                        symbol, start_date, end_date, period, realtime_quote
                    )
            elif self.current_source == ChinaDataSource.TUSHARE:
                logger.info(
                    f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ Tushare æ•°æ®æºï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', period='{period}'"
                )
                result = self._get_tushare_data(
                    symbol, start_date, end_date, period, realtime_quote
                )
                actual_source = "tushare"
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_data(
                    symbol, start_date, end_date, period, realtime_quote
                )
                actual_source = "akshare"
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                result = self._get_baostock_data(
                    symbol, start_date, end_date, period, realtime_quote
                )
                actual_source = "baostock"
            # TDX å·²ç§»é™¤
            else:
                result = f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source.value}"
                actual_source = None

            # è®°å½•è¯¦ç»†çš„è¾“å‡ºç»“æžœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0
            is_success = result and "âŒ" not in result and "é”™è¯¯" not in result

            # ä½¿ç”¨å®žé™…æ•°æ®æºåç§°ï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨ current_source
            display_source = actual_source or self.current_source.value

            if is_success:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: {display_source}] æˆåŠŸèŽ·å–è‚¡ç¥¨æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                    extra={
                        "symbol": symbol,
                        "start_date": start_date,
                        "end_date": end_date,
                        "data_source": display_source,
                        "actual_source": actual_source,
                        "requested_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "result_preview": result[:200] + "..."
                        if result_length > 200
                        else result,
                        "event_type": "data_fetch_success",
                    },
                )

                # ðŸ”¥ å¦‚æžœæœ‰å®žæ—¶è¡Œæƒ…ï¼Œæ›¿æ¢æœ€æ–°ä»·æ ¼
                if should_use_rt and realtime_quote:
                    result = self._merge_realtime_quote_to_result(
                        result, realtime_quote, symbol
                    )

                return result
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº: {symbol}",
                    extra={
                        "symbol": symbol,
                        "start_date": start_date,
                        "end_date": end_date,
                        "data_source": self.current_source.value,
                        "duration": duration,
                        "result_length": result_length,
                        "result_preview": result[:200] + "..."
                        if result_length > 200
                        else result,
                        "event_type": "data_fetch_warning",
                    },
                )

                # æ•°æ®è´¨é‡å¼‚å¸¸æ—¶ä¹Ÿå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº
                fallback_result = self._try_fallback_sources(
                    symbol, start_date, end_date
                )
                if (
                    fallback_result
                    and "âŒ" not in fallback_result
                    and "é”™è¯¯" not in fallback_result
                ):
                    logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸèŽ·å–æ•°æ®: {symbol}")
                    return fallback_result
                else:
                    logger.error(
                        f"âŒ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•èŽ·å–æœ‰æ•ˆæ•°æ®: {symbol}"
                    )
                    return result  # è¿”å›žåŽŸå§‹ç»“æžœï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯ï¼‰

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [æ•°æ®èŽ·å–] å¼‚å¸¸å¤±è´¥: {e}",
                extra={
                    "symbol": symbol,
                    "start_date": start_date,
                    "end_date": end_date,
                    "data_source": self.current_source.value,
                    "duration": duration,
                    "error": str(e),
                    "event_type": "data_fetch_exception",
                },
                exc_info=True,
            )
            return self._try_fallback_sources(
                symbol, start_date, end_date, realtime_quote=realtime_quote
            )

    def _merge_realtime_quote_to_result(
        self, historical_result: str, realtime_quote: Dict, symbol: str
    ) -> str:
        """
        å°†å®žæ—¶è¡Œæƒ…æ•°æ®åˆå¹¶åˆ°åŽ†å²æ•°æ®ç»“æžœä¸­

        Args:
            historical_result: åŽ†å²æ•°æ®æ ¼å¼åŒ–ç»“æžœ
            realtime_quote: å®žæ—¶è¡Œæƒ…æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åˆå¹¶åŽçš„ç»“æžœ
        """
        try:
            # ðŸ”§ å®‰å…¨æå–å®žæ—¶è¡Œæƒ…æ•°æ®ï¼Œå¤„ç† None å€¼
            price = realtime_quote.get("price")
            change = realtime_quote.get("change")
            change_pct = realtime_quote.get("change_pct")
            open_price = realtime_quote.get("open")
            high_price = realtime_quote.get("high")
            low_price = realtime_quote.get("low")
            quote_date = realtime_quote.get("date", "")
            quote_time = realtime_quote.get("time", "å®žæ—¶")

            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
            if price is None:
                logger.warning(f"âš ï¸ å®žæ—¶è¡Œæƒ…ç¼ºå°‘ä»·æ ¼æ•°æ®: {symbol}")
                return historical_result

            # æ ¼å¼åŒ–æ•°å€¼ï¼Œå¤„ç† None å€¼
            price_str = f"Â¥{price:.2f}" if price is not None else "N/A"
            change_str = f"{change:+.2f}" if change is not None else "N/A"
            change_pct_str = f"{change_pct:+.2f}%" if change_pct is not None else "N/A"
            open_str = f"Â¥{open_price:.2f}" if open_price is not None else "N/A"
            high_str = f"Â¥{high_price:.2f}" if high_price is not None else "N/A"
            low_str = f"Â¥{low_price:.2f}" if low_price is not None else "N/A"

            # åœ¨ç»“æžœå¼€å¤´æ·»åŠ å®žæ—¶è¡Œæƒ…æ ‡è¯†
            realtime_notice = f"""
âš¡ å®žæ—¶è¡Œæƒ…ï¼ˆç›˜ä¸­ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ’° å®žæ—¶ä»·æ ¼: {price_str}
ðŸ“ˆ æ¶¨è·Œ: {change_str} ({change_pct_str})
ðŸ“Š ä»Šå¼€: {open_str}  |  æœ€é«˜: {high_str}  |  æœ€ä½Ž: {low_str}
ðŸ• æ›´æ–°æ—¶é—´: {quote_date} {quote_time}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
            # æ›¿æ¢åŽŸæœ‰çš„æœ€æ–°ä»·æ ¼éƒ¨åˆ†
            lines = historical_result.split("\n")
            new_lines = []
            skip_next_price_lines = False

            for i, line in enumerate(lines):
                # åœ¨æ ‡é¢˜åŽæ’å…¥å®žæ—¶è¡Œæƒ…
                if i == 0 and "æŠ€æœ¯åˆ†æžæ•°æ®" in line:
                    new_lines.append(line)
                    # æ‰¾åˆ°æ•°æ®æœŸé—´è¡ŒåŽæ’å…¥
                    continue
                elif "æ•°æ®æœŸé—´:" in line:
                    new_lines.append(line)
                    # æ’å…¥å®žæ—¶è¡Œæƒ…é€šçŸ¥
                    new_lines.append(realtime_notice)
                    continue
                # è·³è¿‡åŽŸæœ‰çš„æœ€æ–°ä»·æ ¼è¡Œï¼Œå› ä¸ºå®žæ—¶è¡Œæƒ…å·²åŒ…å«
                elif "ðŸ’° æœ€æ–°ä»·æ ¼:" in line and not skip_next_price_lines:
                    skip_next_price_lines = True
                    continue
                elif skip_next_price_lines and "ðŸ“ˆ æ¶¨è·Œé¢:" in line:
                    skip_next_price_lines = False
                    continue
                elif skip_next_price_lines:
                    continue
                else:
                    new_lines.append(line)

            return "\n".join(new_lines)

        except Exception as e:
            logger.error(f"âŒ åˆå¹¶å®žæ—¶è¡Œæƒ…å¤±è´¥: {e}")
            # å¦‚æžœåˆå¹¶å¤±è´¥ï¼Œè¿”å›žåŽŸå§‹ç»“æžœ
            return historical_result

    def _get_mongodb_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> tuple[str, str | None]:
        """
        ä»ŽMongoDBèŽ·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

        Returns:
            tuple[str, str | None]: (ç»“æžœå­—ç¬¦ä¸², å®žé™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.debug(
            f"ðŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä»ŽMongoDBèŽ·å–æŒ‡å®šå‘¨æœŸçš„åŽ†å²æ•°æ®
            df = adapter.get_historical_data(
                symbol, start_date, end_date, period=period
            )

            if df is not None and not df.empty:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: MongoDBç¼“å­˜] æˆåŠŸèŽ·å–{period}æ•°æ®: {symbol} ({len(df)}æ¡è®°å½•)"
                )

                # ðŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # èŽ·å–è‚¡ç¥¨åç§°ï¼ˆä»ŽDataFrameä¸­æå–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                stock_name = f"è‚¡ç¥¨{symbol}"
                if "name" in df.columns and not df["name"].empty:
                    stock_name = df["name"].iloc[0]

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼Œä¼ å…¥å®žæ—¶è¡Œæƒ…ï¼‰
                result = self._format_stock_data_response(
                    df, symbol, stock_name, start_date, end_date, realtime_quote
                )

                logger.info(
                    f"âœ… [MongoDB] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL"
                )
                return result, "mongodb"
            else:
                # MongoDBæ²¡æœ‰æ•°æ®ï¼ˆadapterå†…éƒ¨å·²è®°å½•è¯¦ç»†çš„æ•°æ®æºä¿¡æ¯ï¼‰ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                logger.info(
                    f"ðŸ”„ [MongoDB] æœªæ‰¾åˆ°{period}æ•°æ®: {symbol}ï¼Œå¼€å§‹å°è¯•å¤‡ç”¨æ•°æ®æº"
                )
                return self._try_fallback_sources(
                    symbol, start_date, end_date, period, realtime_quote
                )

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] èŽ·å–{period}æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}"
            )
            # MongoDBå¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_sources(
                symbol, start_date, end_date, period, realtime_quote
            )

    def _run_async_safe(self, coro):
        """å®‰å…¨åœ°è¿è¡Œå¼‚æ­¥åç¨‹ï¼Œå¤„ç†äº‹ä»¶å¾ªçŽ¯å†²çª"""
        import asyncio

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            return asyncio.run(coro)

        import concurrent.futures

        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(asyncio.run, coro)
            return future.result()

    def _get_tushare_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> str:
        """ä½¿ç”¨TushareèŽ·å–å¤šå‘¨æœŸæ•°æ® - ä½¿ç”¨provider + ç»Ÿä¸€ç¼“å­˜"""
        logger.debug(
            f"ðŸ“Š [Tushare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(
            f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] _get_tushare_data æŽ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»åž‹: {type(symbol)})"
        )
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ðŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] _get_tushare_data å¼€å§‹æ‰§è¡Œ")
        logger.info(
            f"ðŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å½“å‰æ•°æ®æº: {self.current_source.value}"
        )

        start_time = time.time()
        try:
            # ðŸ”¥ æ£€æŸ¥æ˜¯å¦è·³è¿‡ç¼“å­˜
            skip_cache = (
                os.getenv("SKIP_MONGODB_CACHE_ON_QUERY", "true").lower() == "true"
            )

            # 1. å…ˆå°è¯•ä»Žç¼“å­˜èŽ·å–ï¼ˆé™¤éžé…ç½®äº†è·³è¿‡ï¼‰
            cached_data = None
            if not skip_cache:
                cached_data = self._get_cached_data(
                    symbol, start_date, end_date, max_age_hours=24
                )
            else:
                logger.info(
                    f"ðŸ”„ [é…ç½®è·³è¿‡ç¼“å­˜] SKIP_MONGODB_CACHE_ON_QUERY=trueï¼Œè·³è¿‡ç¼“å­˜æ£€æŸ¥: {symbol}"
                )

            if cached_data is not None and not cached_data.empty:
                logger.info(f"âœ… [ç¼“å­˜å‘½ä¸­] ä»Žç¼“å­˜èŽ·å–{symbol}æ•°æ®")
                # èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                provider = self._get_tushare_adapter()
                if provider:
                    # ðŸ”¥ ä½¿ç”¨ _run_async_safe é¿å…äº‹ä»¶å¾ªçŽ¯å†²çª
                    stock_info = self._run_async_safe(
                        provider.get_stock_basic_info(symbol)
                    )
                    stock_name = (
                        stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                        if stock_info
                        else f"è‚¡ç¥¨{symbol}"
                    )
                else:
                    stock_name = f"è‚¡ç¥¨{symbol}"

                # æ ¼å¼åŒ–è¿”å›ž
                return self._format_stock_data_response(
                    cached_data,
                    symbol,
                    stock_name,
                    start_date,
                    end_date,
                    realtime_quote,
                )

            # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œä»ŽproviderèŽ·å–
            logger.info(
                f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ tushare_providerï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}'"
            )
            logger.info(f"ðŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼€å§‹è°ƒç”¨tushare_provider...")

            provider = self._get_tushare_adapter()
            if not provider:
                return f"âŒ Tushareæä¾›å™¨ä¸å¯ç”¨"

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•èŽ·å–åŽ†å²æ•°æ®
            import asyncio

            data = self._run_async_safe(
                provider.get_historical_data(symbol, start_date, end_date)
            )

            if data is not None and not data.empty:
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_cache(symbol, data, start_date, end_date)

                # èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                stock_info = self._run_async_safe(provider.get_stock_basic_info(symbol))
                stock_name = (
                    stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                    if stock_info
                    else f"è‚¡ç¥¨{symbol}"
                )

                # æ ¼å¼åŒ–è¿”å›ž
                result = self._format_stock_data_response(
                    data, symbol, stock_name, start_date, end_date, realtime_quote
                )

                duration = time.time() - start_time
                logger.info(
                    f"ðŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {duration:.3f}ç§’"
                )
                logger.info(
                    f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›žç»“æžœå‰200å­—ç¬¦: {result[:200] if result else 'None'}"
                )
                logger.debug(
                    f"ðŸ“Š [Tushare] è°ƒç”¨å®Œæˆ: è€—æ—¶={duration:.2f}s, ç»“æžœé•¿åº¦={len(result) if result else 0}"
                )

                return result
            else:
                result = f"âŒ æœªèŽ·å–åˆ°{symbol}çš„æœ‰æ•ˆæ•°æ®"
                duration = time.time() - start_time
                logger.warning(f"âš ï¸ [Tushare] æœªèŽ·å–åˆ°æ•°æ®ï¼Œè€—æ—¶={duration:.2f}s")
                return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [Tushare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True
            )
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ç±»åž‹: {type(e).__name__}")
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ä¿¡æ¯: {str(e)}")
            import traceback

            logger.error(
                f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}"
            )
            raise

    def _get_akshare_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> str:
        """ä½¿ç”¨AKShareèŽ·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        logger.debug(
            f"ðŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}"
        )

        start_time = time.time()
        try:
            # ä½¿ç”¨AKShareçš„ç»Ÿä¸€æŽ¥å£
            from .providers.china.akshare import get_akshare_provider

            provider = get_akshare_provider()

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•èŽ·å–åŽ†å²æ•°æ®
            import asyncio

            data = self._run_async_safe(
                provider.get_historical_data(symbol, start_date, end_date, period)
            )

            duration = time.time() - start_time

            if data is not None and not data.empty:
                # ðŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                stock_info = self._run_async_safe(provider.get_stock_basic_info(symbol))
                stock_name = (
                    stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                    if stock_info
                    else f"è‚¡ç¥¨{symbol}"
                )

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
                result = self._format_stock_data_response(
                    data, symbol, stock_name, start_date, end_date, realtime_quote
                )

                logger.debug(
                    f"ðŸ“Š [AKShare] è°ƒç”¨æˆåŠŸ: è€—æ—¶={duration:.2f}s, æ•°æ®æ¡æ•°={len(data)}, ç»“æžœé•¿åº¦={len(result)}"
                )
                logger.info(
                    f"âœ… [AKShare] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL"
                )
                return result
            else:
                result = f"âŒ æœªèƒ½èŽ·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"
                logger.warning(f"âš ï¸ [AKShare] æ•°æ®ä¸ºç©º: è€—æ—¶={duration:.2f}s")
                return result

        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ [AKShare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True
            )
            return f"âŒ AKShareèŽ·å–{symbol}æ•°æ®å¤±è´¥: {e}"

    async def _get_baostock_data_async(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> str:
        """ä½¿ç”¨BaoStockèŽ·å–å¤šå‘¨æœŸæ•°æ® - å¼‚æ­¥ç‰ˆæœ¬"""
        # ä½¿ç”¨BaoStockçš„ç»Ÿä¸€æŽ¥å£
        from .providers.china.baostock import get_baostock_provider

        provider = get_baostock_provider()

        # ðŸ”¥ FIX: ç›´æŽ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•ï¼Œä¸åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªçŽ¯
        data = await provider.get_historical_data(symbol, start_date, end_date, period)

        if data is not None and not data.empty:
            # ðŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
            # èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = await provider.get_stock_basic_info(symbol)
            stock_name = (
                stock_info.get("name", f"è‚¡ç¥¨{symbol}")
                if stock_info
                else f"è‚¡ç¥¨{symbol}"
            )

            # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
            result = self._format_stock_data_response(
                data, symbol, stock_name, start_date, end_date, realtime_quote
            )

            logger.info(f"âœ… [BaoStock] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL")
            return result
        else:
            return f"âŒ æœªèƒ½èŽ·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"

    def _get_baostock_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> str:
        """ä½¿ç”¨BaoStockèŽ·å–å¤šå‘¨æœŸæ•°æ® - åŒæ­¥åŒ…è£…å™¨"""
        import asyncio

        try:
            # ðŸ”¥ FIX: èŽ·å–å½“å‰äº‹ä»¶å¾ªçŽ¯ï¼Œå¦‚æžœå·²ç»åœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼Œä½¿ç”¨ create_task
            loop = asyncio.get_running_loop()
            # å¦‚æžœåœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼Œç›´æŽ¥è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬
            # æ³¨æ„ï¼šè¿™é‡Œä¸åº”è¯¥è¢«ç›´æŽ¥è°ƒç”¨ï¼Œåº”è¯¥ä½¿ç”¨ _get_baostock_data_async
            logger.warning("âš ï¸ [_get_baostock_data] åœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­è¢«è°ƒç”¨ï¼Œä½¿ç”¨çº¿ç¨‹æ± ")

            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œ
            from concurrent.futures import ThreadPoolExecutor

            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(
                    lambda: asyncio.run(
                        self._get_baostock_data_async(
                            symbol, start_date, end_date, period, realtime_quote
                        )
                    )
                )
                return future.result()
        except RuntimeError:
            # ä¸åœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼Œç›´æŽ¥è¿è¡Œ
            return asyncio.run(
                self._get_baostock_data_async(
                    symbol, start_date, end_date, period, realtime_quote
                )
            )

    # TDX æ•°æ®èŽ·å–æ–¹æ³•å·²ç§»é™¤
    # def _get_tdx_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
    #     """ä½¿ç”¨TDXèŽ·å–å¤šå‘¨æœŸæ•°æ® (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ"

    # ðŸ”§ FIX: åˆ é™¤é‡å¤çš„ _get_volume_safely æ–¹æ³•å®šä¹‰
    # æ­£ç¡®çš„ç‰ˆæœ¬åœ¨ç¬¬769è¡Œï¼Œä½¿ç”¨ iloc[-1] èŽ·å–æœ€åŽä¸€å¤©çš„æˆäº¤é‡
    # è¿™é‡Œçš„ç‰ˆæœ¬ä½¿ç”¨ sum() æ˜¯é”™è¯¯çš„ï¼Œä¼šå¯¼è‡´æˆäº¤é‡æ•°æ®ä¸ä¸€è‡´
    # è¯¦è§: docs/reports/report_optimization_plan.md

    def _try_fallback_sources(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> tuple[str, str | None]:
        """
        å°è¯•å¤‡ç”¨æ•°æ®æº - é¿å…é€’å½’è°ƒç”¨

        Returns:
            tuple[str, str | None]: (ç»“æžœå­—ç¬¦ä¸², å®žé™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.info(
            f"ðŸ”„ [{self.current_source.value}] å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–{period}æ•°æ®: {symbol}"
        )

        # ðŸ”¥ ä»Žæ•°æ®åº“èŽ·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        # æ³¨æ„ï¼šä¸åŒ…å«MongoDBï¼Œå› ä¸ºMongoDBæ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œå¦‚æžœå¤±è´¥äº†å°±ä¸å†å°è¯•
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(
                        f"ðŸ”„ [å¤‡ç”¨æ•°æ®æº] å°è¯• {source.value} èŽ·å–{period}æ•°æ®: {symbol}"
                    )

                    # ç›´æŽ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_data(
                            symbol, start_date, end_date, period, realtime_quote
                        )
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_data(
                            symbol, start_date, end_date, period, realtime_quote
                        )
                    elif source == ChinaDataSource.BAOSTOCK:
                        result = self._get_baostock_data(
                            symbol, start_date, end_date, period, realtime_quote
                        )
                    # TDX å·²ç§»é™¤
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥æ•°æ®æº: {source.value}")
                        continue

                    if "âŒ" not in result:
                        logger.info(
                            f"âœ… [å¤‡ç”¨æ•°æ®æº-{source.value}] æˆåŠŸèŽ·å–{period}æ•°æ®: {symbol}"
                        )
                        return result, source.value  # è¿”å›žç»“æžœå’Œå®žé™…ä½¿ç”¨çš„æ•°æ®æº
                    else:
                        logger.warning(
                            f"âš ï¸ [å¤‡ç”¨æ•°æ®æº-{source.value}] è¿”å›žé”™è¯¯ç»“æžœ: {symbol}"
                        )

                except Exception as e:
                    logger.error(
                        f"âŒ [å¤‡ç”¨æ•°æ®æº-{source.value}] èŽ·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}"
                    )
                    continue

        # ðŸ”¥ FIX: æ‰€æœ‰åœ¨çº¿æ•°æ®æºéƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ MongoDB ç¼“å­˜ä½œä¸ºå…œåº•ï¼ˆå³ä½¿æ•°æ®å¯èƒ½è¿‡æœŸï¼‰
        logger.warning(f"âš ï¸ [æ‰€æœ‰åœ¨çº¿æ•°æ®æºå¤±è´¥] å°è¯•ä½¿ç”¨ MongoDB ç¼“å­˜å…œåº•: {symbol}")
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()
            # ä¸é™åˆ¶æ—¥æœŸèŒƒå›´ï¼ŒèŽ·å–ä»»ä½•å¯ç”¨çš„åŽ†å²æ•°æ®
            df = adapter.get_historical_data(
                symbol, start_date=None, end_date=None, period=period
            )

            if df is not None and not df.empty:
                # æ£€æŸ¥æ•°æ®æ—¶æ•ˆæ€§
                if "date" in df.columns or "trade_date" in df.columns:
                    date_col = "date" if "date" in df.columns else "trade_date"
                    latest_date = df[date_col].max()
                    from datetime import datetime

                    if isinstance(latest_date, str):
                        latest_date = datetime.strptime(latest_date, "%Y-%m-%d")
                    days_old = (datetime.now() - latest_date).days

                    logger.warning(
                        f"âš ï¸ [MongoDBå…œåº•] ä½¿ç”¨å¯èƒ½è¿‡æœŸçš„æ•°æ®: {symbol}, "
                        f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}, "
                        f"å·²è¿‡æœŸ: {days_old} å¤©"
                    )

                    # èŽ·å–è‚¡ç¥¨åç§°
                    stock_name = f"è‚¡ç¥¨{symbol}"
                    if "name" in df.columns and not df["name"].empty:
                        stock_name = df["name"].iloc[0]

                    # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•
                    result = self._format_stock_data_response(
                        df, symbol, stock_name, start_date, end_date, realtime_quote
                    )

                    logger.info(
                        f"âœ… [MongoDBå…œåº•] æˆåŠŸèŽ·å–è¿‡æœŸæ•°æ®: {symbol} ({len(df)}æ¡è®°å½•)"
                    )
                    return result, "mongodb_fallback"
            else:
                logger.error(f"âŒ [MongoDBå…œåº•] ä¹Ÿæ²¡æœ‰ç¼“å­˜æ•°æ®: {symbol}")
        except Exception as e:
            logger.error(f"âŒ [MongoDBå…œåº•] èŽ·å–ç¼“å­˜æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")

        logger.error(f"âŒ [æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•èŽ·å–{period}æ•°æ®: {symbol}")
        return f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•èŽ·å–{symbol}çš„{period}æ•°æ®", None

    def _try_fallback_sources_with_save(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        period: str = "daily",
        realtime_quote: Dict[str, Any] = None,
    ) -> tuple[str, str | None]:
        """
        ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–æ•°æ®å¹¶ä¿å­˜åˆ° MongoDB

        ðŸ”¥ é‡æž„è¯´æ˜Ž (2026-02-01):
        - è·³è¿‡ MongoDB æŸ¥è¯¢ï¼Œç›´æŽ¥ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–
        - èŽ·å–æˆåŠŸåŽä¿å­˜åˆ° MongoDBï¼ˆå¦‚æžœé…ç½®äº† SAVE_TO_MONGODB_AFTER_QUERY=trueï¼‰
        - ä¼˜å…ˆçº§é¡ºåºä»Ž .env è¯»å–ï¼Œé»˜è®¤: Tushare > AKShare > BaoStock

        Returns:
            tuple[str, str | None]: (ç»“æžœå­—ç¬¦ä¸², å®žé™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        # ðŸ”¥ èŽ·å–æ•°æ®æºä¼˜å…ˆçº§ï¼ˆä»Ž .env è¯»å–ï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        logger.info(
            f"ðŸ”„ [è·³è¿‡MongoDBç¼“å­˜] ç›´æŽ¥ä»Žåœ¨çº¿æ•°æ®æºèŽ·å–: {symbol}, ä¼˜å…ˆçº§: {[s.value for s in fallback_order]}"
        )

        result_data = None
        actual_source = None

        # ä¾æ¬¡å°è¯•å„æ•°æ®æº
        for source in fallback_order:
            try:
                logger.info(
                    f"ðŸ”„ [åœ¨çº¿æ•°æ®æº] å°è¯• {source.value} èŽ·å–{period}æ•°æ®: {symbol}"
                )

                # ç›´æŽ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•
                if source == ChinaDataSource.TUSHARE:
                    result_data = self._get_tushare_data(
                        symbol, start_date, end_date, period, realtime_quote
                    )
                elif source == ChinaDataSource.AKSHARE:
                    result_data = self._get_akshare_data(
                        symbol, start_date, end_date, period, realtime_quote
                    )
                elif source == ChinaDataSource.BAOSTOCK:
                    result_data = self._get_baostock_data(
                        symbol, start_date, end_date, period, realtime_quote
                    )
                else:
                    logger.warning(f"âš ï¸ æœªçŸ¥æ•°æ®æº: {source.value}")
                    continue

                if result_data and "âŒ" not in result_data:
                    actual_source = source.value
                    logger.info(
                        f"âœ… [åœ¨çº¿æ•°æ®æº-{source.value}] æˆåŠŸèŽ·å–{period}æ•°æ®: {symbol}"
                    )
                    break  # æˆåŠŸèŽ·å–ï¼Œè·³å‡ºå¾ªçŽ¯
                else:
                    logger.warning(
                        f"âš ï¸ [åœ¨çº¿æ•°æ®æº-{source.value}] è¿”å›žé”™è¯¯ç»“æžœ: {symbol}"
                    )

            except Exception as e:
                logger.error(
                    f"âŒ [åœ¨çº¿æ•°æ®æº-{source.value}] èŽ·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}"
                )
                continue

        # ðŸ”¥ ä¿å­˜åˆ° MongoDBï¼ˆå¦‚æžœé…ç½®äº† SAVE_TO_MONGODB_AFTER_QUERY=trueï¼‰
        if result_data and "âŒ" not in result_data:
            save_to_mongodb = (
                os.getenv("SAVE_TO_MONGODB_AFTER_QUERY", "true").lower() == "true"
            )
            if save_to_mongodb and actual_source:
                try:
                    logger.info(
                        f"ðŸ’¾ [æ•°æ®ä¿å­˜] å°† {symbol} æ•°æ®ä¿å­˜åˆ° MongoDB (æ¥æº: {actual_source})"
                    )
                    # æ•°æ®ä¿å­˜é€»è¾‘åœ¨ provider å±‚å·²å®žçŽ°
                    # è¿™é‡Œåªéœ€è¦ç¡®è®¤ä¿å­˜å³å¯
                except Exception as e:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®ä¿å­˜] ä¿å­˜åˆ° MongoDB å¤±è´¥: {symbol}, é”™è¯¯: {e}"
                    )

            return result_data, actual_source

        # æ‰€æœ‰åœ¨çº¿æ•°æ®æºéƒ½å¤±è´¥ï¼Œå°è¯• MongoDB å…œåº•
        logger.warning(f"âš ï¸ [æ‰€æœ‰åœ¨çº¿æ•°æ®æºå¤±è´¥] å°è¯•ä½¿ç”¨ MongoDB ç¼“å­˜å…œåº•: {symbol}")
        return self._get_mongodb_data(
            symbol, start_date, end_date, period, realtime_quote
        )

    def get_stock_info(self, symbol: str) -> Dict:
        """
        èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ BaoStock
        """
        logger.info(
            f"ðŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹èŽ·å–è‚¡ç¥¨ä¿¡æ¯: {symbol}"
        )

        # ä¼˜å…ˆä½¿ç”¨ App Mongo ç¼“å­˜ï¼ˆå½“ ta_use_app_cache=Trueï¼‰
        try:
            from tradingagents.config.runtime_settings import (
                use_app_cache_enabled,  # type: ignore
            )

            use_cache = use_app_cache_enabled(False)
            logger.info(f"ðŸ”§ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è¿”å›žå€¼: {use_cache}")
        except Exception as e:
            logger.error(
                f"âŒ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è°ƒç”¨å¤±è´¥: {e}", exc_info=True
            )
            use_cache = False

        logger.info(
            f"ðŸ”§ [é…ç½®] ta_use_app_cache={use_cache}, current_source={self.current_source.value}"
        )

        if use_cache:
            try:
                from .cache.app_adapter import (
                    get_basics_from_cache,
                    get_market_quote_dataframe,
                )

                doc = get_basics_from_cache(symbol)
                if doc:
                    # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                    data_source = doc.get("data_source", "app_cache")
                    standardized_data = standardize_stock_basic(doc, data_source)

                    # ä»Žæ ‡å‡†åŒ–æ•°æ®ä¸­æå–å­—æ®µ
                    name = standardized_data.get("name") or f"è‚¡ç¥¨{symbol}"

                    # è§„èŒƒåŒ–è¡Œä¸šä¸Žæ¿å—ï¼ˆé¿å…æŠŠ"ä¸­å°æ¿/åˆ›ä¸šæ¿"ç­‰æ¿å—å€¼è¯¯ä½œè¡Œä¸šï¼‰
                    board_labels = {"ä¸»æ¿", "ä¸­å°æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"}
                    raw_industry = standardized_data.get("industry", "") or ""
                    market_val = standardized_data.get("market", "") or ""

                    if raw_industry in board_labels:
                        if not market_val:
                            market_val = raw_industry
                        # ä½¿ç”¨æ›´ç»†åˆ†ç±»ï¼ˆå¦‚æžœæœ‰ï¼‰
                        if standardized_data.get("industry_gn"):
                            industry_val = standardized_data.get("industry_gn")
                        elif standardized_data.get("industry_sw"):
                            industry_val = standardized_data.get("industry_sw")
                        else:
                            industry_val = "æœªçŸ¥"
                    else:
                        industry_val = raw_industry or "æœªçŸ¥"

                    result = {
                        "symbol": standardized_data.get("code", symbol),
                        "name": name,
                        "area": standardized_data.get("area", "æœªçŸ¥"),
                        "industry": industry_val,
                        "market": market_val or standardized_data.get("market", "æœªçŸ¥"),
                        "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                        # è´¢åŠ¡æŒ‡æ ‡
                        "pe": standardized_data.get("pe"),
                        "pb": standardized_data.get("pb"),
                        "ps": standardized_data.get("ps"),
                        "pe_ttm": standardized_data.get("pe_ttm"),
                        "total_mv": standardized_data.get("total_mv"),
                        "circ_mv": standardized_data.get("circ_mv"),
                        # æ¯è‚¡æŒ‡æ ‡ (2026-02-02 æ–°å¢ž)
                        "eps": standardized_data.get("eps"),  # æ¯è‚¡æ”¶ç›Š
                        "bps": standardized_data.get("bps"),  # æ¯è‚¡å‡€èµ„äº§
                        "ocfps": standardized_data.get("ocfps"),  # æ¯è‚¡ç»è¥çŽ°é‡‘æµ
                        "capital_rese_ps": standardized_data.get(
                            "capital_rese_ps"
                        ),  # æ¯è‚¡å…¬ç§¯é‡‘
                        "undist_profit_ps": standardized_data.get(
                            "undist_profit_ps"
                        ),  # æ¯è‚¡æœªåˆ†é…åˆ©æ¶¦
                        # è¡Œæƒ…æ•°æ®
                        "current_price": None,
                        "change_pct": None,
                        "volume": None,
                        # å…ƒæ•°æ®
                        "source": "app_cache",
                        "data_source": data_source,
                    }

                    # è¿½åŠ å¿«ç…§è¡Œæƒ…ï¼ˆè‹¥å­˜åœ¨ï¼‰
                    try:
                        df = get_market_quote_dataframe(symbol)
                        if df is not None and not df.empty:
                            row = df.iloc[-1]
                            result["current_price"] = row.get("close")
                            result["change_pct"] = row.get("pct_chg")
                            # market_quotes ä¸­çš„ volume å·²ç»æ˜¯"è‚¡"å•ä½ï¼Œæ— éœ€å†è½¬æ¢
                            result["volume"] = row.get("volume")
                            result["quote_date"] = row.get("date")
                            result["quote_source"] = "market_quotes"
                            logger.info(
                                f"âœ… [è‚¡ç¥¨ä¿¡æ¯] é™„åŠ è¡Œæƒ… | price={result['current_price']} pct={result['change_pct']} vol={result['volume']} code={symbol}"
                            )
                    except Exception as _e:
                        logger.debug(f"é™„åŠ è¡Œæƒ…å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{_e}")

                    if name and name != f"è‚¡ç¥¨{symbol}":
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: MongoDB-stock_basic_info] æˆåŠŸèŽ·å–: {symbol}"
                        )
                        return result
                    else:
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æœ‰æ•ˆåç§°: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                        )
            except Exception as e:
                logger.error(
                    f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] èŽ·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}", exc_info=True
                )

        # é¦–å…ˆå°è¯•å½“å‰æ•°æ®æº
        try:
            if self.current_source == ChinaDataSource.TUSHARE:
                from .interface import get_china_stock_info_tushare

                info_str = get_china_stock_info_tushare(symbol)
                raw_result = self._parse_stock_info_string(info_str, symbol)

                # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                standardized_data = standardize_stock_basic(raw_result, "tushare")

                # æž„å»ºæ ‡å‡†åŒ–ç»“æžœ
                result = {
                    "symbol": standardized_data.get("code", symbol),
                    "name": standardized_data.get("name", f"è‚¡ç¥¨{symbol}"),
                    "area": standardized_data.get("area", "æœªçŸ¥"),
                    "industry": standardized_data.get("industry", "æœªçŸ¥"),
                    "market": standardized_data.get("market", "æœªçŸ¥"),
                    "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                    # è´¢åŠ¡æŒ‡æ ‡
                    "pe": standardized_data.get("pe"),
                    "pb": standardized_data.get("pb"),
                    "ps": standardized_data.get("ps"),
                    "pe_ttm": standardized_data.get("pe_ttm"),
                    "total_mv": standardized_data.get("total_mv"),
                    "circ_mv": standardized_data.get("circ_mv"),
                    # è¡Œæƒ…æ•°æ®ï¼ˆä»ŽåŽŸå§‹æ•°æ®èŽ·å–ï¼‰
                    "current_price": raw_result.get("current_price"),
                    "change_pct": raw_result.get("change_pct"),
                    "volume": raw_result.get("volume"),
                    # å…ƒæ•°æ®
                    "source": "tushare",
                    "data_source": "tushare",
                }

                # æ£€æŸ¥æ˜¯å¦èŽ·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                    logger.info(f"âœ… [æ•°æ®æ¥æº: Tushare-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸèŽ·å–: {symbol}")
                    return result
                else:
                    # ðŸ”¥ FIX: æ·»åŠ è¯¦ç»†æ—¥å¿—ä»¥ä¾¿è¯Šæ–­é—®é¢˜
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: Tushareå¤±è´¥] è¿”å›žæ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}\n"
                        f"    è¯Šæ–­ä¿¡æ¯: name={result.get('name')!r}, "
                        f"industry={result.get('industry')!r}, "
                        f"area={result.get('area')!r}, "
                        f"raw_result={raw_result}"
                    )
                    return self._try_fallback_stock_info(symbol)
            else:
                adapter = self.get_data_adapter()
                if adapter and hasattr(adapter, "get_stock_info"):
                    raw_result = adapter.get_stock_info(symbol)

                    # ä½¿ç”¨ç»Ÿä¸€æ ‡å‡†åŒ–å™¨å¤„ç†æ•°æ®
                    data_source_name = self.current_source.value
                    standardized_data = standardize_stock_basic(
                        raw_result, data_source_name
                    )

                    # æž„å»ºæ ‡å‡†åŒ–ç»“æžœ
                    result = {
                        "symbol": standardized_data.get("code", symbol),
                        "name": standardized_data.get("name", f"è‚¡ç¥¨{symbol}"),
                        "area": standardized_data.get("area", "æœªçŸ¥"),
                        "industry": standardized_data.get("industry", "æœªçŸ¥"),
                        "market": standardized_data.get("market", "æœªçŸ¥"),
                        "list_date": standardized_data.get("list_date", "æœªçŸ¥"),
                        # è´¢åŠ¡æŒ‡æ ‡
                        "pe": standardized_data.get("pe"),
                        "pb": standardized_data.get("pb"),
                        "ps": standardized_data.get("ps"),
                        "pe_ttm": standardized_data.get("pe_ttm"),
                        "total_mv": standardized_data.get("total_mv"),
                        "circ_mv": standardized_data.get("circ_mv"),
                        # è¡Œæƒ…æ•°æ®
                        "current_price": raw_result.get("current_price"),
                        "change_pct": raw_result.get("change_pct"),
                        "volume": raw_result.get("volume"),
                        # å…ƒæ•°æ®
                        "source": data_source_name,
                        "data_source": data_source_name,
                    }

                    if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸèŽ·å–: {symbol}"
                        )
                        return result
                    else:
                        # ðŸ”¥ FIX: æ·»åŠ è¯¦ç»†æ—¥å¿—ä»¥ä¾¿è¯Šæ–­é—®é¢˜
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] è¿”å›žæ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}\n"
                            f"    è¯Šæ–­ä¿¡æ¯: name={result.get('name')!r}, "
                            f"industry={result.get('industry')!r}, "
                            f"area={result.get('area')!r}, "
                            f"raw_result={raw_result}"
                        )
                        return self._try_fallback_stock_info(symbol)
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯èŽ·å–ï¼Œå°è¯•é™çº§: {symbol}"
                    )
                    return self._try_fallback_stock_info(symbol)

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] èŽ·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}",
                exc_info=True,
            )
            return self._try_fallback_stock_info(symbol)

    def get_stock_basic_info(self, stock_code: str = None) -> Optional[Dict[str, Any]]:
        """
        èŽ·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆå…¼å®¹ stock_data_service æŽ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚æžœä¸º None åˆ™è¿”å›žæ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨

        Returns:
            Dict: è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼Œæˆ–åŒ…å« error å­—æ®µçš„é”™è¯¯å­—å…¸
        """
        if stock_code is None:
            # è¿”å›žæ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            logger.info("ðŸ“Š èŽ·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨")
            try:
                # å°è¯•ä»Ž MongoDB èŽ·å–
                from tradingagents.config.database_manager import get_database_manager

                db_manager = get_database_manager()
                if db_manager and db_manager.is_mongodb_available():
                    collection = db_manager.mongodb_db["stock_basic_info"]
                    stocks = list(collection.find({}, {"_id": 0}))
                    if stocks:
                        logger.info(f"âœ… ä»ŽMongoDBèŽ·å–æ‰€æœ‰è‚¡ç¥¨: {len(stocks)}æ¡")
                        return stocks
            except Exception as e:
                logger.warning(f"âš ï¸ ä»ŽMongoDBèŽ·å–æ‰€æœ‰è‚¡ç¥¨å¤±è´¥: {e}")

            # é™çº§ï¼šè¿”å›žç©ºåˆ—è¡¨
            return []

        # èŽ·å–å•ä¸ªè‚¡ç¥¨ä¿¡æ¯
        try:
            result = self.get_stock_info(stock_code)
            if result and result.get("name"):
                return result
            else:
                return {"error": f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„ä¿¡æ¯"}
        except Exception as e:
            logger.error(f"âŒ èŽ·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}

    def get_stock_data_with_fallback(
        self,
        stock_code: str,
        start_date: str,
        end_date: str,
        analysis_date: str = None,
    ) -> str:
        """
        èŽ·å–è‚¡ç¥¨æ•°æ®ï¼ˆå…¼å®¹ stock_data_service æŽ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            analysis_date: åˆ†æžæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œç”¨äºŽåˆ¤æ–­å®žæ—¶è¡Œæƒ…

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        logger.info(f"ðŸ“Š èŽ·å–è‚¡ç¥¨æ•°æ®: {stock_code} ({start_date} åˆ° {end_date})")

        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®èŽ·å–æŽ¥å£
            return self.get_stock_data(
                stock_code, start_date, end_date, analysis_date=analysis_date
            )
        except Exception as e:
            logger.error(f"âŒ èŽ·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return f"âŒ èŽ·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}\n\nðŸ’¡ å»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿žæŽ¥\n2. ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®\n3. æ£€æŸ¥æ•°æ®æºé…ç½®"

    def _try_fallback_stock_info(self, symbol: str) -> Dict:
        """å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æºèŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.error(
            f"ðŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–è‚¡ç¥¨ä¿¡æ¯..."
        )

        # èŽ·å–æ‰€æœ‰å¯ç”¨æ•°æ®æº
        available_sources = self.available_sources.copy()

        # ç§»é™¤å½“å‰æ•°æ®æº
        if self.current_source.value in available_sources:
            available_sources.remove(self.current_source.value)

        # å°è¯•æ‰€æœ‰å¤‡ç”¨æ•°æ®æº
        for source_name in available_sources:
            try:
                source = ChinaDataSource(source_name)
                logger.info(f"ðŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}")

                # æ ¹æ®æ•°æ®æºç±»åž‹èŽ·å–è‚¡ç¥¨ä¿¡æ¯
                if source == ChinaDataSource.TUSHARE:
                    # ðŸ”¥ ç›´æŽ¥è°ƒç”¨ Tushare é€‚é…å™¨ï¼Œé¿å…å¾ªçŽ¯è°ƒç”¨
                    result = self._get_tushare_stock_info(symbol)
                elif source == ChinaDataSource.AKSHARE:
                    result = self._get_akshare_stock_info(symbol)
                elif source == ChinaDataSource.BAOSTOCK:
                    result = self._get_baostock_stock_info(symbol)
                else:
                    # å°è¯•é€šç”¨é€‚é…å™¨
                    original_source = self.current_source
                    self.current_source = source
                    adapter = self.get_data_adapter()
                    self.current_source = original_source

                    if adapter and hasattr(adapter, "get_stock_info"):
                        result = adapter.get_stock_info(symbol)
                    else:
                        logger.warning(f"âš ï¸ [è‚¡ç¥¨ä¿¡æ¯] {source_name}ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯èŽ·å–")
                        continue

                # æ£€æŸ¥æ˜¯å¦èŽ·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get("name") and result["name"] != f"è‚¡ç¥¨{symbol}":
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸèŽ·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}"
                    )
                    return result
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {source_name}] è¿”å›žæ— æ•ˆä¿¡æ¯")

            except Exception as e:
                logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source_name}å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè¿”å›žé»˜è®¤å€¼
        logger.error(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•èŽ·å–{symbol}çš„è‚¡ç¥¨ä¿¡æ¯")
        return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "unknown"}

    def _get_akshare_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨AKShareèŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

        ðŸ”¥ é‡è¦ï¼šAKShare éœ€è¦åŒºåˆ†è‚¡ç¥¨å’ŒæŒ‡æ•°
        - å¯¹äºŽ 000001ï¼Œå¦‚æžœä¸åŠ åŽç¼€ï¼Œä¼šè¢«è¯†åˆ«ä¸º"æ·±åœ³æˆæŒ‡"ï¼ˆæŒ‡æ•°ï¼‰
        - å¯¹äºŽè‚¡ç¥¨ï¼Œéœ€è¦ä½¿ç”¨å®Œæ•´ä»£ç ï¼ˆå¦‚ sz000001 æˆ– sh600000ï¼‰
        """
        try:
            import akshare as ak

            # ðŸ”¥ è½¬æ¢ä¸º AKShare æ ¼å¼çš„è‚¡ç¥¨ä»£ç 
            # AKShare çš„ stock_individual_info_em éœ€è¦ä½¿ç”¨ "sz000001" æˆ– "sh600000" æ ¼å¼
            if symbol.startswith("6"):
                # ä¸Šæµ·è‚¡ç¥¨ï¼š600000 -> sh600000
                akshare_symbol = f"sh{symbol}"
            elif symbol.startswith(("0", "3", "2")):
                # æ·±åœ³è‚¡ç¥¨ï¼š000001 -> sz000001
                akshare_symbol = f"sz{symbol}"
            elif symbol.startswith(("8", "4")):
                # åŒ—äº¬è‚¡ç¥¨ï¼š830000 -> bj830000
                akshare_symbol = f"bj{symbol}"
            else:
                # å…¶ä»–æƒ…å†µï¼Œç›´æŽ¥ä½¿ç”¨åŽŸå§‹ä»£ç 
                akshare_symbol = symbol

            logger.debug(
                f"ðŸ“Š [AKShareè‚¡ç¥¨ä¿¡æ¯] åŽŸå§‹ä»£ç : {symbol}, AKShareæ ¼å¼: {akshare_symbol}"
            )

            # ðŸ”¥ FIX: å°è¯•èŽ·å–ä¸ªè‚¡ä¿¡æ¯ï¼Œå¢žå¼ºé”™è¯¯å¤„ç†
            try:
                stock_info = ak.stock_individual_info_em(symbol=akshare_symbol)
                logger.debug(
                    f"ðŸ“Š [AKShare] stock_individual_info_em è¿”å›žç±»åž‹: {type(stock_info)}"
                )
            except ValueError as ve:
                # ðŸ”¥ FIX: æ•èŽ· pandas DataFrame æž„é€ é”™è¯¯
                error_msg = str(ve)
                if "scalar values" in error_msg or "index" in error_msg:
                    logger.warning(
                        f"âš ï¸ [AKShare] stock_individual_info_em è¿”å›žæ•°æ®æ ¼å¼å¼‚å¸¸ "
                        f"(å¯èƒ½æ˜¯APIè¿”å›žç©ºæ•°æ®): {ve}"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ [AKShare] stock_individual_info_em å‚æ•°é”™è¯¯: {ve}"
                    )
            except Exception as api_e:
                logger.warning(
                    f"âš ï¸ [AKShare] stock_individual_info_em è°ƒç”¨å¤±è´¥: {api_e}"
                )
                # ðŸ”¥ FIX: å°è¯•å¤‡é€‰æ–¹æ¡ˆ - ä½¿ç”¨ stock_zh_a_spot_em èŽ·å–å…¨å¸‚åœºæ•°æ®ç„¶åŽç­›é€‰
                # ðŸ”¥ FIX: æ·»åŠ é‡è¯•æœºåˆ¶ä»¥å¤„ç†ç½‘ç»œé”™è¯¯
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        logger.info(
                            f"ðŸ”„ [AKShareå¤‡ç”¨æ–¹æ¡ˆ] å°è¯•ä»Žå…¨å¸‚åœºæ•°æ®èŽ·å–: {symbol} (å°è¯• {attempt + 1}/{max_retries})"
                        )
                        spot_df = ak.stock_zh_a_spot_em()
                        if spot_df is not None and not spot_df.empty:
                            # åœ¨ spot æ•°æ®ä¸­æŸ¥æ‰¾è¯¥è‚¡ç¥¨
                            code_col = (
                                "ä»£ç "
                                if "ä»£ç " in spot_df.columns
                                else "symbol"
                                if "symbol" in spot_df.columns
                                else None
                            )
                            if code_col:
                                stock_row = spot_df[spot_df[code_col] == symbol]
                                if not stock_row.empty:
                                    name_col = (
                                        "åç§°"
                                        if "åç§°" in stock_row.columns
                                        else "name"
                                        if "name" in stock_row.columns
                                        else None
                                    )
                                    if name_col:
                                        stock_name = stock_row.iloc[0][name_col]
                                        logger.info(
                                            f"âœ… [AKShareå¤‡ç”¨æ–¹æ¡ˆ] {symbol} -> {stock_name}"
                                        )
                                        return {
                                            "symbol": symbol,
                                            "name": stock_name,
                                            "source": "akshare",
                                            "area": "æœªçŸ¥",
                                            "industry": "æœªçŸ¥",
                                            "market": "æœªçŸ¥",
                                            "list_date": "æœªçŸ¥",
                                        }
                        # å¦‚æžœæ²¡æ‰¾åˆ°æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªçŽ¯
                        break
                    except Exception as backup_e:
                        error_str = str(backup_e)
                        is_network_error = any(
                            x in error_str.lower()
                            for x in [
                                "remote",
                                "connection",
                                "aborted",
                                "reset",
                                "closed",
                                "without response",
                            ]
                        )
                        if is_network_error and attempt < max_retries - 1:
                            wait_time = min(1.0 * (2**attempt), 10.0)
                            logger.warning(
                                f"âš ï¸ [AKShareå¤‡ç”¨æ–¹æ¡ˆ] ç½‘ç»œé”™è¯¯ï¼Œç­‰å¾… {wait_time:.1f} ç§’åŽé‡è¯• "
                                f"({attempt + 1}/{max_retries}): {error_str[:100]}"
                            )
                            import time

                            time.sleep(wait_time)
                            continue
                        else:
                            logger.warning(f"âš ï¸ [AKShareå¤‡ç”¨æ–¹æ¡ˆ] å¤±è´¥: {backup_e}")
                            break

                # å¦‚æžœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›žé»˜è®¤ä¿¡æ¯
                return {
                    "symbol": symbol,
                    "name": f"è‚¡ç¥¨{symbol}",
                    "source": "akshare",
                    "error": f"ä¸»æŽ¥å£: {api_e}",
                }

            if (
                stock_info is not None
                and hasattr(stock_info, "empty")
                and not stock_info.empty
            ):
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                info = {"symbol": symbol, "source": "akshare"}

                # ðŸ”¥ FIX: æ·»åŠ ç±»åž‹æ£€æŸ¥ï¼Œç¡®ä¿ stock_info æ˜¯ DataFrame
                if not isinstance(stock_info, pd.DataFrame):
                    logger.warning(
                        f"âš ï¸ [AKShare] è¿”å›žç±»åž‹å¼‚å¸¸: {type(stock_info)}, æœŸæœ› DataFrame"
                    )
                    return {
                        "symbol": symbol,
                        "name": f"è‚¡ç¥¨{symbol}",
                        "source": "akshare",
                    }

                # æå–è‚¡ç¥¨åç§°
                try:
                    name_row = stock_info[stock_info["item"] == "è‚¡ç¥¨ç®€ç§°"]
                    if not name_row.empty:
                        stock_name = name_row["value"].iloc[0]
                        info["name"] = stock_name
                        logger.info(f"âœ… [AKShareè‚¡ç¥¨ä¿¡æ¯] {symbol} -> {stock_name}")
                    else:
                        info["name"] = f"è‚¡ç¥¨{symbol}"
                        logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] æœªæ‰¾åˆ°è‚¡ç¥¨ç®€ç§°: {symbol}")
                except Exception as extract_e:
                    logger.warning(f"âš ï¸ [AKShare] æå–è‚¡ç¥¨åç§°å¤±è´¥: {extract_e}")
                    info["name"] = f"è‚¡ç¥¨{symbol}"

                # æå–å…¶ä»–ä¿¡æ¯
                info["area"] = "æœªçŸ¥"  # AKShareæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info["industry"] = "æœªçŸ¥"  # å¯ä»¥é€šè¿‡å…¶ä»–APIèŽ·å–
                info["market"] = "æœªçŸ¥"  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æŽ¨æ–­
                info["list_date"] = "æœªçŸ¥"  # å¯ä»¥é€šè¿‡å…¶ä»–APIèŽ·å–

                return info
            else:
                logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] è¿”å›žç©ºæ•°æ®: {symbol}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "akshare"}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] AKShareèŽ·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": "akshare",
                "error": str(e),
            }

    def _get_baostock_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨BaoStockèŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            import baostock as bs

            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if symbol.startswith("6"):
                bs_code = f"sh.{symbol}"
            else:
                bs_code = f"sz.{symbol}"

            # ç™»å½•BaoStock
            lg = bs.login()
            if lg.error_code != "0":
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

            # æŸ¥è¯¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            rs = bs.query_stock_basic(code=bs_code)
            if rs.error_code != "0":
                bs.logout()
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockæŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

            # è§£æžç»“æžœ
            data_list = []
            while (rs.error_code == "0") & rs.next():
                data_list.append(rs.get_row_data())

            # ç™»å‡º
            bs.logout()

            if data_list:
                # BaoStockè¿”å›žæ ¼å¼: [code, code_name, ipoDate, outDate, type, status]
                info = {"symbol": symbol, "source": "baostock"}
                info["name"] = data_list[0][1]  # code_name
                info["area"] = "æœªçŸ¥"  # BaoStockæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info["industry"] = "æœªçŸ¥"  # BaoStockæ²¡æœ‰è¡Œä¸šä¿¡æ¯
                info["market"] = "æœªçŸ¥"  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æŽ¨æ–­
                info["list_date"] = data_list[0][2]  # ipoDate

                return info
            else:
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "baostock"}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockèŽ·å–å¤±è´¥: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": "baostock",
                "error": str(e),
            }

    def _get_tushare_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨TushareèŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            from .providers.china.tushare import TushareProvider

            provider = TushareProvider()
            if not provider.is_available():
                logger.warning(f"âš ï¸ [è‚¡ç¥¨ä¿¡æ¯] Tushareæœªè¿žæŽ¥")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "tushare"}

            if not provider.api:
                logger.warning(f"âš ï¸ [è‚¡ç¥¨ä¿¡æ¯] Tushare APIæœªåˆå§‹åŒ–")
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "tushare"}

            # ðŸ”¥ FIX: ä½¿ç”¨æ­£ç¡®çš„ ts_code æ ¼å¼ (code.SZ æˆ– code.SH)
            ts_code = provider._normalize_ts_code(symbol)

            stock_data = provider.api.stock_basic(
                ts_code=ts_code,
                fields="ts_code,symbol,name,area,industry,list_date,exchange,market",
            )

            if stock_data is not None and not stock_data.empty:
                row = stock_data.iloc[0]
                # ðŸ”¥ FIX: ä½¿ç”¨ `or` æ“ä½œç¬¦å¤„ç†ç©ºå€¼æƒ…å†µ
                # dict.get() åªåœ¨ key ä¸å­˜åœ¨æ—¶è¿”å›žé»˜è®¤å€¼
                # ä½¿ç”¨ `value or default` å¯ä»¥åœ¨å€¼ä¸ºç©ºå­—ç¬¦ä¸²/Noneæ—¶ä¹Ÿè¿”å›žé»˜è®¤å€¼
                return {
                    "symbol": symbol,
                    "name": row.get("name") or f"è‚¡ç¥¨{symbol}",
                    "area": row.get("area") or "æœªçŸ¥",
                    "industry": row.get("industry") or "æœªçŸ¥",
                    "list_date": row.get("list_date") or "æœªçŸ¥",
                    "exchange": row.get("exchange") or "æœªçŸ¥",
                    "market": row.get("market") or "æœªçŸ¥",
                    "source": "tushare",
                }
            else:
                return {"symbol": symbol, "name": f"è‚¡ç¥¨{symbol}", "source": "tushare"}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] TushareèŽ·å–å¤±è´¥: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": "tushare",
                "error": str(e),
            }

    def _parse_stock_info_string(self, info_str: str, symbol: str) -> Dict:
        """è§£æžè‚¡ç¥¨ä¿¡æ¯å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        try:
            info = {"symbol": symbol, "source": self.current_source.value}
            lines = info_str.split("\n")

            for line in lines:
                if ":" in line:
                    key, value = line.split(":", 1)
                    key = key.strip()
                    value = value.strip()

                    if "è‚¡ç¥¨åç§°" in key:
                        info["name"] = value
                    elif "æ‰€å±žè¡Œä¸š" in key:
                        info["industry"] = value
                    elif "æ‰€å±žåœ°åŒº" in key:
                        info["area"] = value
                    elif "ä¸Šå¸‚å¸‚åœº" in key:
                        info["market"] = value
                    elif "ä¸Šå¸‚æ—¥æœŸ" in key:
                        info["list_date"] = value

            return info

        except Exception as e:
            logger.error(f"âš ï¸ è§£æžè‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "symbol": symbol,
                "name": f"è‚¡ç¥¨{symbol}",
                "source": self.current_source.value,
            }

    # ==================== åŸºæœ¬é¢æ•°æ®èŽ·å–æ–¹æ³• ====================

    def _get_mongodb_fundamentals(self, symbol: str) -> str:
        """ä»Ž MongoDB èŽ·å–è´¢åŠ¡æ•°æ®"""
        logger.debug(f"ðŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            import pandas as pd

            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä»Ž MongoDB èŽ·å–è´¢åŠ¡æ•°æ®
            financial_data = adapter.get_financial_data(symbol)

            # æ£€æŸ¥æ•°æ®ç±»åž‹å’Œå†…å®¹
            if financial_data is not None:
                # å¦‚æžœæ˜¯ DataFrameï¼Œè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                if isinstance(financial_data, pd.DataFrame):
                    if not financial_data.empty:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸèŽ·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)"
                        )
                        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                        financial_dict_list = financial_data.to_dict("records")
                        # æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š
                        return self._format_financial_data(symbol, financial_dict_list)
                    else:
                        logger.warning(
                            f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] è´¢åŠ¡æ•°æ®ä¸ºç©º: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                        )
                        return self._try_fallback_fundamentals(symbol)
                # å¦‚æžœæ˜¯åˆ—è¡¨
                elif isinstance(financial_data, list) and len(financial_data) > 0:
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸèŽ·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)"
                    )
                    return self._format_financial_data(symbol, financial_data)
                # å¦‚æžœæ˜¯å•ä¸ªå­—å…¸ï¼ˆè¿™æ˜¯MongoDBå®žé™…è¿”å›žçš„æ ¼å¼ï¼‰
                elif isinstance(financial_data, dict):
                    logger.info(
                        f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸèŽ·å–: {symbol} (å•æ¡è®°å½•)"
                    )
                    # å°†å•ä¸ªå­—å…¸åŒ…è£…æˆåˆ—è¡¨
                    financial_dict_list = [financial_data]
                    return self._format_financial_data(symbol, financial_dict_list)
                else:
                    logger.warning(
                        f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                    )
                    return self._try_fallback_fundamentals(symbol)
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                )
                # MongoDB æ²¡æœ‰æ•°æ®ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            logger.error(
                f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] èŽ·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}", exc_info=True
            )
            # MongoDB å¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_fundamentals(symbol)

    def _get_tushare_fundamentals(self, symbol: str) -> str:
        """ä»Ž Tushare èŽ·å–åŸºæœ¬é¢æ•°æ®"""
        try:
            from .providers.china.tushare import get_tushare_provider

            logger.info(f"ðŸ“Š [Tushare] å¼€å§‹èŽ·å–åŸºæœ¬é¢æ•°æ®: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨ï¼Œæœªåˆå§‹åŒ–æˆ–æ—  Token")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # èŽ·å–æœ€æ–°äº¤æ˜“æ—¥æœŸçš„æ¯æ—¥åŸºç¡€æ•°æ®
            # å¦‚æžœä»Šå¤©æ²¡æœ‰äº¤æ˜“æ—¥æ•°æ®ï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
            from datetime import datetime, timedelta

            trade_date = datetime.now().strftime("%Y-%m-%d")
            logger.info(f"ðŸ“Š [Tushare] åˆå§‹æŸ¥è¯¢æ—¥æœŸ: {trade_date}")

            # è°ƒç”¨ get_daily_basic èŽ·å– PEã€PBã€PS ç­‰æŒ‡æ ‡
            import asyncio

            try:
                # åˆ›å»ºæˆ–èŽ·å–äº‹ä»¶å¾ªçŽ¯
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_closed():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                # é¦–å…ˆå°è¯•ä»Šå¤©çš„æ•°æ®
                df = loop.run_until_complete(provider.get_daily_basic(trade_date))

                # å¦‚æžœä»Šå¤©æ²¡æœ‰æ•°æ®ï¼Œå°è¯•æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
                if df is None or df.empty:
                    logger.info(
                        f"ðŸ“Š [Tushare] {trade_date} æ— æ•°æ®ï¼ŒæŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥..."
                    )
                    for delta in range(1, 10):  # æœ€å¤šå›žæº¯ 10 å¤©
                        check_date = (datetime.now() - timedelta(days=delta)).strftime(
                            "%Y-%m-%d"
                        )
                        logger.info(f"ðŸ“Š [Tushare] å°è¯•æ—¥æœŸ: {check_date}")
                        df = loop.run_until_complete(
                            provider.get_daily_basic(check_date)
                        )
                        if df is not None and not df.empty:
                            trade_date = check_date
                            logger.info(f"âœ… [Tushare] æ‰¾åˆ°äº¤æ˜“æ—¥æ•°æ®: {trade_date}")
                            break

                if df is None or df.empty:
                    logger.warning(
                        f"âš ï¸ [Tushare] daily_basic è¿”å›žç©ºæ•°æ®ï¼ˆå°è¯•äº†æœ€è¿‘ 10 å¤©ï¼‰"
                    )
                    return f"âš ï¸ Tushare daily_basic æŽ¥å£æœªè¿”å›žæ•°æ®ï¼Œå¯èƒ½éœ€è¦æ›´é«˜æƒé™çš„ Token"

                logger.info(f"âœ… [Tushare] daily_basic è¿”å›ž {len(df)} æ¡è®°å½•")

                # æŸ¥æ‰¾æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
                # éœ€è¦å°†ä»£ç è½¬æ¢ä¸º Tushare æ ¼å¼ (å¦‚ 605589 -> 605589.SH)
                ts_code = self._convert_to_tushare_code(symbol)
                logger.info(f"ðŸ” [Tushare] æŸ¥è¯¢ä»£ç : {ts_code}")

                stock_data = df[df["ts_code"] == ts_code]

                if stock_data.empty:
                    logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} ({ts_code}) çš„æ•°æ®")
                    # å°è¯•ç”¨åŽŸå§‹ä»£ç æŸ¥è¯¢
                    stock_data = df[df["ts_code"] == symbol]
                    if stock_data.empty:
                        return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„åŸºæœ¬é¢æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æˆ–æ•°æ®æºæƒé™"

                # èŽ·å–ç¬¬ä¸€è¡Œæ•°æ®
                row = stock_data.iloc[0]

                # æ ¼å¼åŒ–è¾“å‡º
                report = f"ðŸ“Š {symbol} åŸºæœ¬é¢æ•°æ®ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"
                report += f"ðŸ“… æ•°æ®æ—¥æœŸ: {trade_date}\n"
                report += f"ðŸ“ˆ æ•°æ®æ¥æº: Tushare daily_basic æŽ¥å£\n\n"

                # ä¼°å€¼æŒ‡æ ‡
                report += "ðŸ’° ä¼°å€¼æŒ‡æ ‡:\n"

                pe = row.get("pe")
                if pe is not None and pd.notna(pe) and pe != 0:
                    report += f"   å¸‚ç›ˆçŽ‡(PE): {pe:.2f}\n"

                pb = row.get("pb")
                if pb is not None and pd.notna(pb) and pb != 0:
                    report += f"   å¸‚å‡€çŽ‡(PB): {pb:.2f}\n"

                pe_ttm = row.get("pe_ttm")
                if pe_ttm is not None and pd.notna(pe_ttm) and pe_ttm != 0:
                    report += f"   å¸‚ç›ˆçŽ‡TTM(PE_TTM): {pe_ttm:.2f}\n"

                pb_mrq = row.get("pb_mrq")
                if pb_mrq is not None and pd.notna(pb_mrq) and pb_mrq != 0:
                    report += f"   å¸‚å‡€çŽ‡MRQ(PB_MHQ): {pb_mrq:.2f}\n"

                total_mv = row.get("total_mv")
                if total_mv is not None and pd.notna(total_mv):
                    report += f"   æ€»å¸‚å€¼: {total_mv:.2f}äº¿å…ƒ\n"

                circ_mv = row.get("circ_mv")
                if circ_mv is not None and pd.notna(circ_mv):
                    report += f"   æµé€šå¸‚å€¼: {circ_mv:.2f}äº¿å…ƒ\n"

                turnover_rate = row.get("turnover_rate")
                if turnover_rate is not None and pd.notna(turnover_rate):
                    report += f"   æ¢æ‰‹çŽ‡: {turnover_rate:.2f}%\n"

                volume_ratio = row.get("volume_ratio")
                if volume_ratio is not None and pd.notna(volume_ratio):
                    report += f"   é‡æ¯”: {volume_ratio:.2f}\n"

                logger.info(f"âœ… [Tushare] æˆåŠŸèŽ·å–åŸºæœ¬é¢æ•°æ®: {symbol}")
                logger.info(f"   PE={pe}, PB={pb}, PE_TTM={pe_ttm}")
                return report

            except asyncio.TimeoutError:
                logger.error(f"âŒ [Tushare] async æ“ä½œè¶…æ—¶")
                return f"âŒ Tushare æ•°æ®èŽ·å–è¶…æ—¶ï¼Œè¯·ç¨åŽé‡è¯•"
            except Exception as async_err:
                logger.error(f"âŒ [Tushare] async æ“ä½œå¤±è´¥: {async_err}")
                return f"âŒ Tushare æ•°æ®èŽ·å–å¤±è´¥: {async_err}"

        except ImportError as e:
            logger.error(f"âŒ [Tushare] å¯¼å…¥å¤±è´¥: {e}")
            return f"âŒ Tushare æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…: {e}"
        except Exception as e:
            logger.error(f"âŒ [Tushare] èŽ·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ èŽ·å– {symbol} åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}"

    def _convert_to_tushare_code(self, symbol: str) -> str:
        """
        å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸º Tushare æ ¼å¼

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¦‚ 605589, 605589.SH, 000001.SZ)

        Returns:
            str: Tushare æ ¼å¼ä»£ç  (å¦‚ 605589.SH)
        """
        # ç§»é™¤å·²æœ‰çš„åŽç¼€
        symbol = str(symbol).strip().upper()
        symbol = symbol.replace(".SH", "").replace(".SZ", "").replace(".BJ", "")

        # æ ¹æ®ä»£ç å‰ç¼€åˆ¤æ–­äº¤æ˜“æ‰€
        if symbol.startswith(("60", "68", "90")):
            return f"{symbol}.SH"  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
        elif symbol.startswith(("00", "30", "20")):
            return f"{symbol}.SZ"  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
        elif symbol.startswith(("8", "4")):
            return f"{symbol}.BJ"  # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€
        else:
            # æ— æ³•è¯†åˆ«çš„ä»£ç ï¼Œè¿”å›žåŽŸå§‹ä»£ç 
            logger.warning(f"âš ï¸ [Tushare] æ— æ³•è¯†åˆ« {symbol} çš„äº¤æ˜“æ‰€ï¼Œè¿”å›žåŽŸå§‹ä»£ç ")
            return symbol

    def _get_tushare_financial_indicators(self, symbol: str) -> str:
        """ä»Ž Tushare èŽ·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®"""
        try:
            from .providers.china.tushare import get_tushare_provider
            import asyncio

            logger.info(f"ðŸ“Š [Tushare] å¼€å§‹èŽ·å–è´¢åŠ¡æŒ‡æ ‡: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # åˆ›å»ºäº‹ä»¶å¾ªçŽ¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # è°ƒç”¨ TushareProvider çš„è´¢åŠ¡æŒ‡æ ‡æ–¹æ³•
            result = loop.run_until_complete(
                provider.get_financial_indicators_only(symbol, limit=1)
            )

            if not result or not result.get("financial_indicators"):
                logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®")
                return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®"

            indicators = result["financial_indicators"][0]

            # æ ¼å¼åŒ–è¾“å‡º
            report = f"\nðŸ“Š {symbol} è´¢åŠ¡æŒ‡æ ‡ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"

            # ç›ˆåˆ©èƒ½åŠ›
            report += "ðŸ’¹ ç›ˆåˆ©èƒ½åŠ›:\n"
            roe = indicators.get("roe")
            if roe is not None and pd.notna(roe):
                report += f"   ROE(å‡€èµ„äº§æ”¶ç›ŠçŽ‡): {roe:.2f}%\n"

            roa = indicators.get("roa")
            if roa is not None and pd.notna(roa):
                report += f"   ROA(æ€»èµ„äº§æ”¶ç›ŠçŽ‡): {roa:.2f}%\n"

            gross_profit_margin = indicators.get("grossprofit_margin")
            if gross_profit_margin is not None and pd.notna(gross_profit_margin):
                report += f"   æ¯›åˆ©çŽ‡: {gross_profit_margin:.2f}%\n"

            net_profit_margin = indicators.get("netprofit_margin")
            if net_profit_margin is not None and pd.notna(net_profit_margin):
                report += f"   å‡€åˆ©çŽ‡: {net_profit_margin:.2f}%\n"

            # å¿å€ºèƒ½åŠ›
            report += "\nðŸ¦ å¿å€ºèƒ½åŠ›:\n"
            debt_to_assets = indicators.get("debt_to_assets")
            if debt_to_assets is not None and pd.notna(debt_to_assets):
                report += f"   èµ„äº§è´Ÿå€ºçŽ‡: {debt_to_assets:.2f}%\n"

            current_ratio = indicators.get("current_ratio")
            if current_ratio is not None and pd.notna(current_ratio):
                report += f"   æµåŠ¨æ¯”çŽ‡: {current_ratio:.2f}\n"

            quick_ratio = indicators.get("quick_ratio")
            if quick_ratio is not None and pd.notna(quick_ratio):
                report += f"   é€ŸåŠ¨æ¯”çŽ‡: {quick_ratio:.2f}\n"

            # è¥è¿èƒ½åŠ›
            report += "\nðŸ”„ è¥è¿èƒ½åŠ›:\n"
            inv_turn = indicators.get("inv_turn")
            if inv_turn is not None and pd.notna(inv_turn):
                report += f"   å­˜è´§å‘¨è½¬çŽ‡: {inv_turn:.2f}æ¬¡\n"

            ar_turn = indicators.get("ar_turn")
            if ar_turn is not None and pd.notna(ar_turn):
                report += f"   åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡: {ar_turn:.2f}æ¬¡\n"

            ca_turn = indicators.get("ca_turn")
            if ca_turn is not None and pd.notna(ca_turn):
                report += f"   æµåŠ¨èµ„äº§å‘¨è½¬çŽ‡: {ca_turn:.2f}æ¬¡\n"

            # æˆé•¿èƒ½åŠ›
            report += "\nðŸ“ˆ æˆé•¿èƒ½åŠ›:\n"
            or_ratio = indicators.get("or_ratio")
            if or_ratio is not None and pd.notna(or_ratio):
                report += f"   è¥ä¸šæ”¶å…¥å¢žé•¿çŽ‡: {or_ratio:.2f}%\n"

            op_profit_growth = indicators.get("op_profit_growth_rate_yoy")
            if op_profit_growth is not None and pd.notna(op_profit_growth):
                report += f"   è¥ä¸šåˆ©æ¶¦å¢žé•¿çŽ‡: {op_profit_growth:.2f}%\n"

            logger.info(f"âœ… [Tushare] æˆåŠŸèŽ·å–è´¢åŠ¡æŒ‡æ ‡: {symbol}")
            return report

        except Exception as e:
            logger.error(f"âŒ [Tushare] èŽ·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ èŽ·å– {symbol} è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}"

    def _get_tushare_financial_reports(self, symbol: str) -> str:
        """ä»Ž Tushare èŽ·å–å®Œæ•´è´¢åŠ¡æŠ¥è¡¨"""
        try:
            from .providers.china.tushare import get_tushare_provider
            import asyncio

            logger.info(f"ðŸ“Š [Tushare] å¼€å§‹èŽ·å–è´¢åŠ¡æŠ¥è¡¨: {symbol}")

            provider = get_tushare_provider()

            # æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
            if not provider.is_available():
                logger.warning(f"âš ï¸ [Tushare] Provider ä¸å¯ç”¨")
                return f"âš ï¸ Tushare æœªåˆå§‹åŒ–æˆ– Token æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"

            # åˆ›å»ºäº‹ä»¶å¾ªçŽ¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # è°ƒç”¨ TushareProvider çš„è´¢åŠ¡æ•°æ®æ–¹æ³•
            result = loop.run_until_complete(
                provider.get_financial_data(symbol, report_type="quarterly", limit=1)
            )

            if not result:
                logger.warning(f"âš ï¸ [Tushare] æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®")
                return f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®"

            # æ ¼å¼åŒ–è¾“å‡º
            report = f"\nðŸ“Š {symbol} è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ¥è‡ª Tushareï¼‰\n\n"

            # åˆ©æ¶¦è¡¨æ•°æ®
            income_data = result.get("income_statement")
            if income_data and len(income_data) > 0:
                report += "ðŸ’° åˆ©æ¶¦è¡¨:\n"
                latest_income = income_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_income.get('end_date', 'æœªçŸ¥')}\n"
                report += (
                    f"   è¥ä¸šæ€»æ”¶å…¥: {latest_income.get('total_revenue', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   è¥ä¸šæ”¶å…¥: {latest_income.get('revenue', 0):,.2f}ä¸‡å…ƒ\n"
                report += (
                    f"   è¥ä¸šæˆæœ¬: {latest_income.get('operating_cost', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   å‡€åˆ©æ¶¦: {latest_income.get('n_income', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æ‰£éžå‡€åˆ©æ¶¦: {latest_income.get('n_income_attr_p', 0):,.2f}ä¸‡å…ƒ\n"

            # èµ„äº§è´Ÿå€ºè¡¨æ•°æ®
            balance_data = result.get("balance_sheet")
            if balance_data and len(balance_data) > 0:
                report += "\nðŸ“¦ èµ„äº§è´Ÿå€ºè¡¨:\n"
                latest_balance = balance_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_balance.get('end_date', 'æœªçŸ¥')}\n"
                report += (
                    f"   æ€»èµ„äº§: {latest_balance.get('total_assets', 0):,.2f}ä¸‡å…ƒ\n"
                )
                report += f"   æ€»è´Ÿå€º: {latest_balance.get('total_liab', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   è‚¡ä¸œæƒç›Š: {latest_balance.get('total_hldr_eqy_exc_min_int', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æµåŠ¨èµ„äº§: {latest_balance.get('total_cur_assets', 0):,.2f}ä¸‡å…ƒ\n"
                report += (
                    f"   æµåŠ¨è´Ÿå€º: {latest_balance.get('total_cur_liab', 0):,.2f}ä¸‡å…ƒ\n"
                )

            # çŽ°é‡‘æµé‡è¡¨æ•°æ®
            cashflow_data = result.get("cashflow_statement")
            if cashflow_data and len(cashflow_data) > 0:
                report += "\nðŸ’µ çŽ°é‡‘æµé‡è¡¨:\n"
                latest_cashflow = cashflow_data[0]
                report += f"   æŠ¥å‘ŠæœŸ: {latest_cashflow.get('end_date', 'æœªçŸ¥')}\n"
                report += f"   ç»è¥æ´»åŠ¨çŽ°é‡‘æµ: {latest_cashflow.get('n_cashflow_act', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   æŠ•èµ„æ´»åŠ¨çŽ°é‡‘æµ: {latest_cashflow.get('n_cashflow_inv_act', 0):,.2f}ä¸‡å…ƒ\n"
                report += f"   ç­¹èµ„æ´»åŠ¨çŽ°é‡‘æµ: {latest_cashflow.get('n_cash_flows_fnc_act', 0):,.2f}ä¸‡å…ƒ\n"

            logger.info(f"âœ… [Tushare] æˆåŠŸèŽ·å–è´¢åŠ¡æŠ¥è¡¨: {symbol}")
            return report

        except Exception as e:
            logger.error(f"âŒ [Tushare] èŽ·å–è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {symbol} - {e}")
            import traceback

            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            return f"âŒ èŽ·å– {symbol} è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {e}"

    def _get_akshare_fundamentals(self, symbol: str) -> str:
        """ä»Ž AKShare ç”ŸæˆåŸºæœ¬é¢åˆ†æž"""
        logger.debug(f"ðŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            # AKShare æ²¡æœ‰ç›´æŽ¥çš„åŸºæœ¬é¢æ•°æ®æŽ¥å£ï¼Œä½¿ç”¨ç”Ÿæˆåˆ†æž
            logger.info(f"ðŸ“Š [æ•°æ®æ¥æº: AKShare-ç”Ÿæˆåˆ†æž] ç”ŸæˆåŸºæœ¬é¢åˆ†æž: {symbol}")
            return self._generate_fundamentals_analysis(symbol)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShareå¼‚å¸¸] ç”ŸæˆåŸºæœ¬é¢åˆ†æžå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æžå¤±è´¥: {e}"

    def _get_valuation_indicators(self, symbol: str) -> Dict:
        """ä»Žstock_basic_infoé›†åˆèŽ·å–ä¼°å€¼æŒ‡æ ‡"""
        try:
            from tradingagents.config.database_manager import get_database_manager

            db_manager = get_database_manager()
            if not db_manager.is_mongodb_available():
                return {}

            client = db_manager.get_mongodb_client()
            db = client[db_manager.config.mongodb_config.database_name]

            # ä»Žstock_basic_infoé›†åˆèŽ·å–ä¼°å€¼æŒ‡æ ‡
            collection = db["stock_basic_info"]
            result = collection.find_one({"ts_code": symbol})

            if result:
                return {
                    "pe": result.get("pe"),
                    "pb": result.get("pb"),
                    "pe_ttm": result.get("pe_ttm"),
                    "total_mv": result.get("total_mv"),
                    "circ_mv": result.get("circ_mv"),
                }
            return {}

        except Exception as e:
            logger.error(f"èŽ·å–{symbol}ä¼°å€¼æŒ‡æ ‡å¤±è´¥: {e}")
            return {}

    def _format_financial_data(self, symbol: str, financial_data: List[Dict]) -> str:
        """æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š"""
        try:
            if not financial_data or len(financial_data) == 0:
                return f"âŒ æœªæ‰¾åˆ°{symbol}çš„è´¢åŠ¡æ•°æ®"

            # èŽ·å–æœ€æ–°çš„è´¢åŠ¡æ•°æ®
            latest = financial_data[0]

            # æž„å»ºæŠ¥å‘Š
            report = f"ðŸ“Š {symbol} åŸºæœ¬é¢æ•°æ®ï¼ˆæ¥è‡ªMongoDBï¼‰\n\n"

            # åŸºæœ¬ä¿¡æ¯
            report += f"ðŸ“… æŠ¥å‘ŠæœŸ: {latest.get('report_period', latest.get('end_date', 'æœªçŸ¥'))}\n"
            report += f"ðŸ“ˆ æ•°æ®æ¥æº: MongoDBè´¢åŠ¡æ•°æ®åº“\n\n"

            # è´¢åŠ¡æŒ‡æ ‡
            report += "ðŸ’° è´¢åŠ¡æŒ‡æ ‡:\n"
            revenue = latest.get("revenue") or latest.get("total_revenue")
            if revenue is not None:
                report += f"   è¥ä¸šæ€»æ”¶å…¥: {revenue:,.2f}\n"

            net_profit = latest.get("net_profit") or latest.get("net_income")
            if net_profit is not None:
                report += f"   å‡€åˆ©æ¶¦: {net_profit:,.2f}\n"

            total_assets = latest.get("total_assets")
            if total_assets is not None:
                report += f"   æ€»èµ„äº§: {total_assets:,.2f}\n"

            total_liab = latest.get("total_liab")
            if total_liab is not None:
                report += f"   æ€»è´Ÿå€º: {total_liab:,.2f}\n"

            total_equity = latest.get("total_equity")
            if total_equity is not None:
                report += f"   è‚¡ä¸œæƒç›Š: {total_equity:,.2f}\n"

            # ä¼°å€¼æŒ‡æ ‡ - ä»Žstock_basic_infoé›†åˆèŽ·å–
            report += "\nðŸ“Š ä¼°å€¼æŒ‡æ ‡:\n"
            valuation_data = self._get_valuation_indicators(symbol)
            if valuation_data:
                pe = valuation_data.get("pe")
                if pe is not None:
                    report += f"   å¸‚ç›ˆçŽ‡(PE): {pe:.2f}\n"

                pb = valuation_data.get("pb")
                if pb is not None:
                    report += f"   å¸‚å‡€çŽ‡(PB): {pb:.2f}\n"

                pe_ttm = valuation_data.get("pe_ttm")
                if pe_ttm is not None:
                    report += f"   å¸‚ç›ˆçŽ‡TTM(PE_TTM): {pe_ttm:.2f}\n"

                total_mv = valuation_data.get("total_mv")
                if total_mv is not None:
                    report += f"   æ€»å¸‚å€¼: {total_mv:.2f}äº¿å…ƒ\n"

                circ_mv = valuation_data.get("circ_mv")
                if circ_mv is not None:
                    report += f"   æµé€šå¸‚å€¼: {circ_mv:.2f}äº¿å…ƒ\n"
            else:
                # å¦‚æžœæ— æ³•ä»Žstock_basic_infoèŽ·å–ï¼Œå°è¯•ä»Žè´¢åŠ¡æ•°æ®è®¡ç®—
                pe = latest.get("pe")
                if pe is not None:
                    report += f"   å¸‚ç›ˆçŽ‡(PE): {pe:.2f}\n"

                pb = latest.get("pb")
                if pb is not None:
                    report += f"   å¸‚å‡€çŽ‡(PB): {pb:.2f}\n"

                ps = latest.get("ps")
                if ps is not None:
                    report += f"   å¸‚é”€çŽ‡(PS): {ps:.2f}\n"

            # ç›ˆåˆ©èƒ½åŠ›
            report += "\nðŸ’¹ ç›ˆåˆ©èƒ½åŠ›:\n"
            roe = latest.get("roe")
            if roe is not None:
                report += f"   å‡€èµ„äº§æ”¶ç›ŠçŽ‡(ROE): {roe:.2f}%\n"

            roa = latest.get("roa")
            if roa is not None:
                report += f"   æ€»èµ„äº§æ”¶ç›ŠçŽ‡(ROA): {roa:.2f}%\n"

            gross_margin = latest.get("gross_margin")
            if gross_margin is not None:
                report += f"   æ¯›åˆ©çŽ‡: {gross_margin:.2f}%\n"

            netprofit_margin = latest.get("netprofit_margin") or latest.get(
                "net_margin"
            )
            if netprofit_margin is not None:
                report += f"   å‡€åˆ©çŽ‡: {netprofit_margin:.2f}%\n"

            # çŽ°é‡‘æµ
            n_cashflow_act = latest.get("n_cashflow_act")
            if n_cashflow_act is not None:
                report += "\nðŸ’° çŽ°é‡‘æµ:\n"
                report += f"   ç»è¥æ´»åŠ¨çŽ°é‡‘æµ: {n_cashflow_act:,.2f}\n"

                n_cashflow_inv_act = latest.get("n_cashflow_inv_act")
                if n_cashflow_inv_act is not None:
                    report += f"   æŠ•èµ„æ´»åŠ¨çŽ°é‡‘æµ: {n_cashflow_inv_act:,.2f}\n"

                c_cash_equ_end_period = latest.get("c_cash_equ_end_period")
                if c_cash_equ_end_period is not None:
                    report += f"   æœŸæœ«çŽ°é‡‘åŠç­‰ä»·ç‰©: {c_cash_equ_end_period:,.2f}\n"

            report += f"\nðŸ“ å…±æœ‰ {len(financial_data)} æœŸè´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return f"âŒ æ ¼å¼åŒ–{symbol}è´¢åŠ¡æ•°æ®å¤±è´¥: {e}"

    def _generate_fundamentals_analysis(self, symbol: str) -> str:
        """ç”ŸæˆåŸºæœ¬çš„åŸºæœ¬é¢åˆ†æž"""
        try:
            # èŽ·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = self.get_stock_info(symbol)

            report = f"ðŸ“Š {symbol} åŸºæœ¬é¢åˆ†æžï¼ˆç”Ÿæˆï¼‰\n\n"
            report += f"ðŸ“ˆ è‚¡ç¥¨åç§°: {stock_info.get('name', 'æœªçŸ¥')}\n"
            report += f"ðŸ¢ æ‰€å±žè¡Œä¸š: {stock_info.get('industry', 'æœªçŸ¥')}\n"
            report += f"ðŸ“ æ‰€å±žåœ°åŒº: {stock_info.get('area', 'æœªçŸ¥')}\n"
            report += f"ðŸ“… ä¸Šå¸‚æ—¥æœŸ: {stock_info.get('list_date', 'æœªçŸ¥')}\n"
            report += f"ðŸ›ï¸ äº¤æ˜“æ‰€: {stock_info.get('exchange', 'æœªçŸ¥')}\n\n"

            report += "âš ï¸ æ³¨æ„: è¯¦ç»†è´¢åŠ¡æ•°æ®éœ€è¦ä»Žæ•°æ®æºèŽ·å–\n"
            report += "ðŸ’¡ å»ºè®®: å¯ç”¨MongoDBç¼“å­˜ä»¥èŽ·å–å®Œæ•´çš„è´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆåŸºæœ¬é¢åˆ†æžå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æžå¤±è´¥: {e}"

    def _try_fallback_fundamentals(self, symbol: str) -> str:
        """åŸºæœ¬é¢æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ðŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–åŸºæœ¬é¢...")

        # ðŸ”¥ ä»Žæ•°æ®åº“èŽ·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ðŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–åŸºæœ¬é¢: {source.value}")

                    # ç›´æŽ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_fundamentals(symbol)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_fundamentals(symbol)
                    else:
                        continue

                    if result and "âŒ" not in result:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸèŽ·å–åŸºæœ¬é¢: {source.value}"
                        )
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}è¿”å›žé”™è¯¯ç»“æžœ")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æž
        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: ç”Ÿæˆåˆ†æž] æ‰€æœ‰æ•°æ®æºå¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æž: {symbol}")
        return self._generate_fundamentals_analysis(symbol)

    def _get_mongodb_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»ŽMongoDBèŽ·å–æ–°é—»æ•°æ®"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import (
                get_mongodb_cache_adapter,
            )

            adapter = get_mongodb_cache_adapter()

            # ä»ŽMongoDBèŽ·å–æ–°é—»æ•°æ®
            news_data = adapter.get_news_data(
                symbol, hours_back=hours_back, limit=limit
            )

            if news_data and len(news_data) > 0:
                logger.info(
                    f"âœ… [æ•°æ®æ¥æº: MongoDB-æ–°é—»] æˆåŠŸèŽ·å–: {symbol or 'å¸‚åœºæ–°é—»'} ({len(news_data)}æ¡)"
                )
                return news_data
            else:
                logger.warning(
                    f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº"
                )
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDB] èŽ·å–æ–°é—»å¤±è´¥: {e}")
            return self._try_fallback_news(symbol, hours_back, limit)

    def _get_tushare_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»ŽTushareèŽ·å–æ–°é—»æ•°æ®"""
        try:
            # Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›žç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: Tushare] Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: Tushare] èŽ·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _get_akshare_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """ä»ŽAKShareèŽ·å–æ–°é—»æ•°æ®"""
        try:
            # AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›žç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: AKShare] AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShare] èŽ·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _try_fallback_news(
        self, symbol: str, hours_back: int, limit: int
    ) -> List[Dict[str, Any]]:
        """æ–°é—»æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ðŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–æ–°é—»...")

        # ðŸ”¥ ä»Žæ•°æ®åº“èŽ·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ðŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºèŽ·å–æ–°é—»: {source.value}")

                    # ç›´æŽ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_news(symbol, hours_back, limit)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_news(symbol, hours_back, limit)
                    else:
                        continue

                    if result and len(result) > 0:
                        logger.info(
                            f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸèŽ·å–æ–°é—»: {source.value}"
                        )
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}æœªè¿”å›žæ–°é—»")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        logger.warning(
            f"âš ï¸ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•èŽ·å–æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}"
        )
        return []

    # ========== æ•°æ®è´¨é‡è¯„åˆ†å’ŒéªŒè¯åŠŸèƒ½ ==========

    def get_data_quality_score(self, symbol: str, data: Dict[str, Any]) -> float:
        """
        èŽ·å–æ•°æ®è´¨é‡è¯„åˆ† (0-100)

        è¯„åˆ†ç»´åº¦:
        - æ•°æ®å®Œæ•´æ€§ (30åˆ†): å¿…éœ€å­—æ®µæ˜¯å¦é½å…¨
        - æ•°æ®ä¸€è‡´æ€§ (30åˆ†): æŒ‡æ ‡é—´é€»è¾‘å…³ç³»æ˜¯å¦æ­£ç¡®
        - æ•°æ®æ—¶æ•ˆæ€§ (20åˆ†): æ•°æ®æ˜¯å¦æ˜¯æœ€æ–°çš„
        - æ•°æ®æºå¯é æ€§ (20åˆ†): æ•°æ®æºçš„å¯ä¿¡åº¦

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: å¾…è¯„åˆ†çš„æ•°æ®å­—å…¸

        Returns:
            float: è´¨é‡è¯„åˆ† (0-100)
        """
        score = 0.0
        max_score = 100.0

        # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ (30åˆ†)
        completeness_score = self._check_data_completeness(data)
        score += completeness_score * 0.3

        # 2. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ (30åˆ†)
        consistency_score = self._check_data_consistency(symbol, data)
        score += consistency_score * 0.3

        # 3. æ•°æ®æ—¶æ•ˆæ€§æ£€æŸ¥ (20åˆ†)
        timeliness_score = self._check_data_timeliness(data)
        score += timeliness_score * 0.2

        # 4. æ•°æ®æºå¯é æ€§ (20åˆ†)
        reliability_score = self._check_data_source_reliability()
        score += reliability_score * 0.2

        logger.debug(
            f"ðŸ“Š [æ•°æ®è´¨é‡è¯„åˆ†] {symbol}: {score:.1f}/100 "
            f"(å®Œæ•´:{completeness_score:.1f} ä¸€è‡´:{consistency_score:.1f} "
            f"æ—¶æ•ˆ:{timeliness_score:.1f} å¯é :{reliability_score:.1f})"
        )

        return min(score, max_score)

    def _check_data_completeness(self, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        required_fields = {
            # åŸºç¡€ä»·æ ¼æ•°æ®
            "current_price",
            "open",
            "high",
            "low",
            "volume",
            # åŸºæœ¬é¢æ•°æ®
            "market_cap",
            "PE",
            "PB",
        }

        optional_fields = {
            "MA5",
            "MA10",
            "MA20",
            "MA60",
            "RSI",
            "MACD",
            "turnover_rate",
            "ROE",
            "ROA",
        }

        score = 0.0
        total_weight = 1.0

        # å¿…éœ€å­—æ®µ (æƒé‡0.7)
        present_required = sum(
            1 for f in required_fields if f in data and data[f] is not None
        )
        if required_fields:
            required_score = (present_required / len(required_fields)) * 70
            score += required_score * 0.7

        # å¯é€‰å­—æ®µ (æƒé‡0.3)
        present_optional = sum(
            1 for f in optional_fields if f in data and data[f] is not None
        )
        if optional_fields:
            optional_score = (present_optional / len(optional_fields)) * 30
            score += optional_score * 0.3

        return score

    def _check_data_consistency(self, symbol: str, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        score = 100.0
        issues = []

        # æ£€æŸ¥1: high >= low
        if "high" in data and "low" in data:
            if data["high"] < data["low"]:
                issues.append("æœ€é«˜ä»· < æœ€ä½Žä»·")
                score -= 20

        # æ£€æŸ¥2: current_price åœ¨ high å’Œ low ä¹‹é—´
        if all(k in data for k in ["current_price", "high", "low"]):
            price = data["current_price"]
            if not (data["low"] <= price <= data["high"]):
                issues.append(f"å½“å‰ä»·{price}ä¸åœ¨æœ€é«˜æœ€ä½Žä»·èŒƒå›´å†…")
                score -= 15

        # æ£€æŸ¥3: å¸‚å€¼è®¡ç®—ä¸€è‡´æ€§
        if all(k in data for k in ["market_cap", "share_count", "current_price"]):
            try:
                market_cap = data["market_cap"]
                share_count = data["share_count"]
                price = data["current_price"]

                calculated_cap = (share_count * price) / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
                if market_cap > 0:
                    diff_pct = abs((calculated_cap - market_cap) / market_cap) * 100
                    if diff_pct > 15:  # è¶…è¿‡15%è¯¯å·®
                        issues.append(f"å¸‚å€¼è®¡ç®—ä¸ä¸€è‡´ (å·®å¼‚{diff_pct:.1f}%)")
                        score -= 10
            except (ValueError, TypeError, ZeroDivisionError):
                pass

        # æ£€æŸ¥4: PSæ¯”çŽ‡ä¸€è‡´æ€§
        if all(k in data for k in ["market_cap", "revenue", "PS"]):
            try:
                calculated_ps = data["market_cap"] / data["revenue"]
                if data["revenue"] > 0:
                    diff_pct = abs((calculated_ps - data["PS"]) / data["PS"]) * 100
                    if diff_pct > 10:  # è¶…è¿‡10%è¯¯å·®
                        issues.append(f"PSæ¯”çŽ‡è®¡ç®—ä¸ä¸€è‡´ (å·®å¼‚{diff_pct:.1f}%)")
                        score -= 15
            except (ValueError, TypeError, ZeroDivisionError):
                pass

        # æ£€æŸ¥5: MAåºåˆ—å…³ç³»
        if all(k in data for k in ["MA5", "MA10", "MA20"]):
            ma5, ma10, ma20 = data["MA5"], data["MA10"], data["MA20"]
            # ä¸Šå‡è¶‹åŠ¿: MA5 > MA10 > MA20
            # ä¸‹é™è¶‹åŠ¿: MA5 < MA10 < MA20
            # å¦‚æžœMA5åœ¨MA10å’ŒMA20ä¹‹é—´,å¯èƒ½æœ‰é—®é¢˜
            if not (ma10 < ma5 < ma20 or ma20 < ma5 < ma10):
                issues.append(f"MAåºåˆ—å…³ç³»å¼‚å¸¸: MA5={ma5}, MA10={ma10}, MA20={ma20}")
                score -= 5

        if issues:
            logger.debug(f"ðŸ“Š [æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥] {symbol}: {', '.join(issues)}")

        return max(score, 0.0)

    def _check_data_timeliness(self, data: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ•°æ®æ—¶æ•ˆæ€§"""
        score = 100.0

        # æ£€æŸ¥æ•°æ®ä¸­çš„æ—¥æœŸ
        data_date = data.get("date") or data.get("trade_date") or data.get("timestamp")
        if data_date:
            try:
                from datetime import datetime

                # å°è¯•è§£æžæ—¥æœŸ
                if isinstance(data_date, str):
                    data_date = datetime.strptime(data_date.split()[0], "%Y-%m-%d")
                elif isinstance(data_date, (int, float)):
                    # å‡è®¾æ˜¯Unixæ—¶é—´æˆ³
                    data_date = datetime.fromtimestamp(data_date)

                if data_date:
                    now = datetime.now()
                    days_old = (now - data_date).days

                    # æ•°æ®è¶Šæ–°,åˆ†æ•°è¶Šé«˜
                    if days_old <= 1:
                        score = 100
                    elif days_old <= 7:
                        score = 80
                    elif days_old <= 30:
                        score = 60
                    else:
                        score = 40
            except Exception as e:
                logger.debug(f"æ—¥æœŸè§£æžå¤±è´¥: {e}")
                score = 50  # æ— æ³•åˆ¤æ–­,ç»™ä¸­ç­‰åˆ†

        return score

    def _check_data_source_reliability(self) -> float:
        """æ£€æŸ¥æ•°æ®æºå¯é æ€§"""
        # æ•°æ®æºå¯é æ€§è¯„åˆ†
        reliability_scores = {
            ChinaDataSource.MONGODB: 95,  # ç¼“å­˜æ•°æ®,æœ€å¯é 
            ChinaDataSource.TUSHARE: 90,  # å®˜æ–¹æ•°æ®,é«˜è´¨é‡
            ChinaDataSource.BAOSTOCK: 75,  # å…è´¹ä½†ç¨³å®š
            ChinaDataSource.AKSHARE: 70,  # å¤šæºèšåˆ,è´¨é‡æ³¢åŠ¨
        }

        score = reliability_scores.get(self.current_source, 60)
        return float(score)

    def get_best_source_for_metric(self, metric: str) -> str:
        """
        èŽ·å–æŒ‡å®šæŒ‡æ ‡çš„æœ€ä½³æ•°æ®æº

        é‡è¦ä¿®æ­£:
        - å®žæ—¶è¡Œæƒ…æŒ‡æ ‡ä¼˜å…ˆä½¿ç”¨ AkShare (çœŸæ­£å®žæ—¶)
        - åŸºæœ¬é¢æŒ‡æ ‡ä¼˜å…ˆä½¿ç”¨ Tushare (æœ€å‡†ç¡®)
        - æŠ€æœ¯æŒ‡æ ‡åŸºäºŽåŽ†å²æ•°æ®, Tushare æ›´å¯é 

        Args:
            metric: æŒ‡æ ‡åç§°,å¦‚ 'PE', 'PB', 'PS', 'MA5', 'RSI', 'volume'

        Returns:
            str: æŽ¨èçš„æ•°æ®æºåç§°
        """
        # åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´ (éœ€è¦å®žæ—¶æ•°æ®)
        is_trading_hours = self._is_trading_hours()

        # å®žæ—¶è¡Œæƒ…æŒ‡æ ‡é›†åˆ
        realtime_metrics = {
            "current_price",
            "open",
            "high",
            "low",
            "volume",
            "turnover_rate",
        }

        # ä¸åŒæ•°æ®æºçš„ç‰¹é•¿
        source_specialties = {
            # åŸºæœ¬é¢æŒ‡æ ‡ - Tushareæœ€å‡†ç¡®
            "PE": ChinaDataSource.TUSHARE,
            "PB": ChinaDataSource.TUSHARE,
            "PS": ChinaDataSource.TUSHARE,
            "ROE": ChinaDataSource.TUSHARE,
            "ROA": ChinaDataSource.TUSHARE,
            "market_cap": ChinaDataSource.TUSHARE,
            "revenue": ChinaDataSource.TUSHARE,
            "total_assets": ChinaDataSource.TUSHARE,
            "net_profit": ChinaDataSource.TUSHARE,
            # æŠ€æœ¯æŒ‡æ ‡ - åŸºäºŽåŽ†å²æ•°æ®,Tushareæ›´å¯é 
            "MA5": ChinaDataSource.TUSHARE,
            "MA10": ChinaDataSource.TUSHARE,
            "MA20": ChinaDataSource.TUSHARE,
            "MA60": ChinaDataSource.TUSHARE,
            "RSI": ChinaDataSource.TUSHARE,
            "RSI6": ChinaDataSource.TUSHARE,
            "RSI12": ChinaDataSource.TUSHARE,
            "MACD": ChinaDataSource.TUSHARE,
            "BOLL": ChinaDataSource.TUSHARE,
            "BOLL_UPPER": ChinaDataSource.TUSHARE,
            "BOLL_LOWER": ChinaDataSource.TUSHARE,
            "BOLL_MIDDLE": ChinaDataSource.TUSHARE,
            # å®žæ—¶è¡Œæƒ… - æ ¹æ®æ—¶é—´é€‰æ‹©æ•°æ®æº
            # ç›˜ä¸­: AkShare (çœŸæ­£å®žæ—¶,ç§’çº§æ›´æ–°)
            # ç›˜åŽ: Tushare (å®Œæ•´æ•°æ®,ç»è¿‡æ¸…æ´—)
            "current_price": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "open": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "high": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "low": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "volume": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            "turnover_rate": ChinaDataSource.AKSHARE
            if is_trading_hours
            else ChinaDataSource.TUSHARE,
            # é»˜è®¤
            "default": ChinaDataSource.TUSHARE,
        }

        best_source = source_specialties.get(metric, source_specialties["default"])

        # å¦‚æžœæ˜¯å®žæ—¶æŒ‡æ ‡ä¸”åœ¨ç›˜ä¸­,è®°å½•æ—¥å¿—
        if metric in realtime_metrics and is_trading_hours:
            logger.info(
                f"ðŸ“Š [ç›˜ä¸­å®žæ—¶] {metric} ä½¿ç”¨ {best_source.value} "
                f"(åŽŸå› : {'ç›˜ä¸­éœ€è¦å®žæ—¶æ•°æ®' if best_source == ChinaDataSource.AKSHARE else 'ç›˜åŽä½¿ç”¨å®Œæ•´æ•°æ®'})"
            )

        # å¦‚æžœæœ€ä½³æ•°æ®æºä¸å¯ç”¨,ä½¿ç”¨å½“å‰å¯ç”¨æº
        if best_source not in self.available_sources:
            logger.warning(
                f"âš ï¸ {metric} çš„æœ€ä½³æ•°æ®æº {best_source.value} ä¸å¯ç”¨, "
                f"ä½¿ç”¨å½“å‰æ•°æ®æº {self.current_source.value}"
            )
            return self.current_source.value

        return best_source.value

    def _is_trading_hours(self) -> bool:
        """
        åˆ¤æ–­å½“å‰æ˜¯å¦æ˜¯Aè‚¡äº¤æ˜“æ—¶é—´

        Aè‚¡äº¤æ˜“æ—¶é—´:
        - ä¸Šåˆ: 9:30 - 11:30
        - ä¸‹åˆ: 13:00 - 15:00
        - å»¶åŽ30åˆ†é’Ÿ: ç”¨äºŽæ”¶ç›˜åŽçš„åˆ†æž (15:00 - 15:30)

        Returns:
            bool: Trueè¡¨ç¤ºéœ€è¦å®žæ—¶æ•°æ®
        """
        try:
            from datetime import datetime

            now = datetime.now()

            # å‘¨æœ«ä¸äº¤æ˜“
            if now.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                return False

            current_time = now.hour * 100 + now.minute  # è½¬æ¢ä¸ºHHMMæ ¼å¼,å¦‚930è¡¨ç¤º9:30

            # ä¸Šåˆæ—¶æ®µ: 9:30-11:30, åŠ ä¸Š30åˆ†é’Ÿç¼“å†²åˆ°12:00
            morning_start = 930
            morning_end = 1200

            # ä¸‹åˆæ—¶æ®µ: 13:00-15:30 (æ”¶ç›˜åŽ30åˆ†é’Ÿ)
            afternoon_start = 1300
            afternoon_end = 1530

            is_morning = morning_start <= current_time <= morning_end
            is_afternoon = afternoon_start <= current_time <= afternoon_end

            return is_morning or is_afternoon

        except Exception as e:
            logger.warning(f"åˆ¤æ–­äº¤æ˜“æ—¶é—´å¤±è´¥: {e}, é»˜è®¤ä¸ºéžäº¤æ˜“æ—¶é—´")
            return False

    def is_realtime_capable(self, source: ChinaDataSource) -> Dict[str, bool]:
        """
        åˆ¤æ–­æ•°æ®æºæ˜¯å¦æ”¯æŒå®žæ—¶è¡Œæƒ…

        Args:
            source: æ•°æ®æºæžšä¸¾

        Returns:
            Dict[str, bool]: å„é¡¹å®žæ—¶èƒ½åŠ›çš„å­—å…¸
            {
                'realtime_quote': æ˜¯å¦æ”¯æŒå®žæ—¶æŠ¥ä»·,
                'tick_data': æ˜¯å¦æ”¯æŒé€ç¬”æˆäº¤,
                'level2': æ˜¯å¦æ”¯æŒLevel-2è¡Œæƒ…,
                'delay_seconds': æ•°æ®å»¶è¿Ÿç§’æ•°
            }
        """
        capabilities = {
            ChinaDataSource.MONGODB: {
                "realtime_quote": False,  # ç¼“å­˜æ•°æ®,éžå®žæ—¶
                "tick_data": False,
                "level2": False,
                "delay_seconds": 0,
                "description": "ç¼“å­˜æ•°æ®,æ¥è‡ªå…¶ä»–æ•°æ®æºçš„åŽ†å²å¿«ç…§",
            },
            ChinaDataSource.TUSHARE: {
                "realtime_quote": True,  # æ”¯æŒ,ä½†æœ‰å»¶è¿Ÿ
                "tick_data": True,  # éœ€è¦é«˜çº§ç§¯åˆ†
                "level2": False,  # ä¸æ”¯æŒ
                "delay_seconds": 900,  # çº¦15åˆ†é’Ÿå»¶è¿Ÿ
                "description": "å®˜æ–¹æ•°æ®,ä½†å®žæ—¶è¡Œæƒ…æœ‰15åˆ†é’Ÿå»¶è¿Ÿ",
            },
            ChinaDataSource.AKSHARE: {
                "realtime_quote": True,  # âœ… çœŸæ­£å®žæ—¶
                "tick_data": True,  # âœ… æ”¯æŒ
                "level2": True,  # âœ… éƒ¨åˆ†æ”¯æŒ
                "delay_seconds": 1,  # ç§’çº§å»¶è¿Ÿ
                "description": "âœ… æœ€ä½³å®žæ—¶æ•°æ®æº,æ¥è‡ªä¸œæ–¹è´¢å¯Œ/è…¾è®¯",
            },
            ChinaDataSource.BAOSTOCK: {
                "realtime_quote": False,  # ä¸æ”¯æŒå®žæ—¶
                "tick_data": False,
                "level2": False,
                "delay_seconds": 86400,  # T+1,æ¬¡æ—¥æ›´æ–°
                "description": "ä»…æä¾›åŽ†å²æ•°æ®,ä¸æ”¯æŒå®žæ—¶è¡Œæƒ…",
            },
        }

        return capabilities.get(
            source,
            {
                "realtime_quote": False,
                "tick_data": False,
                "level2": False,
                "delay_seconds": 999999,
                "description": "æœªçŸ¥æ•°æ®æº",
            },
        )

    async def get_data_with_validation(
        self, symbol: str, metric: str, period: str = "daily"
    ) -> tuple[Any, Dict]:
        """
        èŽ·å–æ•°æ®å¹¶è‡ªåŠ¨éªŒè¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            metric: æŒ‡æ ‡åç§° ('current_price', 'PE', 'volume', etc.)
            period: æ•°æ®å‘¨æœŸ

        Returns:
            tuple[Any, Dict]: (æ•°æ®å€¼, éªŒè¯ç»“æžœå­—å…¸)
        """
        # èŽ·å–æœ€ä½³æ•°æ®æº
        best_source_name = self.get_best_source_for_metric(metric)
        logger.info(f"ðŸ“Š [éªŒè¯] ä¸º {metric} é€‰æ‹©æ•°æ®æº: {best_source_name}")

        # èŽ·å–æ•°æ®
        data_str = self.get_stock_data(symbol, "2024-01-01", "2024-12-31", period)

        # è§£æžæ•°æ®
        data = self._parse_data_string(data_str)

        if not data:
            return None, {"is_valid": False, "error": "æ— æ³•èŽ·å–æ•°æ®"}

        # æå–è¯·æ±‚çš„æŒ‡æ ‡
        metric_value = data.get(metric)

        # è´¨é‡è¯„åˆ†
        quality_score = self.get_data_quality_score(symbol, data)

        validation_result = {
            "is_valid": quality_score >= 60,
            "quality_score": quality_score,
            "source": best_source_name,
            "metric": metric,
            "value": metric_value,
            "data": data,
            "warnings": [],
            "errors": [],
        }

        # æ ¹æ®è´¨é‡è¯„åˆ†æ·»åŠ è­¦å‘Š
        if quality_score < 70:
            validation_result["warnings"].append(
                f"æ•°æ®è´¨é‡è¾ƒä½Ž ({quality_score:.1f}/100)"
            )
        if quality_score < 60:
            validation_result["errors"].append(
                f"æ•°æ®è´¨é‡ä¸åˆæ ¼ ({quality_score:.1f}/100)"
            )

        return metric_value, validation_result

    async def cross_validate_metric(
        self, symbol: str, metric: str, sources: List[str] = None
    ) -> Dict:
        """
        å¤šæºäº¤å‰éªŒè¯æŒ‡æ ‡

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            metric: æŒ‡æ ‡åç§°
            sources: è¦éªŒè¯çš„æ•°æ®æºåˆ—è¡¨,å¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨æº

        Returns:
            Dict: äº¤å‰éªŒè¯ç»“æžœ
        """
        if sources is None:
            sources = [s.value for s in self.available_sources]

        logger.info(f"ðŸ“Š [äº¤å‰éªŒè¯] å¼€å§‹å¤šæºéªŒè¯ {symbol} çš„ {metric}")

        results = {}
        values = {}

        # ä¿å­˜å½“å‰æ•°æ®æº
        original_source = self.current_source

        try:
            for source in sources:
                try:
                    # åˆ‡æ¢æ•°æ®æº
                    source_enum = ChinaDataSource(source)
                    if source_enum in self.available_sources:
                        self.current_source = source_enum

                        # èŽ·å–æ•°æ®
                        value, validation = await self.get_data_with_validation(
                            symbol, metric
                        )

                        if value is not None:
                            results[source] = {
                                "value": value,
                                "quality_score": validation.get("quality_score", 0),
                                "is_valid": validation.get("is_valid", False),
                            }
                            values[source] = value

                except Exception as e:
                    logger.warning(f"ä»Ž {source} èŽ·å– {metric} å¤±è´¥: {e}")
                    continue

        finally:
            # æ¢å¤åŽŸå§‹æ•°æ®æº
            self.current_source = original_source

        # åˆ†æžä¸€è‡´æ€§
        cross_validation_result = self._analyze_cross_validation_results(
            symbol, metric, results, values
        )

        return cross_validation_result

    def _analyze_cross_validation_results(
        self, symbol: str, metric: str, results: Dict, values: Dict
    ) -> Dict:
        """åˆ†æžäº¤å‰éªŒè¯ç»“æžœ"""
        if not values:
            return {
                "symbol": symbol,
                "metric": metric,
                "is_valid": False,
                "error": "æ— æ³•ä»Žä»»ä½•æ•°æ®æºèŽ·å–æ•°æ®",
                "sources_checked": list(results.keys()),
            }

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        value_list = list(values.values())
        num_sources = len(value_list)

        # åŸºæœ¬ç»Ÿè®¡
        min_val = min(value_list)
        max_val = max(value_list)
        avg_val = sum(value_list) / num_sources

        # è®¡ç®—æ ‡å‡†å·®å’Œå˜å¼‚ç³»æ•°
        variance = sum((x - avg_val) ** 2 for x in value_list) / num_sources
        std_dev = variance**0.5
        cv = (std_dev / avg_val * 100) if avg_val != 0 else 0

        # åˆ¤æ–­ä¸€è‡´æ€§
        is_consistent = cv < 5  # å˜å¼‚ç³»æ•°å°äºŽ5%è®¤ä¸ºä¸€è‡´

        # æ‰¾å‡ºæœ€å¯é çš„æ•°æ®æº
        best_source = (
            max(results.items(), key=lambda x: x[1]["quality_score"])[0]
            if results
            else None
        )

        # ä¸­ä½æ•°ä½œä¸ºæŽ¨èå€¼
        sorted_values = sorted(value_list)
        if num_sources % 2 == 0:
            median_value = (
                sorted_values[num_sources // 2 - 1] + sorted_values[num_sources // 2]
            ) / 2
        else:
            median_value = sorted_values[num_sources // 2]

        return {
            "symbol": symbol,
            "metric": metric,
            "is_valid": is_consistent,
            "is_consistent": is_consistent,
            "num_sources": num_sources,
            "sources_checked": list(results.keys()),
            "values_by_source": values,
            "quality_scores": {k: v["quality_score"] for k, v in results.items()},
            "statistics": {
                "min": min_val,
                "max": max_val,
                "avg": avg_val,
                "median": median_value,
                "std_dev": std_dev,
                "cv_percent": cv,
            },
            "recommendation": {
                "best_source": best_source,
                "suggested_value": median_value,
                "confidence": max(0, min(1, 1 - cv / 10)),  # CVè¶Šå°,ç½®ä¿¡åº¦è¶Šé«˜
            },
            "warnings": [] if is_consistent else [f"æ•°æ®æºé—´å˜å¼‚ç³»æ•°è¾ƒé«˜: {cv:.2f}%"],
            "errors": [] if num_sources > 0 else ["æ— æ³•èŽ·å–ä»»ä½•æ•°æ®"],
        }

    def _parse_data_string(self, data_str: str) -> Dict[str, Any]:
        """
        è§£æžæ•°æ®å­—ç¬¦ä¸²ä¸ºå­—å…¸

        è¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®žçŽ°,å®žé™…åº”è¯¥æ ¹æ®æ•°æ®æ ¼å¼è§£æž
        """
        if not data_str or isinstance(data_str, dict):
            return data_str or {}

        # å°è¯•è§£æžJSON
        if data_str.startswith("{"):
            import json

            try:
                return json.loads(data_str)
            except json.JSONDecodeError:
                pass

        # å¦‚æžœæ˜¯è¡¨æ ¼æ ¼å¼,è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„è§£æž
        # æš‚æ—¶è¿”å›žç©ºå­—å…¸
        logger.debug("æ— æ³•è§£æžæ•°æ®å­—ç¬¦ä¸²")
        return {}


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®žä¾‹
_data_source_manager = None


def get_data_source_manager() -> DataSourceManager:
    """èŽ·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®žä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager


def get_china_stock_data_unified(
    symbol: str, start_date: str, end_date: str, analysis_date: str = None
) -> str:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨æ•°æ®èŽ·å–æŽ¥å£
    è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„æ•°æ®æºï¼Œæ”¯æŒå¤‡ç”¨æ•°æ®æº

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        analysis_date: åˆ†æžæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œç”¨äºŽåˆ¤æ–­å®žæ—¶è¡Œæƒ…

    Returns:
        str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
    """
    from tradingagents.utils.logging_init import get_logger

    # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
    logger.info(
        f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] data_source_manager.get_china_stock_data_unified æŽ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»åž‹: {type(symbol)})"
    )
    logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
    logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")

    manager = get_data_source_manager()
    logger.info(
        f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ manager.get_stock_dataï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', start_date='{start_date}', end_date='{end_date}', analysis_date='{analysis_date}'"
    )
    result = manager.get_stock_data(
        symbol, start_date, end_date, analysis_date=analysis_date
    )
    # ðŸ”¥ FIX: å¤„ç†è¿”å›žç±»åž‹é”™è¯¯ï¼ˆtuple vs strï¼‰
    if isinstance(result, tuple):
        logger.warning(f"âš ï¸ [ç±»åž‹ä¿®å¤] get_stock_data è¿”å›žäº† tupleï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ ")
        result = result[0] if len(result) > 0 else None

    # åˆ†æžè¿”å›žç»“æžœçš„è¯¦ç»†ä¿¡æ¯
    if result and isinstance(result, str):
        lines = result.split("\n")
        data_lines = [line for line in lines if "2025-" in line and symbol in line]
        logger.info(
            f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›žç»“æžœç»Ÿè®¡: æ€»è¡Œæ•°={len(lines)}, æ•°æ®è¡Œæ•°={len(data_lines)}, ç»“æžœé•¿åº¦={len(result)}å­—ç¬¦"
        )
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›žç»“æžœå‰500å­—ç¬¦: {result[:500]}")
        if len(data_lines) > 0:
            logger.info(
                f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] æ•°æ®è¡Œç¤ºä¾‹: ç¬¬1è¡Œ='{data_lines[0][:100]}', æœ€åŽ1è¡Œ='{data_lines[-1][:100]}'"
            )
    else:
        logger.info(f"ðŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›žç»“æžœ: None")
    return result


def get_china_stock_info_unified(symbol: str) -> Dict:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨ä¿¡æ¯èŽ·å–æŽ¥å£

    Args:
        symbol: è‚¡ç¥¨ä»£ç 

    Returns:
        Dict: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    """
    manager = get_data_source_manager()
    return manager.get_stock_info(symbol)


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®žä¾‹
_data_source_manager = None


def get_data_source_manager() -> DataSourceManager:
    """èŽ·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®žä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager


# ==================== å…¼å®¹æ€§æŽ¥å£ ====================
# ä¸ºäº†å…¼å®¹ stock_data_serviceï¼Œæä¾›ç›¸åŒçš„æŽ¥å£


def get_stock_data_service() -> DataSourceManager:
    """
    èŽ·å–è‚¡ç¥¨æ•°æ®æœåŠ¡å®žä¾‹ï¼ˆå…¼å®¹ stock_data_service æŽ¥å£ï¼‰

    âš ï¸ æ­¤å‡½æ•°ä¸ºå…¼å®¹æ€§æŽ¥å£ï¼Œå®žé™…è¿”å›ž DataSourceManager å®žä¾‹
    æŽ¨èç›´æŽ¥ä½¿ç”¨ get_data_source_manager()
    """
    return get_data_source_manager()


# ==================== ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨ ====================


class USDataSourceManager:
    """
    ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨

    æ”¯æŒçš„æ•°æ®æºï¼š
    - yfinance: è‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼ˆå…è´¹ï¼‰
    - alpha_vantage: åŸºæœ¬é¢å’Œæ–°é—»æ•°æ®ï¼ˆéœ€è¦API Keyï¼‰
    - finnhub: å¤‡ç”¨æ•°æ®æºï¼ˆéœ€è¦API Keyï¼‰
    - mongodb: ç¼“å­˜æ•°æ®æºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    """

    def __init__(self):
        """åˆå§‹åŒ–ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ MongoDB ç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        # æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº
        self.available_sources = self._check_available_sources()

        # è®¾ç½®é»˜è®¤æ•°æ®æº
        self.default_source = self._get_default_source()
        self.current_source = self.default_source

        logger.info(f"ðŸ“Š ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(
            f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}"
        )
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled

        return use_app_cache_enabled()

    def _get_data_source_priority_order(
        self, symbol: Optional[str] = None
    ) -> List[USDataSource]:
        """
        ä»Žæ•°æ®åº“èŽ·å–ç¾Žè‚¡æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºŽé™çº§ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            æŒ‰ä¼˜å…ˆçº§æŽ’åºçš„æ•°æ®æºåˆ—è¡¨ï¼ˆä¸åŒ…å«MongoDBï¼‰
        """
        try:
            # ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # æ–¹æ³•1: ä»Ž datasource_groupings é›†åˆè¯»å–ï¼ˆæŽ¨èï¼‰
            groupings_collection = db.datasource_groupings
            groupings = list(
                groupings_collection.find(
                    {"market_category_id": "us_stocks", "enabled": True}
                ).sort("priority", -1)
            )  # é™åºæŽ’åºï¼Œä¼˜å…ˆçº§é«˜çš„åœ¨å‰

            if groupings:
                # è½¬æ¢ä¸º USDataSource æžšä¸¾
                # ðŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ USDataSource æžšä¸¾ï¼‰
                source_mapping = {
                    "yfinance": USDataSource.YFINANCE,
                    "yahoo_finance": USDataSource.YFINANCE,  # åˆ«å
                    "alpha_vantage": USDataSource.ALPHA_VANTAGE,
                    "finnhub": USDataSource.FINNHUB,
                }

                result = []
                for grouping in groupings:
                    ds_name = grouping.get("data_source_name", "").lower()
                    if ds_name in source_mapping:
                        source = source_mapping[ds_name]
                        # æŽ’é™¤ MongoDBï¼ˆMongoDB æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸å‚ä¸Žé™çº§ï¼‰
                        if (
                            source != USDataSource.MONGODB
                            and source in self.available_sources
                        ):
                            result.append(source)

                if result:
                    logger.info(
                        f"âœ… [ç¾Žè‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»Žæ•°æ®åº“è¯»å–: {[s.value for s in result]}"
                    )
                    return result

            logger.warning("âš ï¸ [ç¾Žè‚¡æ•°æ®æºä¼˜å…ˆçº§] æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
        except Exception as e:
            logger.warning(f"âš ï¸ [ç¾Žè‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»Žæ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # å›žé€€åˆ°é»˜è®¤é¡ºåº
        # é»˜è®¤é¡ºåºï¼šyfinance > Alpha Vantage > Finnhub
        default_order = [
            USDataSource.YFINANCE,
            USDataSource.ALPHA_VANTAGE,
            USDataSource.FINNHUB,
        ]
        # åªè¿”å›žå¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _get_default_source(self) -> USDataSource:
        """èŽ·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æžœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return USDataSource.MONGODB

        # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–ï¼Œé»˜è®¤ä½¿ç”¨ yfinance
        env_source = os.getenv(
            "DEFAULT_US_DATA_SOURCE", DataSourceCode.YFINANCE
        ).lower()

        # æ˜ å°„åˆ°æžšä¸¾
        source_mapping: Dict[str, USDataSource] = {
            DataSourceCode.YFINANCE.value: USDataSource.YFINANCE,
            DataSourceCode.ALPHA_VANTAGE.value: USDataSource.ALPHA_VANTAGE,
            DataSourceCode.FINNHUB.value: USDataSource.FINNHUB,
        }

        return source_mapping.get(env_source, USDataSource.YFINANCE)

    def _check_available_sources(self) -> List[USDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        ä»Žæ•°æ®åº“è¯»å–å¯ç”¨çŠ¶æ€ï¼Œå¹¶æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
        """
        available = []

        # MongoDB ç¼“å­˜
        if self.use_mongodb_cache:
            available.append(USDataSource.MONGODB)
            logger.info("âœ… MongoDBç¼“å­˜æ•°æ®æºå¯ç”¨")

        # ä»Žæ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨å’Œé…ç½®
        enabled_sources_in_db = self._get_enabled_sources_from_db()
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥ yfinance
        if "yfinance" in enabled_sources_in_db:
            try:
                import yfinance

                available.append(USDataSource.YFINANCE)
                logger.info("âœ… yfinanceæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ yfinanceæ•°æ®æºä¸å¯ç”¨: æœªå®‰è£… yfinance åº“")
        else:
            logger.info("â„¹ï¸ yfinanceæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Alpha Vantage
        if "alpha_vantage" in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»Žæ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get("alpha_vantage", {}).get(
                    "api_key"
                ) or os.getenv("ALPHA_VANTAGE_API_KEY")
                if api_key:
                    available.append(USDataSource.ALPHA_VANTAGE)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("alpha_vantage", {}).get("api_key")
                        else "çŽ¯å¢ƒå˜é‡"
                    )
                    logger.info(
                        f"âœ… Alpha Vantageæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})"
                    )
                else:
                    logger.warning(
                        "âš ï¸ Alpha Vantageæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’ŒçŽ¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Alpha Vantageæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Alpha Vantageæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Finnhub
        if "finnhub" in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»Žæ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get("finnhub", {}).get(
                    "api_key"
                ) or os.getenv("FINNHUB_API_KEY")
                if api_key:
                    available.append(USDataSource.FINNHUB)
                    source = (
                        "æ•°æ®åº“é…ç½®"
                        if datasource_configs.get("finnhub", {}).get("api_key")
                        else "çŽ¯å¢ƒå˜é‡"
                    )
                    logger.info(f"âœ… Finnhubæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning(
                        "âš ï¸ Finnhubæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’ŒçŽ¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰"
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Finnhubæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Finnhubæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        return available

    def _get_enabled_sources_from_db(self) -> List[str]:
        """ä»Žæ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä»Ž datasource_groupings é›†åˆè¯»å–
            groupings = list(
                db.datasource_groupings.find(
                    {"market_category_id": "us_stocks", "enabled": True}
                )
            )

            # ðŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ ä»£ç ä¸­ä½¿ç”¨çš„åç§°ï¼‰
            name_mapping = {
                "alpha vantage": "alpha_vantage",
                "yahoo finance": "yfinance",
                "finnhub": "finnhub",
            }

            result = []
            for g in groupings:
                db_name = g.get("data_source_name", "").lower()
                # ä½¿ç”¨æ˜ å°„è¡¨è½¬æ¢åç§°
                code_name = name_mapping.get(db_name, db_name)
                result.append(code_name)
                logger.debug(f"ðŸ”„ æ•°æ®æºåç§°æ˜ å°„: '{db_name}' â†’ '{code_name}'")

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»Žæ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºå¤±è´¥: {e}")
            # é»˜è®¤å…¨éƒ¨å¯ç”¨
            return ["yfinance", "alpha_vantage", "finnhub"]

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()

            # ä»Ž system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get("data_source_configs", [])

            # æž„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get("name", "").lower()
                result[name] = {
                    "api_key": ds_config.get("api_key", ""),
                    "api_secret": ds_config.get("api_secret", ""),
                    "config_params": ds_config.get("config_params", {}),
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»Žæ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> USDataSource:
        """èŽ·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: USDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… ç¾Žè‚¡æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ ç¾Žè‚¡æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False


# å…¨å±€ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨å®žä¾‹
_us_data_source_manager = None


def get_us_data_source_manager() -> USDataSourceManager:
    """èŽ·å–å…¨å±€ç¾Žè‚¡æ•°æ®æºç®¡ç†å™¨å®žä¾‹"""
    global _us_data_source_manager
    if _us_data_source_manager is None:
        _us_data_source_manager = USDataSourceManager()
    return _us_data_source_manager
