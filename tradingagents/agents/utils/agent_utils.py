# -*- coding: utf-8 -*-
from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, AIMessage
from typing import List
from typing import Annotated
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import RemoveMessage
from langchain_core.tools import tool
from datetime import date, timedelta, datetime
import functools
import pandas as pd
import os
from dateutil.relativedelta import relativedelta
from langchain_openai import ChatOpenAI
import tradingagents.dataflows.interface as interface
from tradingagents.default_config import DEFAULT_CONFIG
from langchain_core.messages import HumanMessage

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå’Œå·¥å…·æ—¥å¿—è£…é¥°å™¨
from tradingagents.utils.logging_init import get_logger
from tradingagents.utils.tool_logging import log_tool_call, log_analysis_step

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger

logger = get_logger("agents")


def create_msg_delete():
    def delete_messages(state):
        """Clear messages and add placeholder for Anthropic compatibility

        æ³¨æ„ï¼šåœ¨å¹¶è¡Œæ‰§è¡Œæ¨¡å¼ä¸‹ï¼Œå¤šä¸ªåˆ†æå¸ˆä¼šåŒæ—¶è°ƒç”¨æ­¤å‡½æ•°ã€‚
        ä¸ºäº†é¿å…é‡å¤åˆ é™¤å¯¼è‡´çš„é”™è¯¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ ‡è®°æœºåˆ¶ç¡®ä¿åªæ‰§è¡Œä¸€æ¬¡æ¸…ç†ã€‚
        """
        from langgraph.graph import END

        messages = state.get("messages", [])

        # æ£€æŸ¥æ˜¯å¦å·²ç»æ¸…ç†è¿‡ï¼ˆé€šè¿‡æ£€æŸ¥æœ€åä¸€ä¸ªæ¶ˆæ¯æ˜¯å¦æ˜¯å ä½ç¬¦ï¼‰
        if messages and len(messages) > 0:
            last_msg = messages[-1]
            if hasattr(last_msg, "content") and last_msg.content == "__MSG_CLEARED__":
                # å·²ç»æ¸…ç†è¿‡äº†ï¼Œç›´æ¥è¿”å›ç©ºæ›´æ–°
                return {"messages": []}

        # æ”¶é›†éœ€è¦åˆ é™¤çš„æ¶ˆæ¯ID
        removal_operations = []
        seen_ids = set()

        for m in messages:
            if hasattr(m, "id") and m.id and m.id not in seen_ids:
                removal_operations.append(RemoveMessage(id=m.id))
                seen_ids.add(m.id)

        # æ·»åŠ æ ‡è®°æ¶ˆæ¯è¡¨ç¤ºå·²æ¸…ç†ï¼ˆè€Œä¸æ˜¯ HumanMessageï¼‰
        # ä½¿ç”¨ AIMessage ä½œä¸ºæ ‡è®°ï¼Œé¿å…å¹²æ‰°åç»­æµç¨‹
        marker_message = AIMessage(content="__MSG_CLEARED__", id="msg_cleared_marker")

        return {"messages": removal_operations + [marker_message]}

    return delete_messages


class Toolkit:
    _config = DEFAULT_CONFIG.copy()

    @classmethod
    def update_config(cls, config):
        """Update the class-level configuration."""
        cls._config.update(config)

    @property
    def config(self):
        """Access the configuration."""
        return self._config

    def __init__(self, config=None):
        if config:
            self.update_config(config)

    @staticmethod
    def get_reddit_news(
        curr_date: Annotated[str, "Date you want to get news for in yyyy-mm-dd format"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å– Reddit å…¨çƒæ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        Retrieve global news from Reddit within a specified time frame.
        Args:
            curr_date (str): Date you want to get news for in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the latest global news from Reddit in the specified time frame.
        """

        global_news_result = interface.get_reddit_global_news(curr_date, 7, 5)

        return global_news_result

    @staticmethod
    def get_finnhub_news(
        ticker: Annotated[
            str,
            "Search query of a company, e.g. 'AAPL, TSM, etc.",
        ],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ):
        """
        [å†…éƒ¨API] è·å– Finnhub è‚¡ç¥¨æ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        Retrieve the latest news about a given stock from Finnhub within a date range
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing news about the company within the date range from start_date to end_date
        """

        end_date_str = end_date

        end_date = datetime.strptime(end_date, "%Y-%m-%d")
        start_date = datetime.strptime(start_date, "%Y-%m-%d")
        look_back_days = (end_date - start_date).days

        finnhub_news_result = interface.get_finnhub_news(
            ticker, end_date_str, look_back_days
        )

        return finnhub_news_result

    @staticmethod
    def get_reddit_stock_info(
        ticker: Annotated[
            str,
            "Ticker of a company. e.g. AAPL, TSM",
        ],
        curr_date: Annotated[str, "Current date you want to get news for"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å– Reddit è‚¡ç¥¨ä¿¡æ¯ï¼ˆè¯·ä½¿ç”¨ get_stock_sentiment_unifiedï¼‰
        Retrieve the latest news about a given stock from Reddit, given the current date.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): current date in yyyy-mm-dd format to get news for
        Returns:
            str: A formatted dataframe containing the latest news about the company on the given date
        """

        stock_news_results = interface.get_reddit_company_news(ticker, curr_date, 7, 5)

        return stock_news_results

    @staticmethod
    def get_chinese_social_sentiment(
        ticker: Annotated[str, "Ticker of a company. e.g. AAPL, TSM"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å–ä¸­å›½ç¤¾äº¤åª’ä½“æƒ…ç»ªï¼ˆè¯·ä½¿ç”¨ get_stock_sentiment_unifiedï¼‰
        è·å–ä¸­å›½ç¤¾äº¤åª’ä½“å’Œè´¢ç»å¹³å°ä¸Šå…³äºç‰¹å®šè‚¡ç¥¨çš„æƒ…ç»ªåˆ†æå’Œè®¨è®ºçƒ­åº¦ã€‚
        æ•´åˆé›ªçƒã€ä¸œæ–¹è´¢å¯Œè‚¡å§ã€æ–°æµªè´¢ç»ç­‰ä¸­å›½æœ¬åœŸå¹³å°çš„æ•°æ®ã€‚
        Args:
            ticker (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚ AAPL, TSM
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º yyyy-mm-dd
        Returns:
            str: åŒ…å«ä¸­å›½æŠ•èµ„è€…æƒ…ç»ªåˆ†æã€è®¨è®ºçƒ­åº¦ã€å…³é”®è§‚ç‚¹çš„æ ¼å¼åŒ–æŠ¥å‘Š
        """
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆå¤šä¸ªä¸­å›½å¹³å°çš„æ•°æ®
            chinese_sentiment_results = interface.get_chinese_social_sentiment(
                ticker, curr_date
            )
            return chinese_sentiment_results
        except Exception as e:
            # å¦‚æœä¸­å›½å¹³å°æ•°æ®è·å–å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰çš„Redditæ•°æ®
            return interface.get_reddit_company_news(ticker, curr_date, 7, 5)

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified æˆ– get_stock_market_data_unified
    def get_china_stock_data(
        stock_code: Annotated[
            str, "ä¸­å›½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 000001(å¹³å®‰é“¶è¡Œ), 600519(è´µå·èŒ…å°)"
        ],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
    ) -> str:
        """
        è·å–ä¸­å›½Aè‚¡å®æ—¶å’Œå†å²æ•°æ®ï¼Œé€šè¿‡Tushareç­‰é«˜è´¨é‡æ•°æ®æºæä¾›ä¸“ä¸šçš„è‚¡ç¥¨æ•°æ®ã€‚
        æ”¯æŒå®æ—¶è¡Œæƒ…ã€å†å²Kçº¿ã€æŠ€æœ¯æŒ‡æ ‡ç­‰å…¨é¢æ•°æ®ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€ä½³æ•°æ®æºã€‚
        Args:
            stock_code (str): ä¸­å›½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 000001(å¹³å®‰é“¶è¡Œ), 600519(è´µå·èŒ…å°)
            start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
            end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
        Returns:
            str: åŒ…å«å®æ—¶è¡Œæƒ…ã€å†å²æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡çš„å®Œæ•´è‚¡ç¥¨åˆ†ææŠ¥å‘Š
        """
        try:
            logger.debug(
                f"ğŸ“Š [DEBUG] ===== agent_utils.get_china_stock_data å¼€å§‹è°ƒç”¨ ====="
            )
            logger.debug(
                f"ğŸ“Š [DEBUG] å‚æ•°: stock_code={stock_code}, start_date={start_date}, end_date={end_date}"
            )

            from tradingagents.dataflows.interface import get_china_stock_data_unified

            logger.debug(f"ğŸ“Š [DEBUG] æˆåŠŸå¯¼å…¥ç»Ÿä¸€æ•°æ®æºæ¥å£")

            logger.debug(f"ğŸ“Š [DEBUG] æ­£åœ¨è°ƒç”¨ç»Ÿä¸€æ•°æ®æºæ¥å£...")
            result = get_china_stock_data_unified(stock_code, start_date, end_date)

            logger.debug(f"ğŸ“Š [DEBUG] ç»Ÿä¸€æ•°æ®æºæ¥å£è°ƒç”¨å®Œæˆ")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœç±»å‹: {type(result)}")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœé•¿åº¦: {len(result) if result else 0}")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœå‰200å­—ç¬¦: {str(result)[:200]}...")
            logger.debug(
                f"ğŸ“Š [DEBUG] ===== agent_utils.get_china_stock_data è°ƒç”¨ç»“æŸ ====="
            )

            return result
        except Exception as e:
            import traceback

            error_details = traceback.format_exc()
            logger.error(
                f"âŒ [DEBUG] ===== agent_utils.get_china_stock_data å¼‚å¸¸ ====="
            )
            logger.error(f"âŒ [DEBUG] é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"âŒ [DEBUG] é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] è¯¦ç»†å †æ ˆ:")
            print(error_details)
            logger.error(f"âŒ [DEBUG] ===== å¼‚å¸¸å¤„ç†ç»“æŸ =====")
            return f"ä¸­å›½è‚¡ç¥¨æ•°æ®è·å–å¤±è´¥: {str(e)}ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚"

    @staticmethod
    def get_china_market_overview(
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å–ä¸­å›½è‚¡å¸‚æ¦‚è§ˆï¼ˆè¯·ä½¿ç”¨ get_stock_market_data_unifiedï¼‰
        è·å–ä¸­å›½è‚¡å¸‚æ•´ä½“æ¦‚è§ˆï¼ŒåŒ…æ‹¬ä¸»è¦æŒ‡æ•°çš„å®æ—¶è¡Œæƒ…ã€‚
        æ¶µç›–ä¸Šè¯æŒ‡æ•°ã€æ·±è¯æˆæŒ‡ã€åˆ›ä¸šæ¿æŒ‡ã€ç§‘åˆ›50ç­‰ä¸»è¦æŒ‡æ•°ã€‚
        Args:
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
        Returns:
            str: åŒ…å«ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…çš„å¸‚åœºæ¦‚è§ˆæŠ¥å‘Š
        """
        try:
            # ä½¿ç”¨Tushareè·å–ä¸»è¦æŒ‡æ•°æ•°æ®
            from tradingagents.dataflows.providers.china.tushare import (
                get_tushare_adapter,
            )

            adapter = get_tushare_adapter()

            # ä½¿ç”¨Tushareè·å–ä¸»è¦æŒ‡æ•°ä¿¡æ¯
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè·å–å…·ä½“çš„æŒ‡æ•°æ•°æ®
            return f"""# ä¸­å›½è‚¡å¸‚æ¦‚è§ˆ - {curr_date}

## ğŸ“Š ä¸»è¦æŒ‡æ•°
- ä¸Šè¯æŒ‡æ•°: æ•°æ®è·å–ä¸­...
- æ·±è¯æˆæŒ‡: æ•°æ®è·å–ä¸­...
- åˆ›ä¸šæ¿æŒ‡: æ•°æ®è·å–ä¸­...
- ç§‘åˆ›50: æ•°æ®è·å–ä¸­...

## ğŸ’¡ è¯´æ˜
å¸‚åœºæ¦‚è§ˆåŠŸèƒ½æ­£åœ¨ä»TDXè¿ç§»åˆ°Tushareï¼Œå®Œæ•´åŠŸèƒ½å³å°†æ¨å‡ºã€‚
å½“å‰å¯ä»¥ä½¿ç”¨è‚¡ç¥¨æ•°æ®è·å–åŠŸèƒ½åˆ†æä¸ªè‚¡ã€‚

æ•°æ®æ¥æº: Tushareä¸“ä¸šæ•°æ®æº
æ›´æ–°æ—¶é—´: {curr_date}
"""

        except Exception as e:
            return f"ä¸­å›½å¸‚åœºæ¦‚è§ˆè·å–å¤±è´¥: {str(e)}ã€‚æ­£åœ¨ä»TDXè¿ç§»åˆ°Tushareæ•°æ®æºã€‚"

    @staticmethod
    def get_YFin_data(
        symbol: Annotated[str, "ticker symbol of the company"],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å– Yahoo Finance å†å²æ•°æ®ï¼ˆè¯·ä½¿ç”¨ get_stock_market_data_unifiedï¼‰
        Retrieve the stock price data for a given ticker symbol from Yahoo Finance.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the stock price data for the specified ticker symbol in the specified date range.
        """

        result_data = interface.get_YFin_data(symbol, start_date, end_date)

        return result_data

    @staticmethod
    def get_YFin_data_online(
        symbol: Annotated[str, "ticker symbol of the company"],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å– Yahoo Finance åœ¨çº¿æ•°æ®ï¼ˆè¯·ä½¿ç”¨ get_stock_market_data_unifiedï¼‰
        Retrieve the stock price data for a given ticker symbol from Yahoo Finance.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the stock price data for the specified ticker symbol in the specified date range.
        """

        result_data = interface.get_YFin_data_online(symbol, start_date, end_date)

        return result_data

    @staticmethod
    def get_stockstats_indicators_report(
        symbol: Annotated[str, "ticker symbol of the company"],
        indicator: Annotated[
            str, "technical indicator to get the analysis and report of"
        ],
        curr_date: Annotated[
            str, "The current trading date you are trading on, YYYY-mm-dd"
        ],
        look_back_days: Annotated[int, "how many days to look back"] = 30,
    ) -> str:
        """
        [å†…éƒ¨API] è·å–æŠ€æœ¯æŒ‡æ ‡æŠ¥å‘Šç¦»çº¿ï¼ˆè¯·ä½¿ç”¨ get_stock_market_data_unifiedï¼‰
        Retrieve stock stats indicators for a given ticker symbol and indicator.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            indicator (str): Technical indicator to get the analysis and report of
            curr_date (str): The current trading date you are trading on, YYYY-mm-dd
            look_back_days (int): How many days to look back, default is 30
        Returns:
            str: A formatted dataframe containing the stock stats indicators for the specified ticker symbol and indicator.
        """

        result_stockstats = interface.get_stock_stats_indicators_window(
            symbol, indicator, curr_date, look_back_days, False
        )

        return result_stockstats

    @staticmethod
    def get_stockstats_indicators_report_online(
        symbol: Annotated[str, "ticker symbol of the company"],
        indicator: Annotated[
            str, "technical indicator to get the analysis and report of"
        ],
        curr_date: Annotated[
            str, "The current trading date you are trading on, YYYY-mm-dd"
        ],
        look_back_days: Annotated[int, "how many days to look back"] = 30,
    ) -> str:
        """
        [å†…éƒ¨API] è·å–æŠ€æœ¯æŒ‡æ ‡æŠ¥å‘Šåœ¨çº¿ï¼ˆè¯·ä½¿ç”¨ get_stock_market_data_unifiedï¼‰
        Retrieve stock stats indicators for a given ticker symbol and indicator.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            indicator (str): Technical indicator to get the analysis and report of
            curr_date (str): The current trading date you are trading on, YYYY-mm-dd
            look_back_days (int): How many days to look back, default is 30
        Returns:
            str: A formatted dataframe containing the stock stats indicators for the specified ticker symbol and indicator.
        """

        result_stockstats = interface.get_stock_stats_indicators_window(
            symbol, indicator, curr_date, look_back_days, True
        )

        return result_stockstats

    @staticmethod
    def get_finnhub_company_insider_sentiment(
        ticker: Annotated[str, "ticker symbol for the company"],
        curr_date: Annotated[
            str,
            "current date of you are trading at, yyyy-mm-dd",
        ],
    ):
        """
        [å†…éƒ¨API] è·å–å†…éƒ¨äººå£«æƒ…ç»ªï¼ˆè¯·ä½¿ç”¨ get_stock_fundamentals_unifiedï¼‰
        Retrieve insider sentiment information about a company (retrieved from public SEC information) for the past 30 days
        Args:
            ticker (str): ticker symbol of the company
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the sentiment in the past 30 days starting at curr_date
        """

        data_sentiment = interface.get_finnhub_company_insider_sentiment(
            ticker, curr_date, 30
        )

        return data_sentiment

    @staticmethod
    def get_finnhub_company_insider_transactions(
        ticker: Annotated[str, "ticker symbol"],
        curr_date: Annotated[
            str,
            "current date you are trading at, yyyy-mm-dd",
        ],
    ):
        """
        [å†…éƒ¨API] è·å–å†…éƒ¨äººå£«äº¤æ˜“ï¼ˆè¯·ä½¿ç”¨ get_stock_fundamentals_unifiedï¼‰
        Retrieve insider transaction information about a company (retrieved from public SEC information) for the past 30 days
        Args:
            ticker (str): ticker symbol of the company
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the company's insider transactions/trading information in the past 30 days
        """

        data_trans = interface.get_finnhub_company_insider_transactions(
            ticker, curr_date, 30
        )

        return data_trans

    @staticmethod
    def get_simfin_balance_sheet(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        [å†…éƒ¨API] è·å–èµ„äº§è´Ÿå€ºè¡¨ï¼ˆè¯·ä½¿ç”¨ get_stock_fundamentals_unifiedï¼‰
        Retrieve the most recent balance sheet of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the company's most recent balance sheet
        """

        data_balance_sheet = interface.get_simfin_balance_sheet(ticker, freq, curr_date)

        return data_balance_sheet

    @staticmethod
    def get_simfin_cashflow(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        [å†…éƒ¨API] è·å–ç°é‡‘æµé‡è¡¨ï¼ˆè¯·ä½¿ç”¨ get_stock_fundamentals_unifiedï¼‰
        Retrieve the most recent cash flow statement of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
                str: a report of the company's most recent cash flow statement
        """

        data_cashflow = interface.get_simfin_cashflow(ticker, freq, curr_date)

        return data_cashflow

    @staticmethod
    def get_simfin_income_stmt(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        [å†…éƒ¨API] è·å–æŸç›Šè¡¨ï¼ˆè¯·ä½¿ç”¨ get_stock_fundamentals_unifiedï¼‰
        Retrieve the most recent income statement of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
                str: a report of the company's most recent income statement
        """

        data_income_stmt = interface.get_simfin_income_statements(
            ticker, freq, curr_date
        )

        return data_income_stmt

    @staticmethod
    def get_google_news(
        query: Annotated[str, "Query to search with"],
        curr_date: Annotated[str, "Curr date in yyyy-mm-dd format"],
    ):
        """
        [å†…éƒ¨API] è·å– Google æ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        Retrieve the latest news from Google News based on a query and date range.
        Args:
            query (str): Query to search with
            curr_date (str): Current date in yyyy-mm-dd format
            look_back_days (int): How many days to look back
        Returns:
            str: A formatted string containing the latest news from Google News based on the query and date range.
        """

        google_news_results = interface.get_google_news(query, curr_date, 7)

        return google_news_results

    @staticmethod
    def get_realtime_stock_news(
        ticker: Annotated[str, "Ticker of a company. e.g. AAPL, TSM"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ) -> str:
        """
        [å†…éƒ¨API] è·å–å®æ—¶è‚¡ç¥¨æ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        è·å–è‚¡ç¥¨çš„å®æ—¶æ–°é—»åˆ†æï¼Œè§£å†³ä¼ ç»Ÿæ–°é—»æºçš„æ»åæ€§é—®é¢˜ã€‚
        æ•´åˆå¤šä¸ªä¸“ä¸šè´¢ç»APIï¼Œæä¾›15-30åˆ†é’Ÿå†…çš„æœ€æ–°æ–°é—»ã€‚
        æ”¯æŒå¤šç§æ–°é—»æºè½®è¯¢æœºåˆ¶ï¼Œä¼˜å…ˆä½¿ç”¨å®æ—¶æ–°é—»èšåˆå™¨ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å°è¯•å¤‡ç”¨æ–°é—»æºã€‚
        å¯¹äºAè‚¡å’Œæ¸¯è‚¡ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ä¸­æ–‡è´¢ç»æ–°é—»æºï¼ˆå¦‚ä¸œæ–¹è´¢å¯Œï¼‰ã€‚

        Args:
            ticker (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚ AAPL, TSM, 600036.SH
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º yyyy-mm-dd
        Returns:
            str: åŒ…å«å®æ—¶æ–°é—»åˆ†æã€ç´§æ€¥ç¨‹åº¦è¯„ä¼°ã€æ—¶æ•ˆæ€§è¯´æ˜çš„æ ¼å¼åŒ–æŠ¥å‘Š
        """
        from tradingagents.dataflows.realtime_news_utils import get_realtime_stock_news

        return get_realtime_stock_news(ticker, curr_date, hours_back=6)

    @staticmethod
    def get_stock_news_openai(
        ticker: Annotated[str, "the company's ticker"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        [å†…éƒ¨API] è·å– OpenAI è‚¡ç¥¨æ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        Retrieve the latest news about a given stock by using OpenAI's news API.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest news about the company on the given date.
        """

        openai_news_results = interface.get_stock_news_openai(ticker, curr_date)

        return openai_news_results

    @staticmethod
    def get_global_news_openai(
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        [å†…éƒ¨API] è·å– OpenAI å…¨çƒå®è§‚ç»æµæ–°é—»ï¼ˆè¯·ä½¿ç”¨ get_stock_news_unifiedï¼‰
        Retrieve the latest macroeconomics news on a given date using OpenAI's macroeconomics news API.
        Args:
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest macroeconomic news on the given date.
        """

        openai_news_results = interface.get_global_news_openai(curr_date)

        return openai_news_results

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified
    def get_fundamentals_openai(
        ticker: Annotated[str, "the company's ticker"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest fundamental information about a given stock on a given date by using OpenAI's news API.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest fundamental information about the company on the given date.
        """
        logger.debug(
            f"ğŸ“Š [DEBUG] get_fundamentals_openai è¢«è°ƒç”¨: ticker={ticker}, date={curr_date}"
        )

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­å›½è‚¡ç¥¨
        import re

        if re.match(r"^\d{6}$", str(ticker)):
            logger.debug(f"ğŸ“Š [DEBUG] æ£€æµ‹åˆ°ä¸­å›½Aè‚¡ä»£ç : {ticker}")
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–ä¸­å›½è‚¡ç¥¨åç§°
            try:
                from tradingagents.dataflows.interface import (
                    get_china_stock_info_unified,
                )

                stock_info = get_china_stock_info_unified(ticker)

                # è§£æè‚¡ç¥¨åç§°
                if "è‚¡ç¥¨åç§°:" in stock_info:
                    company_name = (
                        stock_info.split("è‚¡ç¥¨åç§°:")[1].split("\n")[0].strip()
                    )
                else:
                    company_name = f"è‚¡ç¥¨ä»£ç {ticker}"

                logger.debug(f"ğŸ“Š [DEBUG] ä¸­å›½è‚¡ç¥¨åç§°æ˜ å°„: {ticker} -> {company_name}")
            except Exception as e:
                logger.error(f"âš ï¸ [DEBUG] ä»ç»Ÿä¸€æ¥å£è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
                company_name = f"è‚¡ç¥¨ä»£ç {ticker}"

            # ä¿®æ”¹æŸ¥è¯¢ä»¥åŒ…å«æ­£ç¡®çš„å…¬å¸åç§°
            modified_query = f"{company_name}({ticker})"
            logger.debug(f"ğŸ“Š [DEBUG] ä¿®æ”¹åçš„æŸ¥è¯¢: {modified_query}")
        else:
            logger.debug(f"ğŸ“Š [DEBUG] æ£€æµ‹åˆ°éä¸­å›½è‚¡ç¥¨: {ticker}")
            modified_query = ticker

        try:
            openai_fundamentals_results = interface.get_fundamentals_openai(
                modified_query, curr_date
            )
            logger.debug(
                f"ğŸ“Š [DEBUG] OpenAIåŸºæœ¬é¢åˆ†æç»“æœé•¿åº¦: {len(openai_fundamentals_results) if openai_fundamentals_results else 0}"
            )
            return openai_fundamentals_results
        except Exception as e:
            logger.error(f"âŒ [DEBUG] OpenAIåŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}")
            return f"åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified
    def get_china_fundamentals(
        ticker: Annotated[str, "ä¸­å›½Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚600036"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd"],
    ):
        """
        è·å–ä¸­å›½Aè‚¡è‚¡ç¥¨çš„åŸºæœ¬é¢ä¿¡æ¯ï¼Œä½¿ç”¨ä¸­å›½è‚¡ç¥¨æ•°æ®æºã€‚
        Args:
            ticker (str): ä¸­å›½Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚600036, 000001
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd
        Returns:
            str: åŒ…å«è‚¡ç¥¨åŸºæœ¬é¢ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        """
        logger.debug(
            f"ğŸ“Š [DEBUG] get_china_fundamentals è¢«è°ƒç”¨: ticker={ticker}, date={curr_date}"
        )

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­å›½è‚¡ç¥¨
        import re

        if not re.match(r"^\d{6}$", str(ticker)):
            return f"é”™è¯¯ï¼š{ticker} ä¸æ˜¯æœ‰æ•ˆçš„ä¸­å›½Aè‚¡ä»£ç æ ¼å¼"

        try:
            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®æºæ¥å£è·å–è‚¡ç¥¨æ•°æ®ï¼ˆé»˜è®¤Tushareï¼Œæ”¯æŒå¤‡ç”¨æ•°æ®æºï¼‰
            from tradingagents.dataflows.interface import get_china_stock_data_unified

            logger.debug(f"ğŸ“Š [DEBUG] æ­£åœ¨è·å– {ticker} çš„è‚¡ç¥¨æ•°æ®...")

            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®ç”¨äºåŸºæœ¬é¢åˆ†æ
            from datetime import datetime, timedelta

            end_date = datetime.strptime(curr_date, "%Y-%m-%d")
            start_date = end_date - timedelta(days=30)

            stock_data = get_china_stock_data_unified(
                ticker, start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
            )

            logger.debug(
                f"ğŸ“Š [DEBUG] è‚¡ç¥¨æ•°æ®è·å–å®Œæˆï¼Œé•¿åº¦: {len(stock_data) if stock_data else 0}"
            )

            if not stock_data or "è·å–å¤±è´¥" in stock_data or "âŒ" in stock_data:
                return f"æ— æ³•è·å–è‚¡ç¥¨ {ticker} çš„åŸºæœ¬é¢æ•°æ®ï¼š{stock_data}"

            # è°ƒç”¨çœŸæ­£çš„åŸºæœ¬é¢åˆ†æ
            from tradingagents.dataflows.optimized_china_data import (
                OptimizedChinaDataProvider,
            )

            # åˆ›å»ºåˆ†æå™¨å®ä¾‹
            analyzer = OptimizedChinaDataProvider()

            # ç”ŸæˆçœŸæ­£çš„åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
            fundamentals_report = analyzer._generate_fundamentals_report(
                ticker, stock_data
            )

            logger.debug(f"ğŸ“Š [DEBUG] ä¸­å›½åŸºæœ¬é¢åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            logger.debug(
                f"ğŸ“Š [DEBUG] get_china_fundamentals ç»“æœé•¿åº¦: {len(fundamentals_report)}"
            )

            return fundamentals_report

        except Exception as e:
            import traceback

            error_details = traceback.format_exc()
            logger.error(f"âŒ [DEBUG] get_china_fundamentals å¤±è´¥:")
            logger.error(f"âŒ [DEBUG] é”™è¯¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] å †æ ˆ: {error_details}")
            return f"ä¸­å›½è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified æˆ– get_stock_market_data_unified
    def get_hk_stock_data_unified(
        symbol: Annotated[str, "æ¸¯è‚¡ä»£ç ï¼Œå¦‚ï¼š0700.HKã€9988.HKç­‰"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
    ) -> str:
        """
        è·å–æ¸¯è‚¡æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œä¼˜å…ˆä½¿ç”¨AKShareæ•°æ®æºï¼Œå¤‡ç”¨Yahoo Finance

        Args:
            symbol: æ¸¯è‚¡ä»£ç  (å¦‚: 0700.HK)
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            str: æ ¼å¼åŒ–çš„æ¸¯è‚¡æ•°æ®
        """
        logger.debug(
            f"ğŸ‡­ğŸ‡° [DEBUG] get_hk_stock_data_unified è¢«è°ƒç”¨: symbol={symbol}, start_date={start_date}, end_date={end_date}"
        )

        try:
            from tradingagents.dataflows.interface import get_hk_stock_data_unified

            result = get_hk_stock_data_unified(symbol, start_date, end_date)

            logger.debug(
                f"ğŸ‡­ğŸ‡° [DEBUG] æ¸¯è‚¡æ•°æ®è·å–å®Œæˆï¼Œé•¿åº¦: {len(result) if result else 0}"
            )

            return result

        except Exception as e:
            import traceback

            error_details = traceback.format_exc()
            logger.error(f"âŒ [DEBUG] get_hk_stock_data_unified å¤±è´¥:")
            logger.error(f"âŒ [DEBUG] é”™è¯¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] å †æ ˆ: {error_details}")
            return f"æ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {str(e)}"

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_comprehensive_financials", log_args=True)
    def get_stock_comprehensive_financials(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡6ä½ä»£ç ï¼Œå¦‚ï¼š000001ã€600000ï¼‰"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
    ) -> str:
        """
        è·å–è‚¡ç¥¨å®Œæ•´æ ‡å‡†åŒ–è´¢åŠ¡æ•°æ®ï¼ˆä¾›åˆ†æå¸ˆä½¿ç”¨ï¼‰

        ä½¿ç”¨ Tushare 5120ç§¯åˆ†æƒé™ï¼Œä¸€æ¬¡æ€§è·å–æ‰€æœ‰è´¢åŠ¡æŒ‡æ ‡ï¼š
        - ä¼°å€¼æŒ‡æ ‡ï¼šPEã€PE_TTMã€PBã€PSã€è‚¡æ¯ç‡
        - ç›ˆåˆ©èƒ½åŠ›ï¼šEPSã€ROEã€ROAã€æ¯›åˆ©ç‡ã€å‡€åˆ©ç‡
        - è´¢åŠ¡æ•°æ®ï¼šè¥ä¸šæ”¶å…¥ã€å‡€åˆ©æ¶¦ã€ç»è¥ç°é‡‘æµå‡€é¢
        - åˆ†çº¢æ•°æ®ï¼šæ¯è‚¡åˆ†çº¢ã€è‚¡æ¯ç‡ã€åˆ†çº¢å†å²
        - èµ„äº§è´Ÿå€ºï¼šæ€»èµ„äº§ã€æ€»è´Ÿå€ºã€èµ„äº§è´Ÿå€ºç‡

        æ•°æ®æ¥æºï¼š
        - daily_basic: æ¯æ—¥ä¼°å€¼æŒ‡æ ‡ï¼ˆPEã€PBã€PSç­‰ï¼‰
        - income: åˆ©æ¶¦è¡¨ï¼ˆè¥æ”¶ã€å‡€åˆ©æ¶¦ï¼‰
        - cashflow: ç°é‡‘æµé‡è¡¨ï¼ˆç»è¥ç°é‡‘æµï¼‰
        - fina_indicator: è´¢åŠ¡æŒ‡æ ‡ï¼ˆEPSã€ROEç­‰ï¼‰
        - dividend: åˆ†çº¢é€è‚¡æ•°æ®

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€600000ï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: æ ‡å‡†åŒ–çš„å®Œæ•´è´¢åŠ¡æ•°æ®æŠ¥å‘Š
        """
        import asyncio
        from datetime import datetime
        import pandas as pd

        logger.info(f"ğŸ“Š [å®Œæ•´è´¢åŠ¡æ•°æ®] å¼€å§‹è·å– {ticker} çš„å®Œæ•´è´¢åŠ¡æ•°æ®")

        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not curr_date:
            curr_date = Toolkit._config.get("trade_date") or datetime.now().strftime(
                "%Y-%m-%d"
            )
            logger.info(f"ğŸ“… [å®Œæ•´è´¢åŠ¡æ•°æ®] ä½¿ç”¨åˆ†ææ—¥æœŸ: {curr_date}")

        try:
            from tradingagents.dataflows.providers.china.tushare import TushareProvider
            from tradingagents.utils.stock_utils import StockUtils

            # éªŒè¯è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            if not market_info["is_china"]:
                return f"âŒ è¯¥å·¥å…·ä»…æ”¯æŒä¸­å›½Aè‚¡ï¼Œå½“å‰è‚¡ç¥¨: {ticker} ({market_info['market_name']})"

            # åˆå§‹åŒ– TushareProvider
            provider = TushareProvider()

            # å¼‚æ­¥è·å–å®Œæ•´è´¢åŠ¡æ•°æ®
            async def fetch_all_financials():
                await provider.connect()

                # 1. è·å–å®Œæ•´è´¢åŠ¡æ•°æ®åŒ…ï¼ˆåŒ…å« incomeã€cashflowã€fina_indicatorã€dividendï¼‰
                financial_data = await provider.get_financial_data(ticker, limit=8)

                # 2. è·å–æ¯æ—¥ä¼°å€¼æŒ‡æ ‡ï¼ˆPEã€PBã€PSç­‰ï¼‰
                trade_date = curr_date.replace("-", "")
                daily_basic_df = await provider.get_daily_basic(trade_date)

                return financial_data, daily_basic_df

            # è¿è¡Œå¼‚æ­¥ä»»åŠ¡ï¼ˆå…¼å®¹å·²æœ‰äº‹ä»¶å¾ªç¯ï¼‰
            try:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­
                loop = asyncio.get_running_loop()
                # å¦‚æœåœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œå°è¯•ä½¿ç”¨ nest_asyncio
                try:
                    import nest_asyncio

                    nest_asyncio.apply()
                    financial_data, daily_basic_df = asyncio.run(fetch_all_financials())
                except ImportError:
                    logger.warning("âš ï¸ nest_asyncio æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥å…¼å®¹æ¨¡å¼")
                    # å¦‚æœ nest_asyncio æœªå®‰è£…ï¼Œç›´æ¥ä½¿ç”¨ create_task
                    future = asyncio.ensure_future(fetch_all_financials())
                    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
                    import concurrent.futures

                    executor = concurrent.futures.ThreadPoolExecutor()
                    try:
                        financial_data, daily_basic_df = executor.submit(
                            asyncio.run, fetch_all_financials()
                        ).result()
                    finally:
                        executor.shutdown(wait=False)
            except RuntimeError as e:
                if "no running event loop" in str(e).lower():
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œæ­£å¸¸ä½¿ç”¨ asyncio.run
                    financial_data, daily_basic_df = asyncio.run(fetch_all_financials())
                else:
                    raise

            if not financial_data:
                return f"âŒ æœªèƒ½è·å– {ticker} çš„è´¢åŠ¡æ•°æ®"

            # æ„å»ºæ ‡å‡†åŒ–è¾“å‡º
            report_lines = [
                f"# {ticker} å®Œæ•´è´¢åŠ¡æ•°æ®æŠ¥å‘Š",
                f"æ•°æ®æ—¥æœŸ: {curr_date}",
                "=" * 60,
                "",
                "## ğŸ“Š ä¼°å€¼æŒ‡æ ‡",
                "-" * 40,
            ]

            # ä» daily_basic è·å–ä¼°å€¼æŒ‡æ ‡
            if daily_basic_df is not None and not daily_basic_df.empty:
                # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
                ts_code = f"{ticker}.{'SH' if ticker.startswith('6') else 'SZ'}"
                stock_data = daily_basic_df[daily_basic_df["ts_code"] == ts_code]

                if not stock_data.empty:
                    row = stock_data.iloc[0]
                    report_lines.extend(
                        [
                            f"å¸‚ç›ˆç‡ (PE): {row.get('pe', 'N/A')}",
                            f"æ»šåŠ¨å¸‚ç›ˆç‡ (PE_TTM): {row.get('pe_ttm', 'N/A')}",
                            f"å¸‚å‡€ç‡ (PB): {row.get('pb', 'N/A')}",
                            f"å¸‚é”€ç‡ (PS): {row.get('ps', 'N/A')}",
                            f"æ»šåŠ¨å¸‚é”€ç‡ (PS_TTM): {row.get('ps_ttm', 'N/A')}",
                            f"è‚¡æ¯ç‡ (%): {row.get('dv_ratio', 'N/A')}",
                            f"æ€»å¸‚å€¼ (ä¸‡å…ƒ): {row.get('total_mv', 'N/A'):,.0f}"
                            if pd.notna(row.get("total_mv"))
                            else "æ€»å¸‚å€¼ (ä¸‡å…ƒ): N/A",
                            f"æµé€šå¸‚å€¼ (ä¸‡å…ƒ): {row.get('circ_mv', 'N/A'):,.0f}"
                            if pd.notna(row.get("circ_mv"))
                            else "æµé€šå¸‚å€¼ (ä¸‡å…ƒ): N/A",
                            "",
                        ]
                    )

            # ä» fina_indicator è·å–ç›ˆåˆ©æŒ‡æ ‡
            report_lines.extend(
                [
                    "## ğŸ’° ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡",
                    "-" * 40,
                ]
            )

            if "indicators" in financial_data and financial_data["indicators"]:
                latest = (
                    financial_data["indicators"][0]
                    if isinstance(financial_data["indicators"], list)
                    else financial_data["indicators"]
                )
                report_lines.extend(
                    [
                        f"æ¯è‚¡æ”¶ç›Š (EPS): {latest.get('eps', 'N/A')}",
                        f"å‡€èµ„äº§æ”¶ç›Šç‡ (ROE): {latest.get('roe', 'N/A')}%"
                        if latest.get("roe")
                        else "å‡€èµ„äº§æ”¶ç›Šç‡ (ROE): N/A",
                        f"æ€»èµ„äº§æŠ¥é…¬ç‡ (ROA): {latest.get('roa', 'N/A')}%"
                        if latest.get("roa")
                        else "æ€»èµ„äº§æŠ¥é…¬ç‡ (ROA): N/A",
                        f"é”€å”®æ¯›åˆ©ç‡: {latest.get('grossprofit_margin', 'N/A')}%"
                        if latest.get("grossprofit_margin")
                        else "é”€å”®æ¯›åˆ©ç‡: N/A",
                        f"é”€å”®å‡€åˆ©ç‡: {latest.get('netprofit_margin', 'N/A')}%"
                        if latest.get("netprofit_margin")
                        else "é”€å”®å‡€åˆ©ç‡: N/A",
                        "",
                    ]
                )

            # ä» income è·å–è¥æ”¶å’Œåˆ©æ¶¦
            report_lines.extend(
                [
                    "## ğŸ“ˆ è¥ä¸šæ”¶å…¥ä¸åˆ©æ¶¦",
                    "-" * 40,
                ]
            )

            if "income" in financial_data and financial_data["income"]:
                latest_income = (
                    financial_data["income"][0]
                    if isinstance(financial_data["income"], list)
                    else financial_data["income"]
                )
                report_lines.extend(
                    [
                        f"è¥ä¸šæ”¶å…¥: {latest_income.get('revenue', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_income.get("revenue")
                        else "è¥ä¸šæ”¶å…¥: N/A",
                        f"è¥ä¸šæ€»æ”¶å…¥: {latest_income.get('total_revenue', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_income.get("total_revenue")
                        else "è¥ä¸šæ€»æ”¶å…¥: N/A",
                        f"å‡€åˆ©æ¶¦: {latest_income.get('n_income', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_income.get("n_income")
                        else "å‡€åˆ©æ¶¦: N/A",
                        f"å½’æ¯å‡€åˆ©æ¶¦: {latest_income.get('n_income_attr_p', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_income.get("n_income_attr_p")
                        else "å½’æ¯å‡€åˆ©æ¶¦: N/A",
                        "",
                    ]
                )

            # ä» cashflow è·å–ç°é‡‘æµ
            report_lines.extend(
                [
                    "## ğŸ’¸ ç°é‡‘æµé‡",
                    "-" * 40,
                ]
            )

            if "cashflow" in financial_data and financial_data["cashflow"]:
                latest_cf = (
                    financial_data["cashflow"][0]
                    if isinstance(financial_data["cashflow"], list)
                    else financial_data["cashflow"]
                )
                report_lines.extend(
                    [
                        f"ç»è¥ç°é‡‘æµå‡€é¢: {latest_cf.get('n_cashflow_act', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_cf.get("n_cashflow_act")
                        else "ç»è¥ç°é‡‘æµå‡€é¢: N/A",
                        f"æŠ•èµ„ç°é‡‘æµå‡€é¢: {latest_cf.get('n_cashflow_inv_act', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_cf.get("n_cashflow_inv_act")
                        else "æŠ•èµ„ç°é‡‘æµå‡€é¢: N/A",
                        f"ç­¹èµ„ç°é‡‘æµå‡€é¢: {latest_cf.get('n_cashflow_fin_act', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_cf.get("n_cashflow_fin_act")
                        else "ç­¹èµ„ç°é‡‘æµå‡€é¢: N/A",
                        "",
                    ]
                )

            # ä» balancesheet è·å–èµ„äº§è´Ÿå€º
            report_lines.extend(
                [
                    "## ğŸ¦ èµ„äº§è´Ÿå€ºæƒ…å†µ",
                    "-" * 40,
                ]
            )

            if "balancesheet" in financial_data and financial_data["balancesheet"]:
                latest_bs = (
                    financial_data["balancesheet"][0]
                    if isinstance(financial_data["balancesheet"], list)
                    else financial_data["balancesheet"]
                )
                report_lines.extend(
                    [
                        f"æ€»èµ„äº§: {latest_bs.get('total_assets', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_bs.get("total_assets")
                        else "æ€»èµ„äº§: N/A",
                        f"æ€»è´Ÿå€º: {latest_bs.get('total_liab', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_bs.get("total_liab")
                        else "æ€»è´Ÿå€º: N/A",
                        f"è‚¡ä¸œæƒç›Š: {latest_bs.get('total_hldr_eqy_exc_min_int', 'N/A'):,.0f} ä¸‡å…ƒ"
                        if latest_bs.get("total_hldr_eqy_exc_min_int")
                        else "è‚¡ä¸œæƒç›Š: N/A",
                        "",
                    ]
                )

            # ä» dividend è·å–åˆ†çº¢æ•°æ®
            report_lines.extend(
                [
                    "## ğŸ’ åˆ†çº¢é€è‚¡",
                    "-" * 40,
                ]
            )

            if "dividend" in financial_data and financial_data["dividend"]:
                dividends = (
                    financial_data["dividend"]
                    if isinstance(financial_data["dividend"], list)
                    else [financial_data["dividend"]]
                )
                report_lines.append(f"æœ€è¿‘ {len(dividends)} æ¬¡åˆ†çº¢è®°å½•:")
                for i, div in enumerate(dividends[:3]):  # åªæ˜¾ç¤ºæœ€è¿‘3æ¬¡
                    report_lines.extend(
                        [
                            f"  {i + 1}. é™¤æƒé™¤æ¯æ—¥: {div.get('ex_date', 'N/A')}",
                            f"     æ¯è‚¡ç°é‡‘åˆ†çº¢: {div.get('cash_div', 'N/A')} å…ƒ"
                            if div.get("cash_div")
                            else "     æ¯è‚¡ç°é‡‘åˆ†çº¢: N/A",
                            f"     å®æ–½è¿›åº¦: {div.get('div_proc', 'N/A')}",
                        ]
                    )
                report_lines.append("")

            # æ·»åŠ æœ€æ–°è‚¡æ¯ç‡
            if "latest_dividend_yield" in financial_data:
                report_lines.extend(
                    [
                        f"æœ€æ–°è‚¡æ¯ç‡: {financial_data['latest_dividend_yield']}%",
                        f"æœ€æ–°æ¯è‚¡åˆ†çº¢: {financial_data.get('latest_cash_div', 'N/A')} å…ƒ"
                        if financial_data.get("latest_cash_div")
                        else "æœ€æ–°æ¯è‚¡åˆ†çº¢: N/A",
                        "",
                    ]
                )

            # æ·»åŠ è´¢åŠ¡æ‘˜è¦æ€»ç»“
            report_lines.extend(
                [
                    "=" * 60,
                    "## ğŸ“ è´¢åŠ¡å¥åº·åº¦æ‘˜è¦",
                    "-" * 40,
                ]
            )

            # æ ¹æ®æ•°æ®ç”Ÿæˆç®€è¦åˆ†æ
            health_indicators = []

            if "indicators" in financial_data and financial_data["indicators"]:
                latest = (
                    financial_data["indicators"][0]
                    if isinstance(financial_data["indicators"], list)
                    else financial_data["indicators"]
                )
                roe = latest.get("roe")
                if roe and roe > 15:
                    health_indicators.append(f"âœ… ROE {roe}% > 15%ï¼Œç›ˆåˆ©èƒ½åŠ›ä¼˜ç§€")
                elif roe and roe > 10:
                    health_indicators.append(f"âœ… ROE {roe}% > 10%ï¼Œç›ˆåˆ©èƒ½åŠ›è‰¯å¥½")
                elif roe:
                    health_indicators.append(f"âš ï¸ ROE {roe}% < 10%ï¼Œç›ˆåˆ©èƒ½åŠ›ä¸€èˆ¬")

                debt_ratio = latest.get("debt_to_assets")
                if debt_ratio and debt_ratio < 40:
                    health_indicators.append(
                        f"âœ… èµ„äº§è´Ÿå€ºç‡ {debt_ratio}% < 40%ï¼Œè´¢åŠ¡é£é™©è¾ƒä½"
                    )
                elif debt_ratio and debt_ratio < 60:
                    health_indicators.append(f"âš ï¸ èµ„äº§è´Ÿå€ºç‡ {debt_ratio}% é€‚ä¸­")
                elif debt_ratio:
                    health_indicators.append(
                        f"âŒ èµ„äº§è´Ÿå€ºç‡ {debt_ratio}% > 60%ï¼Œè´¢åŠ¡é£é™©è¾ƒé«˜"
                    )

            if health_indicators:
                report_lines.extend(health_indicators)
            else:
                report_lines.append("æš‚æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆè´¢åŠ¡å¥åº·åº¦åˆ†æ")

            report_lines.append("")
            report_lines.append(
                f"æ•°æ®æ¥æº: Tushare Pro | ç§¯åˆ†è¦æ±‚: 5120 | æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )

            return "\n".join(report_lines)

        except Exception as e:
            import traceback

            error_details = traceback.format_exc()
            logger.error(f"âŒ [å®Œæ•´è´¢åŠ¡æ•°æ®] è·å–å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {error_details}")
            return f"âŒ è·å– {ticker} å®Œæ•´è´¢åŠ¡æ•°æ®å¤±è´¥: {str(e)}"

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_fundamentals_unified", log_args=True)
    def get_stock_fundamentals_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æ•°æ®æº
        æ”¯æŒåŸºäºåˆ†æçº§åˆ«çš„æ•°æ®è·å–ç­–ç•¥

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: åŸºæœ¬é¢åˆ†ææ•°æ®å’ŒæŠ¥å‘Š
        """
        logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        # ğŸ”§ è·å–åˆ†æçº§åˆ«é…ç½®ï¼Œæ”¯æŒåŸºäºçº§åˆ«çš„æ•°æ®è·å–ç­–ç•¥
        research_depth = Toolkit._config.get("research_depth", "æ ‡å‡†")
        logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] å½“å‰åˆ†æçº§åˆ«: {research_depth}")

        # æ•°å­—ç­‰çº§åˆ°ä¸­æ–‡ç­‰çº§çš„æ˜ å°„
        numeric_to_chinese = {1: "å¿«é€Ÿ", 2: "åŸºç¡€", 3: "æ ‡å‡†", 4: "æ·±åº¦", 5: "å…¨é¢"}

        # æ ‡å‡†åŒ–ç ”ç©¶æ·±åº¦ï¼šæ”¯æŒæ•°å­—è¾“å…¥
        if isinstance(research_depth, (int, float)):
            research_depth = int(research_depth)
            if research_depth in numeric_to_chinese:
                chinese_depth = numeric_to_chinese[research_depth]
                logger.info(
                    f"ğŸ”¢ [ç­‰çº§è½¬æ¢] æ•°å­—ç­‰çº§ {research_depth} â†’ ä¸­æ–‡ç­‰çº§ '{chinese_depth}'"
                )
                research_depth = chinese_depth
            else:
                logger.warning(f"âš ï¸ æ— æ•ˆçš„æ•°å­—ç­‰çº§: {research_depth}ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†åˆ†æ")
                research_depth = "æ ‡å‡†"
        elif isinstance(research_depth, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—ï¼Œè½¬æ¢ä¸ºæ•´æ•°
            if research_depth.isdigit():
                numeric_level = int(research_depth)
                if numeric_level in numeric_to_chinese:
                    chinese_depth = numeric_to_chinese[numeric_level]
                    logger.info(
                        f"ğŸ”¢ [ç­‰çº§è½¬æ¢] å­—ç¬¦ä¸²æ•°å­— '{research_depth}' â†’ ä¸­æ–‡ç­‰çº§ '{chinese_depth}'"
                    )
                    research_depth = chinese_depth
                else:
                    logger.warning(
                        f"âš ï¸ æ— æ•ˆçš„å­—ç¬¦ä¸²æ•°å­—ç­‰çº§: {research_depth}ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†åˆ†æ"
                    )
                    research_depth = "æ ‡å‡†"
            # å¦‚æœå·²ç»æ˜¯ä¸­æ–‡ç­‰çº§ï¼Œç›´æ¥ä½¿ç”¨
            elif research_depth in ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†", "æ·±åº¦", "å…¨é¢"]:
                logger.info(f"ğŸ“ [ç­‰çº§ç¡®è®¤] ä½¿ç”¨ä¸­æ–‡ç­‰çº§: '{research_depth}'")
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„ç ”ç©¶æ·±åº¦: {research_depth}ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†åˆ†æ")
                research_depth = "æ ‡å‡†"
        else:
            logger.warning(
                f"âš ï¸ æ— æ•ˆçš„ç ”ç©¶æ·±åº¦ç±»å‹: {type(research_depth)}ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†åˆ†æ"
            )
            research_depth = "æ ‡å‡†"

        # æ ¹æ®åˆ†æçº§åˆ«è°ƒæ•´æ•°æ®è·å–ç­–ç•¥
        # ğŸ”§ ä¿®æ­£æ˜ å°„å…³ç³»ï¼šdata_depth åº”è¯¥ä¸ research_depth ä¿æŒä¸€è‡´
        if research_depth == "å¿«é€Ÿ":
            # å¿«é€Ÿåˆ†æï¼šè·å–åŸºç¡€æ•°æ®ï¼Œå‡å°‘æ•°æ®æºè°ƒç”¨
            data_depth = "basic"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] å¿«é€Ÿåˆ†ææ¨¡å¼ï¼šè·å–åŸºç¡€æ•°æ®")
        elif research_depth == "åŸºç¡€":
            # åŸºç¡€åˆ†æï¼šè·å–æ ‡å‡†æ•°æ®
            data_depth = "standard"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] åŸºç¡€åˆ†ææ¨¡å¼ï¼šè·å–æ ‡å‡†æ•°æ®")
        elif research_depth == "æ ‡å‡†":
            # æ ‡å‡†åˆ†æï¼šè·å–æ ‡å‡†æ•°æ®ï¼ˆä¸æ˜¯fullï¼ï¼‰
            data_depth = "standard"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] æ ‡å‡†åˆ†ææ¨¡å¼ï¼šè·å–æ ‡å‡†æ•°æ®")
        elif research_depth == "æ·±åº¦":
            # æ·±åº¦åˆ†æï¼šè·å–å®Œæ•´æ•°æ®
            data_depth = "full"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] æ·±åº¦åˆ†ææ¨¡å¼ï¼šè·å–å®Œæ•´æ•°æ®")
        elif research_depth == "å…¨é¢":
            # å…¨é¢åˆ†æï¼šè·å–æœ€å…¨é¢çš„æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰å¯ç”¨æ•°æ®æº
            data_depth = "comprehensive"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] å…¨é¢åˆ†ææ¨¡å¼ï¼šè·å–æœ€å…¨é¢æ•°æ®")
        else:
            # é»˜è®¤ä½¿ç”¨æ ‡å‡†åˆ†æ
            data_depth = "standard"
            logger.info(f"ğŸ”§ [åˆ†æçº§åˆ«] æœªçŸ¥çº§åˆ«ï¼Œä½¿ç”¨æ ‡å‡†åˆ†ææ¨¡å¼")

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(
            f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·æ¥æ”¶åˆ°çš„åŸå§‹è‚¡ç¥¨ä»£ç : '{ticker}' (ç±»å‹: {type(ticker)})"
        )
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(ticker))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(ticker))}")

        # ä¿å­˜åŸå§‹tickerç”¨äºå¯¹æ¯”
        original_ticker = ticker

        try:
            from tradingagents.utils.stock_utils import StockUtils
            from datetime import datetime, timedelta

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info["is_china"]
            is_hk = market_info["is_hk"]
            is_us = market_info["is_us"]

            logger.info(
                f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] StockUtils.get_market_info è¿”å›çš„å¸‚åœºä¿¡æ¯: {market_info}"
            )
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")
            logger.info(
                f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è´§å¸: {market_info['currency_name']} ({market_info['currency_symbol']})"
            )

            # æ£€æŸ¥tickeræ˜¯å¦åœ¨å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿäº†å˜åŒ–
            if str(ticker) != str(original_ticker):
                logger.warning(
                    f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è­¦å‘Šï¼šè‚¡ç¥¨ä»£ç å‘ç”Ÿäº†å˜åŒ–ï¼åŸå§‹: '{original_ticker}' -> å½“å‰: '{ticker}'"
                )

            # è®¾ç½®é»˜è®¤æ—¥æœŸ - ä¼˜å…ˆä½¿ç”¨ Toolkit._config ä¸­çš„ trade_date
            if not curr_date:
                # å°è¯•ä» Toolkit é…ç½®è·å–åˆ†ææ—¥æœŸ
                curr_date = Toolkit._config.get("trade_date")
                if curr_date:
                    logger.info(
                        f"ğŸ“… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] ä½¿ç”¨ Toolkit._config ä¸­çš„åˆ†ææ—¥æœŸ: {curr_date}"
                    )
                else:
                    curr_date = datetime.now().strftime("%Y-%m-%d")
                    logger.warning(
                        f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æœªæä¾›åˆ†ææ—¥æœŸï¼Œä½¿ç”¨ç³»ç»Ÿæ—¶é—´: {curr_date}"
                    )

            # åŸºæœ¬é¢åˆ†æä¼˜åŒ–ï¼šä¸éœ€è¦å¤§é‡å†å²æ•°æ®ï¼Œåªéœ€è¦å½“å‰ä»·æ ¼å’Œè´¢åŠ¡æ•°æ®
            # æ ¹æ®æ•°æ®æ·±åº¦çº§åˆ«è®¾ç½®ä¸åŒçš„åˆ†ææ¨¡å—æ•°é‡ï¼Œè€Œéå†å²æ•°æ®èŒƒå›´
            # ğŸ”§ ä¿®æ­£æ˜ å°„å…³ç³»ï¼šanalysis_modules åº”è¯¥ä¸ data_depth ä¿æŒä¸€è‡´
            if data_depth == "basic":  # å¿«é€Ÿåˆ†æï¼šåŸºç¡€æ¨¡å—
                analysis_modules = "basic"
                logger.info(f"ğŸ“Š [åŸºæœ¬é¢ç­–ç•¥] å¿«é€Ÿåˆ†ææ¨¡å¼ï¼šè·å–åŸºç¡€è´¢åŠ¡æŒ‡æ ‡")
            elif data_depth == "standard":  # åŸºç¡€/æ ‡å‡†åˆ†æï¼šæ ‡å‡†æ¨¡å—
                analysis_modules = "standard"
                logger.info(f"ğŸ“Š [åŸºæœ¬é¢ç­–ç•¥] æ ‡å‡†åˆ†ææ¨¡å¼ï¼šè·å–æ ‡å‡†è´¢åŠ¡åˆ†æ")
            elif data_depth == "full":  # æ·±åº¦åˆ†æï¼šå®Œæ•´æ¨¡å—
                analysis_modules = "full"
                logger.info(f"ğŸ“Š [åŸºæœ¬é¢ç­–ç•¥] æ·±åº¦åˆ†ææ¨¡å¼ï¼šè·å–å®Œæ•´åŸºæœ¬é¢åˆ†æ")
            elif data_depth == "comprehensive":  # å…¨é¢åˆ†æï¼šç»¼åˆæ¨¡å—
                analysis_modules = "comprehensive"
                logger.info(f"ğŸ“Š [åŸºæœ¬é¢ç­–ç•¥] å…¨é¢åˆ†ææ¨¡å¼ï¼šè·å–ç»¼åˆåŸºæœ¬é¢åˆ†æ")
            else:
                analysis_modules = "standard"  # é»˜è®¤æ ‡å‡†åˆ†æ
                logger.info(f"ğŸ“Š [åŸºæœ¬é¢ç­–ç•¥] é»˜è®¤æ¨¡å¼ï¼šè·å–æ ‡å‡†åŸºæœ¬é¢åˆ†æ")

            # åŸºæœ¬é¢åˆ†æç­–ç•¥ï¼š
            # 1. è·å–10å¤©æ•°æ®ï¼ˆä¿è¯èƒ½æ‹¿åˆ°æ•°æ®ï¼Œå¤„ç†å‘¨æœ«/èŠ‚å‡æ—¥ï¼‰
            # 2. åªä½¿ç”¨æœ€è¿‘2å¤©æ•°æ®å‚ä¸åˆ†æï¼ˆä»…éœ€å½“å‰ä»·æ ¼ï¼‰
            days_to_fetch = 10  # å›ºå®šè·å–10å¤©æ•°æ®
            days_to_analyze = 2  # åªåˆ†ææœ€è¿‘2å¤©

            logger.info(
                f"ğŸ“… [åŸºæœ¬é¢ç­–ç•¥] è·å–{days_to_fetch}å¤©æ•°æ®ï¼Œåˆ†ææœ€è¿‘{days_to_analyze}å¤©"
            )

            if not start_date:
                start_date = (datetime.now() - timedelta(days=days_to_fetch)).strftime(
                    "%Y-%m-%d"
                )

            if not end_date:
                end_date = curr_date

            result_data = []

            if is_china:
                # ä¸­å›½Aè‚¡ï¼šåŸºæœ¬é¢åˆ†æä¼˜åŒ–ç­–ç•¥ - åªè·å–å¿…è¦çš„å½“å‰ä»·æ ¼å’ŒåŸºæœ¬é¢æ•°æ®
                logger.info(
                    f"ğŸ‡¨ğŸ‡³ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†Aè‚¡æ•°æ®ï¼Œæ•°æ®æ·±åº¦: {data_depth}..."
                )
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿›å…¥Aè‚¡å¤„ç†åˆ†æ”¯ï¼Œticker: '{ticker}'")
                logger.info(
                    f"ğŸ’¡ [ä¼˜åŒ–ç­–ç•¥] åŸºæœ¬é¢åˆ†æåªè·å–å½“å‰ä»·æ ¼å’Œè´¢åŠ¡æ•°æ®ï¼Œä¸è·å–å†å²æ—¥çº¿æ•°æ®"
                )

                # ğŸ”§ FIX: ä½¿ç”¨ç»Ÿä¸€äº¤æ˜“æ—¥ç®¡ç†å™¨ï¼Œç¡®ä¿ä¸æŠ€æœ¯åˆ†æä½¿ç”¨ç›¸åŒçš„æ•°æ®æ—¥æœŸ
                from tradingagents.utils.trading_date_manager import (
                    get_trading_date_manager,
                )
                from tradingagents.utils.price_cache import get_price_cache

                date_mgr = get_trading_date_manager()
                trading_date = date_mgr.get_latest_trading_date(curr_date)

                # å¦‚æœå¯¹é½åçš„æ—¥æœŸä¸åŒï¼Œè®°å½•æ—¥å¿—
                if trading_date != curr_date:
                    logger.info(
                        f"ğŸ“… [åŸºæœ¬é¢åˆ†æ] æ—¥æœŸå¯¹é½: {curr_date} â†’ {trading_date} (æœ€æ–°äº¤æ˜“æ—¥)"
                    )

                # ä¼˜åŒ–ç­–ç•¥ï¼šåŸºæœ¬é¢åˆ†æä¸éœ€è¦å¤§é‡å†å²æ—¥çº¿æ•°æ®
                # åªè·å–å½“å‰è‚¡ä»·ä¿¡æ¯ï¼ˆæœ€è¿‘5å¤©æ•°æ®ä»¥ç¡®ä¿åŒ…å«äº¤æ˜“æ—¥ï¼‰å’ŒåŸºæœ¬é¢è´¢åŠ¡æ•°æ®
                try:
                    # è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯
                    from datetime import datetime, timedelta

                    recent_end_date = trading_date
                    recent_start_date = (
                        datetime.strptime(trading_date, "%Y-%m-%d") - timedelta(days=5)
                    ).strftime("%Y-%m-%d")

                    logger.info(
                        f"ğŸ“… [åŸºæœ¬é¢åˆ†æ] ä½¿ç”¨ç»Ÿä¸€äº¤æ˜“æ—¥: {trading_date}, æŸ¥è¯¢èŒƒå›´: {recent_start_date} è‡³ {recent_end_date}"
                    )

                    from tradingagents.dataflows.interface import (
                        get_china_stock_data_unified,
                    )

                    logger.info(
                        f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ get_china_stock_data_unifiedï¼ˆä»…è·å–æœ€æ–°ä»·æ ¼ï¼‰ï¼Œä¼ å…¥å‚æ•°: ticker='{ticker}', start_date='{recent_start_date}', end_date='{recent_end_date}'"
                    )
                    current_price_data = get_china_stock_data_unified(
                        ticker, recent_start_date, recent_end_date
                    )

                    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¿”å›æ•°æ®çš„å‰500å­—ç¬¦
                    logger.info(
                        f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡ä»·æ ¼æ•°æ®è¿”å›é•¿åº¦: {len(current_price_data)}"
                    )
                    logger.info(
                        f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡ä»·æ ¼æ•°æ®å‰500å­—ç¬¦:\n{current_price_data[:500]}"
                    )

                    result_data.append(f"## Aè‚¡å½“å‰ä»·æ ¼ä¿¡æ¯\n{current_price_data}")
                except Exception as e:
                    logger.error(f"âŒ [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡ä»·æ ¼æ•°æ®è·å–å¤±è´¥: {e}")
                    result_data.append(f"## Aè‚¡å½“å‰ä»·æ ¼ä¿¡æ¯\nè·å–å¤±è´¥: {e}")
                    current_price_data = ""

                try:
                    # è·å–åŸºæœ¬é¢è´¢åŠ¡æ•°æ®ï¼ˆè¿™æ˜¯åŸºæœ¬é¢åˆ†æçš„æ ¸å¿ƒï¼‰
                    from tradingagents.dataflows.optimized_china_data import (
                        OptimizedChinaDataProvider,
                    )

                    analyzer = OptimizedChinaDataProvider()
                    logger.info(
                        f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ OptimizedChinaDataProvider._generate_fundamentals_reportï¼Œä¼ å…¥å‚æ•°: ticker='{ticker}', analysis_modules='{analysis_modules}'"
                    )

                    # ä¼ é€’åˆ†ææ¨¡å—å‚æ•°åˆ°åŸºæœ¬é¢åˆ†ææ–¹æ³•
                    fundamentals_data = analyzer._generate_fundamentals_report(
                        ticker, current_price_data, analysis_modules
                    )

                    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¿”å›æ•°æ®çš„å‰500å­—ç¬¦
                    logger.info(
                        f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡åŸºæœ¬é¢æ•°æ®è¿”å›é•¿åº¦: {len(fundamentals_data)}"
                    )
                    logger.info(
                        f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡åŸºæœ¬é¢æ•°æ®å‰500å­—ç¬¦:\n{fundamentals_data[:500]}"
                    )

                    result_data.append(f"## Aè‚¡åŸºæœ¬é¢è´¢åŠ¡æ•°æ®\n{fundamentals_data}")
                except Exception as e:
                    logger.error(f"âŒ [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] Aè‚¡åŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {e}")
                    result_data.append(f"## Aè‚¡åŸºæœ¬é¢è´¢åŠ¡æ•°æ®\nè·å–å¤±è´¥: {e}")

            elif is_hk:
                # æ¸¯è‚¡ï¼šä½¿ç”¨AKShareæ•°æ®æºï¼Œæ”¯æŒå¤šé‡å¤‡ç”¨æ–¹æ¡ˆ
                logger.info(
                    f"ğŸ‡­ğŸ‡° [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†æ¸¯è‚¡æ•°æ®ï¼Œæ•°æ®æ·±åº¦: {data_depth}..."
                )

                hk_data_success = False

                # ğŸ”¥ ç»Ÿä¸€ç­–ç•¥ï¼šæ‰€æœ‰çº§åˆ«éƒ½è·å–å®Œæ•´æ•°æ®
                # åŸå› ï¼šæç¤ºè¯æ˜¯ç»Ÿä¸€çš„ï¼Œå¦‚æœæ•°æ®ä¸å®Œæ•´ä¼šå¯¼è‡´LLMåŸºäºä¸å­˜åœ¨çš„æ•°æ®è¿›è¡Œåˆ†æï¼ˆå¹»è§‰ï¼‰
                logger.info(
                    f"ğŸ” [æ¸¯è‚¡åŸºæœ¬é¢] ç»Ÿä¸€ç­–ç•¥ï¼šè·å–å®Œæ•´æ•°æ®ï¼ˆå¿½ç•¥ data_depth å‚æ•°ï¼‰"
                )

                # ä¸»è¦æ•°æ®æºï¼šAKShare
                try:
                    from tradingagents.dataflows.interface import (
                        get_hk_stock_data_unified,
                    )

                    hk_data = get_hk_stock_data_unified(ticker, start_date, end_date)

                    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¿”å›æ•°æ®çš„å‰500å­—ç¬¦
                    logger.info(f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®è¿”å›é•¿åº¦: {len(hk_data)}")
                    logger.info(
                        f"ğŸ” [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®å‰500å­—ç¬¦:\n{hk_data[:500]}"
                    )

                    # æ£€æŸ¥æ•°æ®è´¨é‡
                    if hk_data and len(hk_data) > 100 and "âŒ" not in hk_data:
                        result_data.append(f"## æ¸¯è‚¡æ•°æ®\n{hk_data}")
                        hk_data_success = True
                        logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä¸»è¦æ•°æ®æºæˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä¸»è¦æ•°æ®æºè´¨é‡ä¸ä½³")

                except Exception as e:
                    logger.error(f"âŒ [åŸºæœ¬é¢å·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {e}")

                # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºç¡€æ¸¯è‚¡ä¿¡æ¯
                if not hk_data_success:
                    try:
                        from tradingagents.dataflows.interface import (
                            get_hk_stock_info_unified,
                        )

                        hk_info = get_hk_stock_info_unified(ticker)

                        basic_info = f"""## æ¸¯è‚¡åŸºç¡€ä¿¡æ¯

**è‚¡ç¥¨ä»£ç **: {ticker}
**è‚¡ç¥¨åç§°**: {hk_info.get("name", f"æ¸¯è‚¡{ticker}")}
**äº¤æ˜“è´§å¸**: æ¸¯å¸ (HK$)
**äº¤æ˜“æ‰€**: é¦™æ¸¯äº¤æ˜“æ‰€ (HKG)
**æ•°æ®æº**: {hk_info.get("source", "åŸºç¡€ä¿¡æ¯")}

âš ï¸ æ³¨æ„ï¼šè¯¦ç»†çš„ä»·æ ¼å’Œè´¢åŠ¡æ•°æ®æš‚æ—¶æ— æ³•è·å–ï¼Œå»ºè®®ç¨åé‡è¯•æˆ–ä½¿ç”¨å…¶ä»–æ•°æ®æºã€‚

**åŸºæœ¬é¢åˆ†æå»ºè®®**ï¼š
- å»ºè®®æŸ¥çœ‹å…¬å¸æœ€æ–°è´¢æŠ¥
- å…³æ³¨æ¸¯è‚¡å¸‚åœºæ•´ä½“èµ°åŠ¿
- è€ƒè™‘æ±‡ç‡å› ç´ å¯¹æŠ•èµ„çš„å½±å“
"""
                        result_data.append(basic_info)
                        logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡å¤‡ç”¨ä¿¡æ¯æˆåŠŸ")

                    except Exception as e2:
                        # æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ
                        fallback_info = f"""## æ¸¯è‚¡ä¿¡æ¯ï¼ˆå¤‡ç”¨ï¼‰

**è‚¡ç¥¨ä»£ç **: {ticker}
**è‚¡ç¥¨ç±»å‹**: æ¸¯è‚¡
**äº¤æ˜“è´§å¸**: æ¸¯å¸ (HK$)
**äº¤æ˜“æ‰€**: é¦™æ¸¯äº¤æ˜“æ‰€ (HKG)

âŒ æ•°æ®è·å–é‡åˆ°é—®é¢˜: {str(e2)}

**å»ºè®®**ï¼š
- è¯·ç¨åé‡è¯•
- æˆ–ä½¿ç”¨å…¶ä»–æ•°æ®æº
- æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®
"""
                        result_data.append(fallback_info)
                        logger.error(f"âŒ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥: {e2}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨OpenAI/Finnhubæ•°æ®æº
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†ç¾è‚¡æ•°æ®...")

                # ğŸ”¥ ç»Ÿä¸€ç­–ç•¥ï¼šæ‰€æœ‰çº§åˆ«éƒ½è·å–å®Œæ•´æ•°æ®
                # åŸå› ï¼šæç¤ºè¯æ˜¯ç»Ÿä¸€çš„ï¼Œå¦‚æœæ•°æ®ä¸å®Œæ•´ä¼šå¯¼è‡´LLMåŸºäºä¸å­˜åœ¨çš„æ•°æ®è¿›è¡Œåˆ†æï¼ˆå¹»è§‰ï¼‰
                logger.info(
                    f"ğŸ” [ç¾è‚¡åŸºæœ¬é¢] ç»Ÿä¸€ç­–ç•¥ï¼šè·å–å®Œæ•´æ•°æ®ï¼ˆå¿½ç•¥ data_depth å‚æ•°ï¼‰"
                )

                try:
                    from tradingagents.dataflows.interface import (
                        get_fundamentals_openai,
                    )

                    us_data = get_fundamentals_openai(ticker, curr_date)
                    result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢æ•°æ®\n{us_data}")
                    logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] ç¾è‚¡æ•°æ®è·å–æˆåŠŸ")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢æ•°æ®\nè·å–å¤±è´¥: {e}")
                    logger.error(f"âŒ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] ç¾è‚¡æ•°æ®è·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} åŸºæœ¬é¢åˆ†ææ•°æ®

**è‚¡ç¥¨ç±»å‹**: {market_info["market_name"]}
**è´§å¸**: {market_info["currency_name"]} ({market_info["currency_symbol"]})
**åˆ†ææ—¥æœŸ**: {curr_date}
**æ•°æ®æ·±åº¦çº§åˆ«**: {data_depth}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ•°æ®æº*
"""

            # æ·»åŠ è¯¦ç»†çš„æ•°æ®è·å–æ—¥å¿—
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] ===== æ•°æ®è·å–å®Œæˆæ‘˜è¦ =====")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è‚¡ç¥¨ä»£ç : {ticker}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®æ·±åº¦çº§åˆ«: {data_depth}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è·å–çš„æ•°æ®æ¨¡å—æ•°é‡: {len(result_data)}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ€»æ•°æ®é•¿åº¦: {len(combined_result)} å­—ç¬¦")

            # è®°å½•æ¯ä¸ªæ•°æ®æ¨¡å—çš„è¯¦ç»†ä¿¡æ¯
            for i, data_section in enumerate(result_data, 1):
                section_lines = data_section.split("\n")
                section_title = section_lines[0] if section_lines else "æœªçŸ¥æ¨¡å—"
                section_length = len(data_section)
                logger.info(
                    f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®æ¨¡å— {i}: {section_title} ({section_length} å­—ç¬¦)"
                )

                # å¦‚æœæ•°æ®åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œç‰¹åˆ«æ ‡è®°
                if "è·å–å¤±è´¥" in data_section or "âŒ" in data_section:
                    logger.warning(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®æ¨¡å— {i} åŒ…å«é”™è¯¯ä¿¡æ¯")
                else:
                    logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®æ¨¡å— {i} è·å–æˆåŠŸ")

            # æ ¹æ®æ•°æ®æ·±åº¦çº§åˆ«è®°å½•å…·ä½“çš„è·å–ç­–ç•¥
            if data_depth in ["basic", "standard"]:
                logger.info(
                    f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] åŸºç¡€/æ ‡å‡†çº§åˆ«ç­–ç•¥: ä»…è·å–æ ¸å¿ƒä»·æ ¼æ•°æ®å’ŒåŸºç¡€ä¿¡æ¯"
                )
            elif data_depth in ["full", "detailed", "comprehensive"]:
                logger.info(
                    f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å®Œæ•´/è¯¦ç»†/å…¨é¢çº§åˆ«ç­–ç•¥: è·å–ä»·æ ¼æ•°æ® + åŸºæœ¬é¢æ•°æ®"
                )
            else:
                logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] é»˜è®¤ç­–ç•¥: è·å–å®Œæ•´æ•°æ®")

            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] ===== æ•°æ®è·å–æ‘˜è¦ç»“æŸ =====")

            # ğŸ” æ·»åŠ æ•°æ®éªŒè¯ä¿¡æ¯
            try:
                from tradingagents.agents.utils.data_validation_integration import (
                    add_data_validation_to_fundamentals_report,
                )

                combined_result = add_data_validation_to_fundamentals_report(
                    ticker, combined_result
                )
                logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] {ticker} æ•°æ®éªŒè¯å·²å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®éªŒè¯å¤±è´¥: {e}")

            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€åŸºæœ¬é¢åˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_market_data_unified", log_args=True)
    def get_stock_market_data_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        start_date: Annotated[
            str,
            "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DDã€‚æ³¨æ„ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ‰©å±•åˆ°é…ç½®çš„å›æº¯å¤©æ•°ï¼ˆé€šå¸¸ä¸º365å¤©ï¼‰ï¼Œä½ åªéœ€è¦ä¼ é€’åˆ†ææ—¥æœŸå³å¯",
        ],
        end_date: Annotated[
            str,
            "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DDã€‚é€šå¸¸ä¸start_dateç›¸åŒï¼Œä¼ é€’å½“å‰åˆ†ææ—¥æœŸå³å¯",
        ],
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨å¸‚åœºæ•°æ®å·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æ•°æ®æºè·å–ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®

        âš ï¸ é‡è¦ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ‰©å±•æ—¥æœŸèŒƒå›´åˆ°é…ç½®çš„å›æº¯å¤©æ•°ï¼ˆé€šå¸¸ä¸º365å¤©ï¼‰ï¼Œä»¥ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ã€‚
        ä½ åªéœ€è¦ä¼ é€’å½“å‰åˆ†ææ—¥æœŸä½œä¸º start_date å’Œ end_date å³å¯ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—å†å²æ—¥æœŸèŒƒå›´ã€‚

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ã€‚ä¼ é€’å½“å‰åˆ†ææ—¥æœŸå³å¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ‰©å±•
            end_date: ç»“æŸæ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ã€‚ä¼ é€’å½“å‰åˆ†ææ—¥æœŸå³å¯

        Returns:
            str: å¸‚åœºæ•°æ®å’ŒæŠ€æœ¯åˆ†ææŠ¥å‘Š

        ç¤ºä¾‹ï¼š
            å¦‚æœåˆ†ææ—¥æœŸæ˜¯ 2025-11-09ï¼Œä¼ é€’ï¼š
            - ticker: "00700.HK"
            - start_date: "2025-11-09"
            - end_date: "2025-11-09"
            ç³»ç»Ÿä¼šè‡ªåŠ¨è·å– 2024-11-09 åˆ° 2025-11-09 çš„365å¤©å†å²æ•°æ®
        """
        logger.info(f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from tradingagents.utils.stock_utils import StockUtils

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info["is_china"]
            is_hk = market_info["is_hk"]
            is_us = market_info["is_us"]

            logger.info(f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")
            logger.info(
                f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] è´§å¸: {market_info['currency_name']} ({market_info['currency_symbol']}"
            )

            result_data = []

            if is_china:
                # ä¸­å›½Aè‚¡ï¼šä½¿ç”¨ä¸­å›½è‚¡ç¥¨æ•°æ®æº
                logger.info(f"ğŸ‡¨ğŸ‡³ [ç»Ÿä¸€å¸‚åœºå·¥å…·] å¤„ç†Aè‚¡å¸‚åœºæ•°æ®...")

                # ğŸ”§ FIX: ä½¿ç”¨ç»Ÿä¸€äº¤æ˜“æ—¥ç®¡ç†å™¨ï¼Œç¡®ä¿ä¸åŸºæœ¬é¢åˆ†æä½¿ç”¨ç›¸åŒçš„æ•°æ®æ—¥æœŸ
                from tradingagents.utils.trading_date_manager import (
                    get_trading_date_manager,
                )

                date_mgr = get_trading_date_manager()
                aligned_end_date = date_mgr.get_latest_trading_date(end_date)

                # å¦‚æœå¯¹é½åçš„æ—¥æœŸä¸åŒï¼Œè®°å½•æ—¥å¿—
                if aligned_end_date != end_date:
                    logger.info(
                        f"ğŸ“… [æŠ€æœ¯åˆ†æ] æ—¥æœŸå¯¹é½: {end_date} â†’ {aligned_end_date} (æœ€æ–°äº¤æ˜“æ—¥)"
                    )

                try:
                    from tradingagents.dataflows.interface import (
                        get_china_stock_data_unified,
                    )

                    stock_data = get_china_stock_data_unified(
                        ticker, start_date, aligned_end_date
                    )

                    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¿”å›æ•°æ®çš„å‰500å­—ç¬¦
                    logger.info(f"ğŸ” [å¸‚åœºå·¥å…·è°ƒè¯•] Aè‚¡æ•°æ®è¿”å›é•¿åº¦: {len(stock_data)}")
                    logger.info(
                        f"ğŸ” [å¸‚åœºå·¥å…·è°ƒè¯•] Aè‚¡æ•°æ®å‰500å­—ç¬¦:\n{stock_data[:500]}"
                    )

                    result_data.append(f"## Aè‚¡å¸‚åœºæ•°æ®\n{stock_data}")
                except Exception as e:
                    logger.error(f"âŒ [å¸‚åœºå·¥å…·è°ƒè¯•] Aè‚¡æ•°æ®è·å–å¤±è´¥: {e}")
                    result_data.append(f"## Aè‚¡å¸‚åœºæ•°æ®\nè·å–å¤±è´¥: {e}")

            elif is_hk:
                # æ¸¯è‚¡ï¼šä½¿ç”¨AKShareæ•°æ®æº
                logger.info(f"ğŸ‡­ğŸ‡° [ç»Ÿä¸€å¸‚åœºå·¥å…·] å¤„ç†æ¸¯è‚¡å¸‚åœºæ•°æ®...")

                try:
                    from tradingagents.dataflows.interface import (
                        get_hk_stock_data_unified,
                    )

                    hk_data = get_hk_stock_data_unified(ticker, start_date, end_date)

                    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¿”å›æ•°æ®çš„å‰500å­—ç¬¦
                    logger.info(f"ğŸ” [å¸‚åœºå·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®è¿”å›é•¿åº¦: {len(hk_data)}")
                    logger.info(
                        f"ğŸ” [å¸‚åœºå·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®å‰500å­—ç¬¦:\n{hk_data[:500]}"
                    )

                    result_data.append(f"## æ¸¯è‚¡å¸‚åœºæ•°æ®\n{hk_data}")
                except Exception as e:
                    logger.error(f"âŒ [å¸‚åœºå·¥å…·è°ƒè¯•] æ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {e}")
                    result_data.append(f"## æ¸¯è‚¡å¸‚åœºæ•°æ®\nè·å–å¤±è´¥: {e}")

            else:
                # ç¾è‚¡ï¼šä¼˜å…ˆä½¿ç”¨FINNHUB APIæ•°æ®æº
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€å¸‚åœºå·¥å…·] å¤„ç†ç¾è‚¡å¸‚åœºæ•°æ®...")

                try:
                    from tradingagents.dataflows.providers.us.optimized import (
                        get_us_stock_data_cached,
                    )

                    us_data = get_us_stock_data_cached(ticker, start_date, end_date)
                    result_data.append(f"## ç¾è‚¡å¸‚åœºæ•°æ®\n{us_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡å¸‚åœºæ•°æ®\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} å¸‚åœºæ•°æ®åˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info["market_name"]}
**è´§å¸**: {market_info["currency_name"]} ({market_info["currency_symbol"]})
**åˆ†ææœŸé—´**: {start_date} è‡³ {end_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ•°æ®æº*
"""

            # ğŸ” æ·»åŠ æ•°æ®éªŒè¯ä¿¡æ¯
            try:
                from tradingagents.agents.utils.data_validation_integration import (
                    add_data_validation_to_market_report,
                )

                combined_result = add_data_validation_to_market_report(
                    ticker, combined_result
                )
                logger.info(f"âœ… [ç»Ÿä¸€å¸‚åœºå·¥å…·] {ticker} æ•°æ®éªŒè¯å·²å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ [ç»Ÿä¸€å¸‚åœºå·¥å…·] æ•°æ®éªŒè¯å¤±è´¥: {e}")

            logger.info(
                f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}"
            )
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€å¸‚åœºæ•°æ®å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€å¸‚åœºå·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_news_unified", log_args=True)
    def get_stock_news_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨æ–°é—»å·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æ–°é—»æ•°æ®æº

        æ•°æ®æºç­–ç•¥:
        - Aè‚¡/æ¸¯è‚¡: ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ–°é—»ï¼ˆAKShareï¼‰
        - ç¾è‚¡: ä½¿ç”¨ Finnhub æ–°é—»
        - æ³¨: å·²ç§»é™¤ Google æ–°é—»ï¼ˆå›½å†…è®¿é—®ä¸ç¨³å®šï¼‰

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: æ–°é—»åˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from tradingagents.utils.stock_utils import StockUtils
            from datetime import datetime, timedelta

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info["is_china"]
            is_hk = market_info["is_hk"]
            is_us = market_info["is_us"]

            logger.info(f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

            # è®¡ç®—æ–°é—»æŸ¥è¯¢çš„æ—¥æœŸèŒƒå›´
            end_date = datetime.strptime(curr_date, "%Y-%m-%d")
            start_date = end_date - timedelta(days=7)
            start_date_str = start_date.strftime("%Y-%m-%d")

            result_data = []

            if is_china or is_hk:
                # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨AKShareä¸œæ–¹è´¢å¯Œæ–°é—»å’ŒGoogleæ–°é—»ï¼ˆä¸­æ–‡æœç´¢ï¼‰
                logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] å¤„ç†ä¸­æ–‡æ–°é—»...")

                # 1. å°è¯•è·å–AKShareä¸œæ–¹è´¢å¯Œæ–°é—»
                try:
                    # å¤„ç†è‚¡ç¥¨ä»£ç 
                    clean_ticker = (
                        ticker.replace(".SH", "")
                        .replace(".SZ", "")
                        .replace(".SS", "")
                        .replace(".HK", "")
                        .replace(".XSHE", "")
                        .replace(".XSHG", "")
                    )

                    logger.info(
                        f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»: {clean_ticker}"
                    )

                    # é€šè¿‡ AKShare Provider è·å–æ–°é—»
                    from tradingagents.dataflows.providers.china.akshare import (
                        AKShareProvider,
                    )

                    provider = AKShareProvider()

                    # è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»
                    news_df = provider.get_stock_news_sync(symbol=clean_ticker)

                    if news_df is not None and not news_df.empty:
                        # æ ¼å¼åŒ–ä¸œæ–¹è´¢å¯Œæ–°é—»
                        em_news_items = []
                        for _, row in news_df.iterrows():
                            # AKShare è¿”å›çš„å­—æ®µå
                            news_title = row.get("æ–°é—»æ ‡é¢˜", "") or row.get("æ ‡é¢˜", "")
                            news_time = row.get("å‘å¸ƒæ—¶é—´", "") or row.get("æ—¶é—´", "")
                            news_url = row.get("æ–°é—»é“¾æ¥", "") or row.get("é“¾æ¥", "")

                            news_item = f"- **{news_title}** [{news_time}]({news_url})"
                            em_news_items.append(news_item)

                        # æ·»åŠ åˆ°ç»“æœä¸­
                        if em_news_items:
                            em_news_text = "\n".join(em_news_items)
                            result_data.append(f"## ä¸œæ–¹è´¢å¯Œæ–°é—»\n{em_news_text}")
                            logger.info(
                                f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] æˆåŠŸè·å–{len(em_news_items)}æ¡ä¸œæ–¹è´¢å¯Œæ–°é—»"
                            )
                except Exception as em_e:
                    logger.error(f"âŒ [ç»Ÿä¸€æ–°é—»å·¥å…·] ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–å¤±è´¥: {em_e}")
                    result_data.append(f"## ä¸œæ–¹è´¢å¯Œæ–°é—»\nè·å–å¤±è´¥: {em_e}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨Finnhubæ–°é—»
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€æ–°é—»å·¥å…·] å¤„ç†ç¾è‚¡æ–°é—»...")

                try:
                    from tradingagents.dataflows.interface import get_finnhub_news

                    news_data = get_finnhub_news(ticker, start_date_str, curr_date)
                    result_data.append(f"## ç¾è‚¡æ–°é—»\n{news_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡æ–°é—»\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} æ–°é—»åˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info["market_name"]}
**åˆ†ææ—¥æœŸ**: {curr_date}
**æ–°é—»æ—¶é—´èŒƒå›´**: {start_date_str} è‡³ {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ–°é—»æº*
"""

            logger.info(
                f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}"
            )
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€æ–°é—»å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€æ–°é—»å·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_sentiment_unified", log_args=True)
    def get_stock_sentiment_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨æƒ…ç»ªåˆ†æå·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æƒ…ç»ªæ•°æ®æº

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: æƒ…ç»ªåˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from tradingagents.utils.stock_utils import StockUtils

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info["is_china"]
            is_hk = market_info["is_hk"]
            is_us = market_info["is_us"]

            logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

            result_data = []

            if is_china or is_hk:
                # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
                logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ä¸­æ–‡å¸‚åœºæƒ…ç»ª...")

                try:
                    # å¯ä»¥é›†æˆå¾®åšã€é›ªçƒã€ä¸œæ–¹è´¢å¯Œç­‰ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ª
                    # ç›®å‰ä½¿ç”¨åŸºç¡€çš„æƒ…ç»ªåˆ†æ
                    sentiment_summary = f"""
## ä¸­æ–‡å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨**: {ticker} ({market_info["market_name"]})
**åˆ†ææ—¥æœŸ**: {curr_date}

### å¸‚åœºæƒ…ç»ªæ¦‚å†µ
- ç”±äºä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®æºæš‚æœªå®Œå…¨é›†æˆï¼Œå½“å‰æä¾›åŸºç¡€åˆ†æ
- å»ºè®®å…³æ³¨é›ªçƒã€ä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºç­‰å¹³å°çš„è®¨è®ºçƒ­åº¦
- æ¸¯è‚¡å¸‚åœºè¿˜éœ€å…³æ³¨é¦™æ¸¯æœ¬åœ°è´¢ç»åª’ä½“æƒ…ç»ª

### æƒ…ç»ªæŒ‡æ ‡
- æ•´ä½“æƒ…ç»ª: ä¸­æ€§
- è®¨è®ºçƒ­åº¦: å¾…åˆ†æ
- æŠ•èµ„è€…ä¿¡å¿ƒ: å¾…è¯„ä¼°

*æ³¨ï¼šå®Œæ•´çš„ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­*
"""
                    result_data.append(sentiment_summary)
                except Exception as e:
                    result_data.append(f"## ä¸­æ–‡å¸‚åœºæƒ…ç»ª\nè·å–å¤±è´¥: {e}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨Redditæƒ…ç»ªåˆ†æ
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ç¾è‚¡æƒ…ç»ª...")

                try:
                    from tradingagents.dataflows.interface import get_reddit_sentiment

                    sentiment_data = get_reddit_sentiment(ticker, curr_date)
                    result_data.append(f"## ç¾è‚¡Redditæƒ…ç»ª\n{sentiment_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡Redditæƒ…ç»ª\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} æƒ…ç»ªåˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info["market_name"]}
**åˆ†ææ—¥æœŸ**: {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æƒ…ç»ªæ•°æ®æº*
"""

            logger.info(
                f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}"
            )
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] {error_msg}")
            return error_msg
