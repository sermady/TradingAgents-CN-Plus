# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬
ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºç´¢å¼•ï¼Œæå‡æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tradingagents.utils.logging_init import get_logger

logger = get_logger("database_indexes")


def create_mongodb_indexes():
    """åˆ›å»º MongoDB ç´¢å¼•"""

    logger.info("=" * 60)
    logger.info("åˆ›å»º MongoDB ç´¢å¼•")
    logger.info("=" * 60)

    try:
        from app.core.database import get_mongo_db_sync

        db = get_mongo_db_sync()

        # åˆ›å»ºç¼“å­˜é›†åˆç´¢å¼•
        cache_collection = db.cache_collection
        logger.info("\nğŸ“ åˆ›å»ºç¼“å­˜é›†åˆç´¢å¼•...")

        cache_indexes = [
            # ä¸»è¦é”®å”¯ä¸€ç´¢å¼•
            {
                "key": [("key", 1)],
                "unique": True,
                "name": "cache_key_unique",
                "background": True,
            },
            # åˆ›å»ºæ—¶é—´ç´¢å¼•
            {
                "key": [("created_at", -1)],
                "name": "cache_created_at_idx",
                "background": True,
            },
            # TTL ç´¢å¼•
            {"key": [("ttl", 1)], "name": "cache_ttl_idx", "background": True},
            # æ•°æ®ç±»å‹ + åˆ›å»ºæ—¶é—´å¤åˆç´¢å¼•
            {
                "key": [("data_type", 1), ("created_at", -1)],
                "name": "cache_type_created_idx",
                "background": True,
            },
        ]

        for index_spec in cache_indexes:
            try:
                cache_collection.create_index(**index_spec)
                logger.info(f"  âœ… {index_spec['name']}: {index_spec}")
            except Exception as e:
                if "already exists" not in str(e).lower():
                    logger.warning(f"  âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_spec['name']}: {e}")

        # åˆ›å»º Token ä½¿ç”¨é›†åˆç´¢å¼•
        token_usage_collection = db.token_usage
        logger.info("\nğŸ“ åˆ›å»º Token ä½¿ç”¨é›†åˆç´¢å¼•...")

        token_indexes = [
            # æä¾›å•†ç´¢å¼•
            {"key": [("provider", 1)], "name": "provider_idx", "background": True},
            # æ—¥æœŸç´¢å¼•
            {"key": [("date", -1)], "name": "date_idx", "background": True},
            # æä¾›å•† + æ—¥æœŸå¤åˆç´¢å¼•
            {
                "key": [("provider", 1), ("date", -1)],
                "name": "provider_date_idx",
                "background": True,
            },
        ]

        for index_spec in token_indexes:
            try:
                token_usage_collection.create_index(**index_spec)
                logger.info(f"  âœ… {index_spec['name']}: {index_spec}")
            except Exception as e:
                if "already exists" not in str(e).lower():
                    logger.warning(f"  âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_spec['name']}: {e}")

        # åˆ›å»ºç”¨æˆ·é…ç½®é›†åˆç´¢å¼•
        system_configs_collection = db.system_configs
        logger.info("\nğŸ“ åˆ›å»ºç³»ç»Ÿé…ç½®é›†åˆç´¢å¼•...")

        config_indexes = [
            # æ¿€æ´»é…ç½®ç´¢å¼•
            {"key": [("is_active", -1)], "name": "is_active_idx", "background": True},
            # ç‰ˆæœ¬ç´¢å¼•
            {"key": [("version", -1)], "name": "version_idx", "background": True},
        ]

        for index_spec in config_indexes:
            try:
                system_configs_collection.create_index(**index_spec)
                logger.info(f"  âœ… {index_spec['name']}: {index_spec}")
            except Exception as e:
                if "already exists" not in str(e).lower():
                    logger.warning(f"  âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_spec['name']}: {e}")

        # éªŒè¯ç´¢å¼•
        logger.info("\nğŸ” éªŒè¯ç´¢å¼•...")

        # ç¼“å­˜é›†åˆç´¢å¼•éªŒè¯
        logger.info("  cache_collection ç´¢å¼•åˆ—è¡¨:")
        for index in cache_collection.list_indexes():
            logger.info(f"    - {index['name']}: {index['key']}")

        # Token ä½¿ç”¨é›†åˆç´¢å¼•éªŒè¯
        logger.info("  token_usage ç´¢å¼•åˆ—è¡¨:")
        for index in token_usage_collection.list_indexes():
            logger.info(f"    - {index['name']}: {index.get('key', 'N/A')}")

        # ç³»ç»Ÿé…ç½®é›†åˆç´¢å¼•éªŒè¯
        logger.info("  system_configs ç´¢å¼•åˆ—è¡¨:")
        for index in system_configs_collection.list_indexes():
            logger.info(f"    - {index['name']}: {index.get('key', 'N/A')}")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆï¼")
        logger.info("=" * 60 + "\n")

        return True

    except Exception as e:
        logger.error(f"\nâŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return False


def verify_indexes():
    """éªŒè¯ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸ"""

    logger.info("\n" + "=" * 60)
    logger.info("éªŒè¯ç´¢å¼•æ•ˆæœ")
    logger.info("=" * 60)

    try:
        from app.core.database import get_mongo_db_sync

        db = get_mongo_db_sync()

        # æµ‹è¯•æŸ¥è¯¢ï¼šæŸ¥æ‰¾ä»Šå¤©ä¹‹å‰çš„ç¼“å­˜æ•°æ®
        from datetime import datetime, timedelta

        threshold = datetime.now() - timedelta(days=7)

        logger.info("\nğŸ§ª æµ‹è¯•æŸ¥è¯¢ï¼šæŸ¥æ‰¾7å¤©å‰çš„ç¼“å­˜è®°å½•...")

        cache_collection = db.cache_collection
        count = cache_collection.count_documents({"created_at": {"$lt": threshold}})
        logger.info(f"  ğŸ“Š 7å¤©å‰çš„ç¼“å­˜è®°å½•æ•°: {count}")

        # æµ‹è¯•æŸ¥è¯¢ï¼šæŒ‰æä¾›å•†å’Œæ—¥æœŸèšåˆ Token ä½¿ç”¨
        logger.info("\nğŸ§ª æµ‹è¯•æŸ¥è¯¢ï¼šæŒ‰æä¾›å•†èšåˆ Token ä½¿ç”¨...")

        token_usage_collection = db.token_usage
        pipeline = [
            {
                "$group": {
                    "_id": {"provider": "$provider", "date": "$date"},
                    "count": {"$sum": 1},
                }
            },
            {"$sort": {"_id.date": -1}},
            {"$limit": 5},
        ]

        results = list(token_usage_collection.aggregate(pipeline))
        logger.info(f"  ğŸ“Š æœ€è¿‘çš„ Token ä½¿ç”¨è®°å½•:")
        for result in results:
            provider = result["_id"]["provider"]
            date = result["_id"]["date"]
            count = result["count"]
            logger.info(f"    {provider} @ {date}: {count} æ¬¡è°ƒç”¨")

        logger.info("\nâœ… ç´¢å¼•éªŒè¯å®Œæˆï¼")

        return True

    except Exception as e:
        logger.error(f"\nâŒ ç´¢å¼•éªŒè¯å¤±è´¥: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return False


def main():
    """ä¸»å‡½æ•°"""

    logger.info("=" * 60)
    logger.info("æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬")
    logger.info("=" * 60)

    # 1. åˆ›å»ºç´¢å¼•
    create_success = create_mongodb_indexes()

    if create_success:
        # 2. éªŒè¯ç´¢å¼•
        verify_success = verify_indexes()

    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("æ€»ç»“")
    logger.info("=" * 60)
    logger.info(f"  ç´¢å¼•åˆ›å»º: {'âœ… æˆåŠŸ' if create_success else 'âŒ å¤±è´¥'}")
    logger.info(f"  ç´¢å¼•éªŒè¯: {'âœ… æˆåŠŸ' if verify_success else 'âŒ å¤±è´¥'}")

    if create_success and verify_success:
        logger.info("\nâœ… æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å®Œæˆï¼")
        return 0
    else:
        logger.error("\nâŒ æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å¤±è´¥ï¼")
        return 1


if __name__ == "__main__":
    sys.exit(main())
