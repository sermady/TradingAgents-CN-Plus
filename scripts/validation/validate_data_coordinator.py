# -*- coding: utf-8 -*-
"""
DataCoordinator éªŒè¯è„šæœ¬

éªŒè¯ä¼˜åŒ–åçš„ DataCoordinator åŠŸèƒ½:
1. PSæ¯”ç‡éªŒè¯å’Œä¿®æ­£
2. æˆäº¤é‡å•ä½æ ‡å‡†åŒ–
3. å¤šçº§é™çº§ç­–ç•¥
4. æ•°æ®éªŒè¯é›†æˆ
5. æ•°æ®è´¨é‡è¯„åˆ†
6. å¹¶è¡Œæ•°æ®è·å–
7. åˆ†æçº§ç¼“å­˜
8. æ¸¯è‚¡/ç¾è‚¡ä¸æ”¯æŒæç¤º
"""

import sys
import time
from datetime import datetime

sys.path.insert(0, r'E:\WorkSpace\TradingAgents-CN')

from tradingagents.graph.data_coordinator import get_data_coordinator
from tradingagents.utils.trading_date_manager import get_trading_date_manager


def test_ps_ratio_validation():
    """æµ‹è¯• PS æ¯”ç‡éªŒè¯å’Œä¿®æ­£"""
    print("\n" + "=" * 60)
    print("PSæ¯”ç‡éªŒè¯æµ‹è¯•")
    print("=" * 60)

    coordinator = get_data_coordinator()

    # æµ‹è¯•æ•°æ®ï¼šæ¨¡æ‹Ÿæœ‰é—®é¢˜çš„PSæ¯”ç‡ï¼ˆå¦‚605589çš„æƒ…å†µï¼‰
    test_data = {
        "PS": 0.14,  # æ˜æ˜¾é”™è¯¯çš„PS
        "market_cap": 110.96,  # äº¿å…ƒ
        "revenue": 74.12,  # äº¿å…ƒ
    }

    issues, corrected_ps = coordinator._validate_and_fix_ps_ratio(test_data, "605589")

    print(f"\næµ‹è¯•è‚¡ç¥¨: 605589")
    print(f"åŸå§‹PS: {test_data['PS']}")
    print(f"å¸‚å€¼: {test_data['market_cap']}äº¿")
    print(f"è¥æ”¶: {test_data['revenue']}äº¿")
    print(f"è®¡ç®—PS: {test_data['market_cap'] / test_data['revenue']:.2f}")
    print(f"ä¿®æ­£PS: {corrected_ps}")
    print(f"æ£€æµ‹é—®é¢˜æ•°: {len(issues)}")

    if issues:
        print("\næ£€æµ‹åˆ°çš„é—®é¢˜:")
        for issue in issues[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
            print(f"  - [{issue['severity']}] {issue['message']}")

    # éªŒè¯ç»“æœ
    expected_ps = test_data['market_cap'] / test_data['revenue']
    if corrected_ps is None:
        print("âŒ PSæ¯”ç‡éªŒè¯å¤±è´¥: æœªè¿”å›ä¿®æ­£å€¼")
        return False

    if abs(corrected_ps - expected_ps) > 0.1:
        print(f"âŒ PSæ¯”ç‡éªŒè¯å¤±è´¥: ä¿®æ­£å€¼ä¸æ­£ç¡® {corrected_ps} != {expected_ps}")
        return False

    print("âœ… PSæ¯”ç‡éªŒè¯é€šè¿‡")
    return True


def test_volume_standardization():
    """æµ‹è¯•æˆäº¤é‡å•ä½æ ‡å‡†åŒ–"""
    print("\n" + "=" * 60)
    print("æˆäº¤é‡å•ä½æ ‡å‡†åŒ–æµ‹è¯•")
    print("=" * 60)

    coordinator = get_data_coordinator()

    # æµ‹è¯•1: æ˜ç¡®æ ‡æ³¨ä¸º"æ‰‹"çš„æ•°æ®
    test_data_1 = {"volume": 954158}  # å•ä½å¯èƒ½æ˜¯"æ‰‹"
    data_str_1 = "æˆäº¤é‡: 954,158 æ‰‹"

    updated_data, unit_info = coordinator._standardize_volume_unit(test_data_1, data_str_1)

    print(f"\næµ‹è¯• - æ˜ç¡®æ ‡æ³¨ä¸º'æ‰‹':")
    print(f"åŸå§‹æˆäº¤é‡: {test_data_1['volume']}")
    print(f"å¤„ç†åæˆäº¤é‡: {updated_data['volume']}")
    print(f"å•ä½ä¿¡æ¯: {unit_info}")

    if updated_data['volume'] != 95415800:  # åº”è¯¥è½¬æ¢ä¸º"è‚¡"ï¼ˆä¹˜ä»¥100ï¼‰
        print(f"âŒ æˆäº¤é‡æ ‡å‡†åŒ–å¤±è´¥: {updated_data['volume']} != 95415800")
        return False

    if unit_info != "converted_from_lots":
        print(f"âŒ å•ä½ä¿¡æ¯æ ‡è®°å¤±è´¥: {unit_info} != converted_from_lots")
        return False

    print("âœ… æˆäº¤é‡å•ä½æ ‡å‡†åŒ–é€šè¿‡")
    return True


def test_analysis_cache():
    """æµ‹è¯•åˆ†æçº§ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("åˆ†æçº§ç¼“å­˜æµ‹è¯•")
    print("=" * 60)

    coordinator = get_data_coordinator()
    symbol = "000001"
    trade_date = datetime.now().strftime("%Y-%m-%d")

    # æ¸…é™¤ç¼“å­˜
    coordinator.clear_analysis_cache()

    # ç¬¬ä¸€æ¬¡è·å–ï¼ˆåº”è¯¥èµ°ç½‘ç»œï¼‰
    print(f"\nç¬¬ä¸€æ¬¡è·å– {symbol} æ•°æ®...")
    start = time.time()
    result1 = coordinator.fetch_all_data(symbol, trade_date, parallel=True, use_cache=True)
    time1 = time.time() - start
    print(f"è€—æ—¶: {time1:.2f}s")

    # ç¬¬äºŒæ¬¡è·å–ï¼ˆåº”è¯¥ä»ç¼“å­˜è¯»å–ï¼‰
    print(f"\nç¬¬äºŒæ¬¡è·å– {symbol} æ•°æ®ï¼ˆåº”è¯¥ä»ç¼“å­˜è¯»å–ï¼‰...")
    start = time.time()
    result2 = coordinator.fetch_all_data(symbol, trade_date, parallel=True, use_cache=True)
    time2 = time.time() - start
    print(f"è€—æ—¶: {time2:.2f}s")

    # éªŒè¯ç¼“å­˜å‘½ä¸­
    if time2 >= time1 / 2:
        print(f"âš ï¸ ç¼“å­˜å¯èƒ½æœªå‘½ä¸­: ç¬¬äºŒæ¬¡è€—æ—¶ {time2:.2f}s >= ç¬¬ä¸€æ¬¡ {time1:.2f}s / 2")
        # ä¸è¿”å›Falseï¼Œå› ä¸ºå¯èƒ½åªæ˜¯ç½‘ç»œå¾ˆå¿«

    if result1['market_data'] != result2['market_data']:
        print("âŒ ç¼“å­˜æ•°æ®ä¸ä¸€è‡´")
        return False

    print("âœ… åˆ†æçº§ç¼“å­˜æµ‹è¯•é€šè¿‡")
    return True


def test_non_china_market():
    """æµ‹è¯•æ¸¯è‚¡/ç¾è‚¡ä¸æ”¯æŒæç¤º"""
    print("\n" + "=" * 60)
    print("éAè‚¡å¸‚åœºæµ‹è¯•")
    print("=" * 60)

    from tradingagents.graph.data_coordinator import data_coordinator_node

    # æµ‹è¯•ç¾è‚¡
    print("\næµ‹è¯•ç¾è‚¡: AAPL")
    state_us = {
        "company_of_interest": "AAPL",
        "trade_date": datetime.now().strftime("%Y-%m-%d"),
    }
    result_us = data_coordinator_node(state_us)

    print(f"å¸‚åœºæ•°æ®: {result_us['market_data'][:80]}...")

    if "ä¸æ”¯æŒ" not in result_us['market_data'] and "unsupported" not in str(result_us['data_sources'].get('market', '')):
        print("âŒ ç¾è‚¡æœªæ­£ç¡®æç¤ºä¸æ”¯æŒ")
        return False

    # æµ‹è¯•æ¸¯è‚¡
    print("\næµ‹è¯•æ¸¯è‚¡: 00700.HK")
    state_hk = {
        "company_of_interest": "00700.HK",
        "trade_date": datetime.now().strftime("%Y-%m-%d"),
    }
    result_hk = data_coordinator_node(state_hk)

    print(f"å¸‚åœºæ•°æ®: {result_hk['market_data'][:80]}...")

    if "ä¸æ”¯æŒ" not in result_hk['market_data'] and "unsupported" not in str(result_hk['data_sources'].get('market', '')):
        print("âŒ æ¸¯è‚¡æœªæ­£ç¡®æç¤ºä¸æ”¯æŒ")
        return False

    print("âœ… éAè‚¡å¸‚åœºæµ‹è¯•é€šè¿‡")
    return True


def test_data_coordinator():
    """æµ‹è¯• DataCoordinator"""
    print("\n" + "=" * 60)
    print("DataCoordinator åŠŸèƒ½éªŒè¯")
    print("=" * 60)

    # æµ‹è¯•è‚¡ç¥¨ä»£ç ï¼ˆå¹³å®‰é“¶è¡Œï¼‰
    test_symbol = "000001.SZ"
    date_mgr = get_trading_date_manager()
    trade_date = date_mgr.get_latest_trading_date()

    print(f"\nğŸ“Š æµ‹è¯•è‚¡ç¥¨: {test_symbol}")
    print(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {trade_date}")

    # è·å– DataCoordinator
    coordinator = get_data_coordinator()

    # æ¸…é™¤ç¼“å­˜ç¡®ä¿å…¬å¹³æµ‹è¯•
    coordinator.clear_analysis_cache()

    print("\nğŸ”„ å¼€å§‹è·å–æ•°æ®...")
    start_time = time.time()

    # è·å–æ‰€æœ‰æ•°æ®
    results = coordinator.fetch_all_data(test_symbol, trade_date, parallel=True)

    total_time = time.time() - start_time

    print("\n" + "=" * 60)
    print("ğŸ“‹ ç»“æœæ±‡æ€»")
    print("=" * 60)

    # æ˜¾ç¤ºæ•°æ®æ¥æº
    print("\nğŸ“¡ æ•°æ®æ¥æº:")
    for data_type, source in results.get("data_sources", {}).items():
        print(f"   - {data_type}: {source}")

    # æ˜¾ç¤ºæ•°æ®è´¨é‡è¯„åˆ†
    quality_score = results.get("data_quality_score", 0)
    print(f"\nâ­ æ€»ä½“æ•°æ®è´¨é‡è¯„åˆ†: {quality_score:.1%}")

    # æ˜¾ç¤º metadata
    metadata = results.get("data_metadata", {})
    if metadata.get("corrected_ps"):
        print(f"ğŸ“ PSæ¯”ç‡ä¿®æ­£å€¼: {metadata['corrected_ps']}")
    if metadata.get("volume_unit_info"):
        print(f"ğŸ“ æˆäº¤é‡å•ä½å¤„ç†: {metadata['volume_unit_info']}")

    # æ˜¾ç¤ºæ•°æ®é•¿åº¦
    print("\nğŸ“¦ æ•°æ®é•¿åº¦:")
    print(f"   - å¸‚åœºæ•°æ®: {len(results.get('market_data', ''))} å­—ç¬¦")
    print(f"   - åŸºæœ¬é¢æ•°æ®: {len(results.get('financial_data', ''))} å­—ç¬¦")
    print(f"   - æ–°é—»æ•°æ®: {len(results.get('news_data', ''))} å­—ç¬¦")
    print(f"   - èˆ†æƒ…æ•°æ®: {len(results.get('sentiment_data', ''))} å­—ç¬¦")

    # æ˜¾ç¤ºæ•°æ®é—®é¢˜
    issues = results.get("data_issues", {})
    if issues:
        print("\nâš ï¸ æ•°æ®è´¨é‡é—®é¢˜:")
        for data_type, issue_list in issues.items():
            if issue_list:
                print(f"   - {data_type}:")
                for issue in issue_list[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªé—®é¢˜
                    severity = issue.get("severity", "info")
                    message = issue.get("message", "")
                    print(f"     [{severity}] {message}")

    # æ˜¾ç¤ºè€—æ—¶
    fetch_time = results.get("fetch_time", 0)
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {fetch_time:.2f} ç§’")
    print(f"   (éªŒè¯è„šæœ¬æ€»è€—æ—¶: {total_time:.2f} ç§’)")

    # éªŒè¯ç»“æœ
    print("\n" + "=" * 60)
    print("âœ… éªŒè¯ç»“æœ")
    print("=" * 60)

    success = True

    # æ£€æŸ¥æ•°æ®è´¨é‡
    if quality_score >= 0.5:  # é™ä½è¦æ±‚ï¼Œå› ä¸ºæ–°é—»/èˆ†æƒ…æ•°æ®å¯èƒ½ä¸å¯ç”¨
        print("âœ… æ•°æ®è´¨é‡è¯„åˆ†é€šè¿‡ (>= 50%)")
    else:
        print(f"âš ï¸ æ•°æ®è´¨é‡è¯„åˆ†è¾ƒä½: {quality_score:.1%}")
        success = False

    # æ£€æŸ¥æ•°æ®æ¥æº
    sources = results.get("data_sources", {})
    if sources.get("market") != "failed" and sources.get("market") != "unsupported":
        print("âœ… å¸‚åœºæ•°æ®è·å–æˆåŠŸ")
    else:
        print("âŒ å¸‚åœºæ•°æ®è·å–å¤±è´¥")
        success = False

    if sources.get("financial") != "failed" and sources.get("financial") != "unsupported":
        print("âœ… åŸºæœ¬é¢æ•°æ®è·å–æˆåŠŸ")
    else:
        print("âŒ åŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥")
        success = False

    # æ£€æŸ¥è€—æ—¶
    if fetch_time < 30:
        print(f"âœ… æ•°æ®è·å–è€—æ—¶é€šè¿‡ (< 30ç§’)")
    else:
        print(f"âš ï¸ æ•°æ®è·å–è€—æ—¶è¾ƒé•¿: {fetch_time:.2f}ç§’")

    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ æ‰€æœ‰å…³é”®éªŒè¯é€šè¿‡!")
    else:
        print("âš ï¸ éƒ¨åˆ†éªŒè¯æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    print("=" * 60)

    return success


def test_trading_date_manager():
    """æµ‹è¯•äº¤æ˜“æ—¥ç®¡ç†å™¨"""
    print("\n" + "=" * 60)
    print("äº¤æ˜“æ—¥ç®¡ç†å™¨éªŒè¯")
    print("=" * 60)

    date_mgr = get_trading_date_manager()

    # æµ‹è¯•è·å–æœ€æ–°äº¤æ˜“æ—¥
    latest_date = date_mgr.get_latest_trading_date()
    print(f"\nğŸ“… æœ€æ–°äº¤æ˜“æ—¥: {latest_date}")

    # æµ‹è¯•æ—¥æœŸèŒƒå›´
    start_date, end_date = date_mgr.get_trading_date_range(lookback_days=10)
    print(f"ğŸ“… äº¤æ˜“æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")

    # éªŒè¯æ—¥æœŸæ ¼å¼
    try:
        datetime.strptime(latest_date, "%Y-%m-%d")
        print("âœ… æ—¥æœŸæ ¼å¼æ­£ç¡®")
        return True
    except ValueError:
        print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯")
        return False


if __name__ == "__main__":
    print("\nğŸ” å¼€å§‹éªŒè¯ Aè‚¡åˆ†æç³»ç»Ÿä¼˜åŒ–...\n")

    results = []

    # æµ‹è¯•äº¤æ˜“æ—¥ç®¡ç†å™¨
    results.append(("äº¤æ˜“æ—¥ç®¡ç†å™¨", test_trading_date_manager()))

    # æµ‹è¯• PS æ¯”ç‡éªŒè¯
    results.append(("PSæ¯”ç‡éªŒè¯", test_ps_ratio_validation()))

    # æµ‹è¯•æˆäº¤é‡æ ‡å‡†åŒ–
    results.append(("æˆäº¤é‡æ ‡å‡†åŒ–", test_volume_standardization()))

    # æµ‹è¯•åˆ†æçº§ç¼“å­˜
    results.append(("åˆ†æçº§ç¼“å­˜", test_analysis_cache()))

    # æµ‹è¯•éAè‚¡å¸‚åœº
    results.append(("éAè‚¡å¸‚åœºæç¤º", test_non_china_market()))

    # æµ‹è¯• DataCoordinator
    results.append(("DataCoordinator", test_data_coordinator()))

    # æœ€ç»ˆç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆéªŒè¯ç»“æœ")
    print("=" * 60)

    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{name}: {status}")

    passed_count = sum(1 for _, p in results if p)
    total_count = len(results)

    print(f"\næ€»è®¡: {passed_count}/{total_count} é¡¹æµ‹è¯•é€šè¿‡")

    if passed_count == total_count:
        print("\nğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡! Aè‚¡åˆ†æç³»ç»Ÿä¼˜åŒ–æˆåŠŸã€‚")
        sys.exit(0)
    else:
        print("\nâš ï¸ éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å’Œé…ç½®ã€‚")
        sys.exit(1)
