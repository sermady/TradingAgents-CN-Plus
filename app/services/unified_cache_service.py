# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç¼“å­˜æœåŠ¡ (Unified Cache Service)

æ•´åˆMongoDBã€Rediså’ŒFileç¼“å­˜ï¼Œæä¾›ç»Ÿä¸€çš„ç¼“å­˜æ¥å£ã€‚

ç‰¹æ€§:
- å¤šçº§ç¼“å­˜æ”¯æŒ (Redis > MongoDB > File)
- ç»Ÿä¸€çš„ç¼“å­˜é”®å‘½åè§„èŒƒ
- è‡ªåŠ¨ç¼“å­˜å¤±æ•ˆç­–ç•¥
- ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
"""

import json
import hashlib
import logging
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, timezone, timedelta
from pathlib import Path
from threading import Lock
import redis
from pymongo import MongoClient
from pymongo.errors import PyMongoError

from app.core.database import get_mongo_db, get_redis_client
from app.core.config import settings

logger = logging.getLogger(__name__)


class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""

    def __init__(
        self,
        key: str,
        value: Any,
        ttl: int = 3600,  # é»˜è®¤1å°æ—¶
        source: str = "memory",
    ):
        self.key = key
        self.value = value
        self.created_at = datetime.now(timezone.utc)
        self.updated_at = datetime.now(timezone.utc)
        self.ttl = ttl
        self.source = source
        self.hit_count = 0

    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        age = (datetime.now(timezone.utc) - self.created_at).total_seconds()
        return age > self.ttl


class UnifiedCacheService:
    """
    ç»Ÿä¸€ç¼“å­˜æœåŠ¡

    æ”¯æŒå¤šçº§ç¼“å­˜:
    1. å†…å­˜ç¼“å­˜ (æœ€å¿«)
    2. Redisç¼“å­˜ (åˆ†å¸ƒå¼)
    3. MongoDBç¼“å­˜ (æŒä¹…åŒ–)
    4. Fileç¼“å­˜ (æŒä¹…åŒ–)
    """

    _instance: Optional["UnifiedCacheService"] = None
    _lock: Lock = Lock()

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        # å†…å­˜ç¼“å­˜
        self._memory_cache: Dict[str, CacheEntry] = {}
        self._memory_lock = Lock()

        # Rediså®¢æˆ·ç«¯
        self._redis_client = None
        self._redis_prefix = "tradingagents:cache:"

        # MongoDBå®¢æˆ·ç«¯
        self._mongo_client = None
        self._mongo_db_name = settings.MONGODB_DATABASE
        self._mongo_collection = "cache_store"

        # Fileç¼“å­˜è·¯å¾„
        self._file_cache_dir = Path("data/cache")
        self._file_cache_dir.mkdir(parents=True, exist_ok=True)

        # ç¼“å­˜ç»Ÿè®¡
        self._stats = {"hits": 0, "misses": 0, "sets": 0, "deletes": 0, "expires": 0}
        self._stats_lock = Lock()

        # é˜²é›ªå´©ä¿æŠ¤ (Cache Stampede Protection)
        # ä½¿ç”¨é”å­—å…¸é˜²æ­¢åŒä¸€keyçš„å¹¶å‘é‡å»º
        self._refresh_locks: Dict[str, Lock] = {}
        self._refresh_locks_lock = Lock()
        # æ ‡è®°æ­£åœ¨é‡å»ºä¸­çš„key
        self._refreshing_keys: set = set()
        # æ—©æœŸåˆ·æ–°é˜ˆå€¼ï¼ˆåœ¨TTLå‰©ä½™å¤šå°‘æ¯”ä¾‹æ—¶æå‰åˆ·æ–°ï¼‰
        self._early_refresh_ratio = 0.2
        # é™ˆæ—§æ•°æ®å®¹å¿æ—¶é—´ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿç»§ç»­ä½¿ç”¨çš„æ—¶é—´ï¼Œå•ä½ï¼šç§’ï¼‰
        self._stale_ttl_tolerance = 30

        self._initialized = True
        logger.info("âœ… ç»Ÿä¸€ç¼“å­˜æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆå«é˜²é›ªå´©ä¿æŠ¤ï¼‰")

    # ==================== é”®ç®¡ç† ====================

    @staticmethod
    def normalize_key(key: str, category: str = "general") -> str:
        """
        è§„èŒƒåŒ–ç¼“å­˜é”®

        Args:
            key: åŸå§‹é”®
            category: ç¼“å­˜ç±»åˆ«

        Returns:
            è§„èŒƒåŒ–çš„ç¼“å­˜é”®
        """
        # è½¬æ¢ä¸ºå°å†™
        key = key.lower()
        # æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
        key = key.replace(" ", "_").replace(":", "_").replace("-", "_")
        # æ·»åŠ ç±»åˆ«å‰ç¼€
        return f"{category}:{key}"

    @staticmethod
    def generate_cache_key(category: str, *args, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            category: ç¼“å­˜ç±»åˆ«
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°

        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        # åºåˆ—åŒ–å‚æ•°
        key_parts = [str(arg) for arg in args]
        key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))

        # ç”Ÿæˆå“ˆå¸Œ
        key_str = ":".join(key_parts)
        key_hash = hashlib.md5(key_str.encode()).hexdigest()[:16]

        return f"{category}:{key_hash}"

    # ==================== é˜²é›ªå´©ä¿æŠ¤æ–¹æ³• ====================

    def _get_refresh_lock(self, key: str) -> Lock:
        """è·å–æŒ‡å®škeyçš„åˆ·æ–°é”ï¼ˆç”¨äºé˜²æ­¢å¹¶å‘é‡å»ºï¼‰"""
        with self._refresh_locks_lock:
            if key not in self._refresh_locks:
                self._refresh_locks[key] = Lock()
            return self._refresh_locks[key]

    def _is_refreshing(self, key: str) -> bool:
        """æ£€æŸ¥æŒ‡å®škeyæ˜¯å¦æ­£åœ¨åˆ·æ–°ä¸­"""
        with self._refresh_locks_lock:
            return key in self._refreshing_keys

    def _mark_refreshing(self, key: str):
        """æ ‡è®°keyæ­£åœ¨åˆ·æ–°ä¸­"""
        with self._refresh_locks_lock:
            self._refreshing_keys.add(key)

    def _unmark_refreshing(self, key: str):
        """å–æ¶ˆæ ‡è®°keyæ­£åœ¨åˆ·æ–°ä¸­"""
        with self._refresh_locks_lock:
            self._refreshing_keys.discard(key)

    def _should_early_refresh(self, entry: "CacheEntry") -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æå‰åˆ·æ–°ï¼ˆé¢„é˜²é›ªå´©ï¼‰

        åœ¨TTLå‰©ä½™20%æ—¶æå‰è§¦å‘åˆ·æ–°ï¼Œé¿å…å¤§é‡è¯·æ±‚åŒæ—¶ç­‰å¾…ç¼“å­˜è¿‡æœŸ
        """
        if entry.ttl <= 0:
            return False
        age = (datetime.now(timezone.utc) - entry.created_at).total_seconds()
        remaining_ratio = (entry.ttl - age) / entry.ttl
        return remaining_ratio < self._early_refresh_ratio

    def get_with_refresh(
        self,
        key: str,
        refresh_func,
        category: str = "general",
        ttl: int = 3600,
        refresh_ttl: int = 30,
        levels: List[str] = None,
    ) -> Tuple[Optional[Any], str]:
        """è·å–ç¼“å­˜å€¼ï¼Œå¹¶åœ¨éœ€è¦æ—¶è‡ªåŠ¨åˆ·æ–°ï¼ˆé˜²é›ªå´©ç‰ˆæœ¬ï¼‰

        æ ¸å¿ƒæœºåˆ¶ï¼š
        1. ä¼˜å…ˆè¿”å›ç°æœ‰ç¼“å­˜ï¼ˆå³ä½¿å·²è¿‡æœŸï¼Œåœ¨å®¹å¿æœŸå†…ä»å¯ç”¨ï¼‰
        2. åªæœ‰ä¸€ä¸ªè¯·æ±‚è´Ÿè´£é‡å»ºç¼“å­˜
        3. é‡å»ºæœŸé—´å…¶ä»–è¯·æ±‚è¿”å›æ—§æ•°æ®ï¼Œé¿å…ç­‰å¾…

        Args:
            key: ç¼“å­˜é”®
            refresh_func: åˆ·æ–°å‡½æ•°ï¼Œè¿”å›æ–°å€¼
            category: ç¼“å­˜ç±»åˆ«
            ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            refresh_ttl: é‡å»ºé”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            levels: ç¼“å­˜çº§åˆ«

        Returns:
            (å€¼, æ¥æº) - æ¥æºå¯èƒ½æ˜¯ "memory", "redis", "stale", "refreshed", "error"
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb"]

        normalized_key = self.normalize_key(key, category)

        # æ­¥éª¤1ï¼šå°è¯•è·å–ç°æœ‰ç¼“å­˜
        value, source = self.get(key, category, levels)

        if value is not None:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æå‰åˆ·æ–°ï¼ˆé¢„é˜²æ€§åˆ·æ–°ï¼‰
            with self._memory_lock:
                entry = self._memory_cache.get(normalized_key)
                if entry and not self._should_early_refresh(entry):
                    # ç¼“å­˜æ­£å¸¸ï¼Œæ— éœ€åˆ·æ–°
                    return value, source

        # æ­¥éª¤2ï¼šå°è¯•è·å–åˆ·æ–°é”ï¼ˆåªæœ‰ä¸€ä¸ªè¯·æ±‚èƒ½é‡å»ºï¼‰
        refresh_lock = self._get_refresh_lock(normalized_key)
        acquired = refresh_lock.acquire(blocking=False)

        if not acquired:
            # å…¶ä»–è¯·æ±‚æ­£åœ¨é‡å»ºï¼Œè¿”å›ç°æœ‰å€¼ï¼ˆå³ä½¿è¿‡æœŸï¼‰
            if value is not None:
                logger.debug(f"âš¡ ç¼“å­˜é‡å»ºä¸­ï¼Œè¿”å›æ—§å€¼: {normalized_key}")
                return value, f"{source}_stale"
            # æ²¡æœ‰æ—§å€¼ï¼Œç­‰å¾…å…¶ä»–è¯·æ±‚é‡å»ºå®Œæˆ
            acquired_timeout = refresh_lock.acquire(timeout=refresh_ttl)
            if acquired_timeout:
                refresh_lock.release()
            # å†æ¬¡å°è¯•è·å–ç¼“å­˜
            value, source = self.get(key, category, levels)
            if value is not None:
                return value, source
            return None, "timeout"

        # æ­¥éª¤3ï¼šè·å¾—é”ï¼Œæ‰§è¡Œé‡å»º
        try:
            self._mark_refreshing(normalized_key)
            logger.info(f"ğŸ”„ ç¼“å­˜é‡å»º: {normalized_key}")

            # æ‰§è¡Œåˆ·æ–°å‡½æ•°
            new_value = refresh_func()

            if new_value is not None:
                # ä¿å­˜æ–°ç¼“å­˜
                self.set(key, new_value, ttl, category, levels)
                return new_value, "refreshed"
            else:
                # åˆ·æ–°å¤±è´¥ï¼Œè¿”å›æ—§å€¼
                if value is not None:
                    logger.warning(f"âš ï¸ åˆ·æ–°å¤±è´¥ï¼Œä½¿ç”¨æ—§å€¼: {normalized_key}")
                    return value, f"{source}_stale"
                return None, "error"

        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜é‡å»ºå¼‚å¸¸ {normalized_key}: {e}")
            # å¼‚å¸¸æ—¶è¿”å›æ—§å€¼
            if value is not None:
                return value, f"{source}_stale"
            return None, "error"
        finally:
            self._unmark_refreshing(normalized_key)
            refresh_lock.release()

    # ==================== å†…å­˜ç¼“å­˜ ====================

    def _get_from_memory(self, key: str) -> Tuple[Optional[Any], str]:
        """
        ä»å†…å­˜è·å–ç¼“å­˜

        Returns:
            (å€¼, æ¥æº)
        """
        with self._memory_lock:
            if key in self._memory_cache:
                entry = self._memory_cache[key]
                if not entry.is_expired():
                    entry.hit_count += 1
                    self._increment_stat("hits")
                    logger.debug(f"ğŸ“¦ å†…å­˜ç¼“å­˜å‘½ä¸­: {key}")
                    return entry.value, "memory"
                else:
                    del self._memory_cache[key]
                    self._increment_stat("expires")
            self._increment_stat("misses")
            return None, "memory"

    def _set_to_memory(
        self, key: str, value: Any, ttl: int = 3600, category: str = "general"
    ):
        """è®¾ç½®å†…å­˜ç¼“å­˜"""
        with self._memory_lock:
            self._memory_cache[key] = CacheEntry(
                key=key, value=value, ttl=ttl, source="memory"
            )
            self._increment_stat("sets")
            logger.debug(f"ğŸ’¾ è®¾ç½®å†…å­˜ç¼“å­˜: {key} (TTL: {ttl}s)")

    def _delete_from_memory(self, key: str) -> bool:
        """åˆ é™¤å†…å­˜ç¼“å­˜"""
        with self._memory_lock:
            if key in self._memory_cache:
                del self._memory_cache[key]
                self._increment_stat("deletes")
                return True
        return False

    # ==================== Redisç¼“å­˜ ====================

    def _get_redis_client(self) -> Optional[redis.Redis]:
        """è·å–Rediså®¢æˆ·ç«¯

        å¸¦å¥åº·æ£€æŸ¥å’Œé™çº§ç­–ç•¥çš„Redisè¿æ¥ç®¡ç†

        Returns:
            Rediså®¢æˆ·ç«¯ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å›None
        """
        if self._redis_client is None:
            try:
                self._redis_client = get_redis_client()

                # å¥åº·æ£€æŸ¥ï¼šå°è¯•ping Redis
                if self._redis_client:
                    self._redis_client.ping()
                    logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ Redisè¿æ¥å¤±è´¥: pingå¤±è´¥")
                    self._redis_client = None

            except redis.ConnectionError as e:
                logger.warning(f"âš ï¸ Redisè¿æ¥å¤±è´¥: {e}")
                logger.info("ğŸ’¡ å°†è‡ªåŠ¨é™çº§åˆ°MongoDBç¼“å­˜")
                self._redis_client = None
            except redis.TimeoutError as e:
                logger.warning(f"âš ï¸ Redisè¿æ¥è¶…æ—¶: {e}")
                logger.info("ğŸ’¡ å°†è‡ªåŠ¨é™çº§åˆ°MongoDBç¼“å­˜")
                self._redis_client = None
            except Exception as e:
                logger.warning(f"âš ï¸ Redisåˆå§‹åŒ–å¼‚å¸¸: {e}")
                self._redis_client = None
        else:
            # å·²æœ‰å®¢æˆ·ç«¯ï¼Œå®šæœŸæ£€æŸ¥å¥åº·çŠ¶æ€
            try:
                self._redis_client.ping()
            except Exception as e:
                logger.warning(f"âš ï¸ Rediså¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                logger.info("ğŸ’¡ å°†è‡ªåŠ¨é™çº§åˆ°MongoDBç¼“å­˜")
                self._redis_client = None

        return self._redis_client

    def _get_from_redis(self, key: str) -> Tuple[Optional[Any], str]:
        """
        ä»Redisè·å–ç¼“å­˜

        Returns:
            (å€¼, æ¥æº)
        """
        client = self._get_redis_client()
        if client is None:
            return None, "redis"

        try:
            full_key = self._redis_prefix + key
            data = client.get(full_key)

            if data:
                value = json.loads(data)
                client.expire(full_key, 3600)  # åˆ·æ–°TTL

                with self._stats_lock:
                    self._stats["hits"] += 1
                logger.debug(f"ğŸ“¦ Redisç¼“å­˜å‘½ä¸­: {key}")
                return value, "redis"

            with self._stats_lock:
                self._stats["misses"] += 1
            return None, "redis"

        except Exception as e:
            logger.warning(f"âš ï¸ Redisè¯»å–å¤±è´¥: {e}")
            return None, "redis"

    def _set_to_redis(
        self, key: str, value: Any, ttl: int = 3600, category: str = "general"
    ):
        """è®¾ç½®Redisç¼“å­˜"""
        client = self._get_redis_client()
        if client is None:
            return

        try:
            full_key = self._redis_prefix + key
            data = json.dumps(value, ensure_ascii=False)
            client.setex(full_key, ttl, data)

            with self._stats_lock:
                self._stats["sets"] += 1
            logger.debug(f"ğŸ’¾ è®¾ç½®Redisç¼“å­˜: {key} (TTL: {ttl}s)")

        except Exception as e:
            logger.warning(f"âš ï¸ Rediså†™å…¥å¤±è´¥: {e}")

    def _delete_from_redis(self, key: str) -> bool:
        """åˆ é™¤Redisç¼“å­˜"""
        client = self._get_redis_client()
        if client is None:
            return False

        try:
            full_key = self._redis_prefix + key
            result = client.delete(full_key)
            if result > 0:
                with self._stats_lock:
                    self._stats["deletes"] += 1
                return True
            return False

        except Exception as e:
            logger.warning(f"âš ï¸ Redisåˆ é™¤å¤±è´¥: {e}")
            return False

    # ==================== MongoDBç¼“å­˜ ====================

    def _get_from_mongodb(self, key: str) -> Tuple[Optional[Any], str]:
        """
        ä»MongoDBè·å–ç¼“å­˜

        Returns:
            (å€¼, æ¥æº)
        """
        try:
            db = get_mongo_db()
            collection = db[self._mongo_collection]

            now = datetime.now(timezone.utc)
            doc = collection.find_one({"key": key, "expires_at": {"$gt": now}})

            if doc:
                value = doc.get("value")
                with self._stats_lock:
                    self._stats["hits"] += 1
                logger.debug(f"ğŸ“¦ MongoDBç¼“å­˜å‘½ä¸­: {key}")
                return value, "mongodb"

            with self._stats_lock:
                self._stats["misses"] += 1
            return None, "mongodb"

        except Exception as e:
            logger.warning(f"âš ï¸ MongoDBè¯»å–å¤±è´¥: {e}")
            return None, "mongodb"

    def _set_to_mongodb(
        self, key: str, value: Any, ttl: int = 3600, category: str = "general"
    ):
        """è®¾ç½®MongoDBç¼“å­˜"""
        try:
            db = get_mongo_db()
            collection = db[self._mongo_collection]

            expires_at = datetime.now(timezone.utc) + timedelta(seconds=ttl)

            collection.update_one(
                {"key": key},
                {
                    "$set": {
                        "key": key,
                        "value": value,
                        "category": category,
                        "created_at": datetime.now(timezone.utc),
                        "expires_at": expires_at,
                    }
                },
                upsert=True,
            )

            with self._stats_lock:
                self._stats["sets"] += 1
            logger.debug(f"ğŸ’¾ è®¾ç½®MongoDBç¼“å­˜: {key} (TTL: {ttl}s)")

        except Exception as e:
            logger.warning(f"âš ï¸ MongoDBå†™å…¥å¤±è´¥: {e}")

    def _delete_from_mongodb(self, key: str) -> bool:
        """åˆ é™¤MongoDBç¼“å­˜"""
        try:
            db = get_mongo_db()
            collection = db[self._mongo_collection]

            result = collection.delete_one({"key": key})
            if result.deleted_count > 0:
                with self._stats_lock:
                    self._stats["deletes"] += 1
                return True
            return False

        except Exception as e:
            logger.warning(f"âš ï¸ MongoDBåˆ é™¤å¤±è´¥: {e}")
            return False

    # ==================== Fileç¼“å­˜ ====================

    def _get_from_file(self, key: str) -> Tuple[Optional[Any], str]:
        """
        ä»Fileè·å–ç¼“å­˜

        Returns:
            (å€¼, æ¥æº)
        """
        try:
            file_path = self._file_cache_dir / f"{key}.json"

            if file_path.exists():
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                # æ£€æŸ¥è¿‡æœŸ
                expires_at = datetime.fromisoformat(
                    data.get("expires_at", "2099-12-31")
                )
                if expires_at > datetime.now(timezone.utc):
                    with self._stats_lock:
                        self._stats["hits"] += 1
                    logger.debug(f"ğŸ“¦ Fileç¼“å­˜å‘½ä¸­: {key}")
                    return data.get("value"), "file"
                else:
                    file_path.unlink()  # åˆ é™¤è¿‡æœŸæ–‡ä»¶
                    with self._stats_lock:
                        self._stats["expires"] += 1

            with self._stats_lock:
                self._stats["misses"] += 1
            return None, "file"

        except Exception as e:
            logger.warning(f"âš ï¸ Fileè¯»å–å¤±è´¥: {e}")
            return None, "file"

    def _set_to_file(
        self, key: str, value: Any, ttl: int = 3600, category: str = "general"
    ):
        """è®¾ç½®Fileç¼“å­˜"""
        try:
            file_path = self._file_cache_dir / f"{key}.json"
            file_path.parent.mkdir(parents=True, exist_ok=True)

            expires_at = datetime.now(timezone.utc) + timedelta(seconds=ttl)

            data = {
                "key": key,
                "value": value,
                "category": category,
                "created_at": datetime.now(timezone.utc).isoformat(),
                "expires_at": expires_at.isoformat(),
            }

            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            with self._stats_lock:
                self._stats["sets"] += 1
            logger.debug(f"ğŸ’¾ è®¾ç½®Fileç¼“å­˜: {key} (TTL: {ttl}s)")

        except Exception as e:
            logger.warning(f"âš ï¸ Fileå†™å…¥å¤±è´¥: {e}")

    # ==================== ç»Ÿä¸€æ¥å£ ====================

    def get(
        self, key: str, category: str = "general", levels: List[str] = None
    ) -> Tuple[Optional[Any], str]:
        """
        è·å–ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            category: ç¼“å­˜ç±»åˆ«
            levels: ç¼“å­˜çº§åˆ« ["memory", "redis", "mongodb", "file"]

        Returns:
            (å€¼, æ¥æº)
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb", "file"]

        key = self.normalize_key(key, category)

        for level in levels:
            if level == "memory":
                value, source = self._get_from_memory(key)
            elif level == "redis":
                value, source = self._get_from_redis(key)
            elif level == "mongodb":
                value, source = self._get_from_mongodb(key)
            elif level == "file":
                value, source = self._get_from_file(key)
            else:
                continue

            if value is not None:
                # å›å¡«åˆ°æ›´å¿«çš„ç¼“å­˜
                if level != "memory" and "memory" in levels:
                    self._set_to_memory(key, value, ttl=300, category=category)
                return value, source

        return None, "none"

    def set(
        self,
        key: str,
        value: Any,
        ttl: int = 3600,
        category: str = "general",
        levels: List[str] = None,
    ):
        """
        è®¾ç½®ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´(ç§’)
            category: ç¼“å­˜ç±»åˆ«
            levels: ç¼“å­˜çº§åˆ«
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb", "file"]

        key = self.normalize_key(key, category)

        for level in levels:
            if level == "memory":
                self._set_to_memory(key, value, ttl, category)
            elif level == "redis":
                self._set_to_redis(key, value, ttl, category)
            elif level == "mongodb":
                self._set_to_mongodb(key, value, ttl, category)
            elif level == "file":
                self._set_to_file(key, value, ttl, category)

    def delete(
        self, key: str, category: str = "general", levels: List[str] = None
    ) -> int:
        """
        åˆ é™¤ç¼“å­˜

        Args:
            key: ç¼“å­˜é”®
            category: ç¼“å­˜ç±»åˆ«
            levels: ç¼“å­˜çº§åˆ«

        Returns:
            åˆ é™¤çš„ç¼“å­˜æ•°é‡
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb", "file"]

        key = self.normalize_key(key, category)

        deleted = 0
        for level in levels:
            if level == "memory" and self._delete_from_memory(key):
                deleted += 1
            elif level == "redis" and self._delete_from_redis(key):
                deleted += 1
            elif level == "mongodb" and self._delete_from_mongodb(key):
                deleted += 1

        logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜: {key} ({deleted}ä¸ªçº§åˆ«)")
        return deleted

    def clear_category(self, category: str, levels: List[str] = None) -> int:
        """
        æ¸…é™¤ç±»åˆ«ç¼“å­˜

        Args:
            category: ç¼“å­˜ç±»åˆ«
            levels: ç¼“å­˜çº§åˆ«

        Returns:
            æ¸…é™¤çš„ç¼“å­˜æ•°é‡
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb"]

        deleted = 0

        # æ¸…é™¤å†…å­˜ç¼“å­˜
        if "memory" in levels:
            with self._memory_lock:
                keys_to_delete = [
                    k for k in self._memory_cache if k.startswith(category + ":")
                ]
                for key in keys_to_delete:
                    del self._memory_cache[key]
                    deleted += 1

        # æ¸…é™¤MongoDBç¼“å­˜
        if "mongodb" in levels:
            try:
                db = get_mongo_db()
                collection = db[self._mongo_collection]
                result = collection.delete_many({"category": category})
                deleted += result.deleted_count
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…é™¤MongoDBç¼“å­˜å¤±è´¥: {e}")

        # æ¸…é™¤Redisç¼“å­˜
        if "redis" in levels:
            client = self._get_redis_client()
            if client:
                try:
                    pattern = self._redis_prefix + category + ":*"
                    keys = list(client.scan_iter(match=pattern))
                    if keys:
                        deleted += client.delete(*keys)
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…é™¤Redisç¼“å­˜å¤±è´¥: {e}")

        logger.info(f"ğŸ—‘ï¸ æ¸…é™¤ç±»åˆ«ç¼“å­˜: {category} ({deleted}ä¸ª)")
        return deleted

    # ==================== ç¼“å­˜å‡»ç©¿ä¿æŠ¤ ====================

    def get_or_set_with_fallback(
        self,
        key: str,
        factory_func,
        category: str = "general",
        ttl: int = 3600,
        fallback_value: Any = None,
        fallback_ttl: int = 60,
        max_retries: int = 3,
        levels: List[str] = None,
    ) -> Tuple[Any, str]:
        """è·å–æˆ–è®¾ç½®ç¼“å­˜ï¼Œå¸¦ç¼“å­˜å‡»ç©¿ä¿æŠ¤

        å½“ç¼“å­˜å¤±æ•ˆä¸”æ•°æ®æºä¸å¯ç”¨æ—¶ï¼Œé˜²æ­¢å¤§é‡è¯·æ±‚ç›´æ¥å†²å‡»åç«¯ç³»ç»Ÿã€‚
        ä½¿ç”¨é™çº§ç­–ç•¥ï¼š
        1. æ­£å¸¸è·å–ç¼“å­˜
        2. ç¼“å­˜å¤±æ•ˆæ—¶ï¼Œåªæœ‰ä¸€ä¸ªè¯·æ±‚é‡å»º
        3. é‡å»ºå¤±è´¥æ—¶ï¼Œè¿”å›å…œåº•å€¼å¹¶è®¾ç½®çŸ­æ—¶æ•ˆç¼“å­˜

        Args:
            key: ç¼“å­˜é”®
            factory_func: æ•°æ®å·¥å‚å‡½æ•°ï¼ˆç”¨äºé‡å»ºç¼“å­˜ï¼‰
            category: ç¼“å­˜ç±»åˆ«
            ttl: æ­£å¸¸ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            fallback_value: å…œåº•å€¼ï¼ˆå½“factory_funcå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
            fallback_ttl: å…œåº•å€¼ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤60ç§’ï¼‰
            max_retries: é‡å»ºé‡è¯•æ¬¡æ•°
            levels: ç¼“å­˜çº§åˆ«

        Returns:
            (å€¼, æ¥æº) - æ¥æºå¯èƒ½æ˜¯ "cache", "refreshed", "fallback", "error"
        """
        if levels is None:
            levels = ["memory", "redis", "mongodb"]

        # æ­¥éª¤1ï¼šå°è¯•è·å–ç°æœ‰ç¼“å­˜
        value, source = self.get(key, category, levels)

        if value is not None:
            return value, source

        # æ­¥éª¤2ï¼šä½¿ç”¨é˜²é›ªå´©æœºåˆ¶é‡å»ºç¼“å­˜
        normalized_key = self.normalize_key(key, category)
        refresh_lock = self._get_refresh_lock(normalized_key)
        acquired = refresh_lock.acquire(blocking=False)

        if not acquired:
            # å…¶ä»–è¯·æ±‚æ­£åœ¨é‡å»ºï¼Œç­‰å¾…åé‡è¯•
            logger.debug(f"â³ ç­‰å¾…ç¼“å­˜é‡å»º: {normalized_key}")
            acquired_timeout = refresh_lock.acquire(timeout=fallback_ttl)
            if acquired_timeout:
                refresh_lock.release()

            # å†æ¬¡å°è¯•è·å–
            value, source = self.get(key, category, levels)
            if value is not None:
                return value, source
            # ä»ç„¶æ²¡æœ‰ï¼Œä½¿ç”¨å…œåº•å€¼
            if fallback_value is not None:
                logger.warning(f"âš ï¸ ä½¿ç”¨å…œåº•å€¼: {normalized_key}")
                return fallback_value, "fallback"
            return None, "error"

        # æ­¥éª¤3ï¼šè·å¾—é”ï¼Œå°è¯•é‡å»º
        try:
            self._mark_refreshing(normalized_key)

            # é‡è¯•æœºåˆ¶
            for attempt in range(max_retries):
                try:
                    logger.info(
                        f"ğŸ”„ ç¼“å­˜é‡å»ºå°è¯• {attempt + 1}/{max_retries}: {normalized_key}"
                    )
                    new_value = factory_func()

                    if new_value is not None:
                        # é‡å»ºæˆåŠŸï¼Œä¿å­˜æ­£å¸¸ç¼“å­˜
                        self.set(key, new_value, ttl, category, levels)
                        return new_value, "refreshed"

                    # å·¥å‚å‡½æ•°è¿”å›Noneï¼ŒçŸ­æš‚ç­‰å¾…åé‡è¯•
                    if attempt < max_retries - 1:
                        import time

                        time.sleep(0.5 * (attempt + 1))

                except Exception as e:
                    logger.error(f"âŒ é‡å»ºå°è¯• {attempt + 1} å¤±è´¥: {e}")
                    if attempt < max_retries - 1:
                        import time

                        time.sleep(0.5 * (attempt + 1))

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨å…œåº•å€¼
            if fallback_value is not None:
                logger.warning(f"âš ï¸ é‡å»ºå¤±è´¥ï¼Œä½¿ç”¨å…œåº•å€¼: {normalized_key}")
                # è®¾ç½®çŸ­æ—¶æ•ˆç¼“å­˜ï¼Œé˜²æ­¢æŒç»­å†²å‡»
                self.set(key, fallback_value, fallback_ttl, category, levels)
                return fallback_value, "fallback"

            return None, "error"

        finally:
            self._unmark_refreshing(normalized_key)
            refresh_lock.release()

    def set_circuit_breaker(
        self,
        key: str,
        is_fail: bool,
        category: str = "general",
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
    ) -> bool:
        """è®¾ç½®ç†”æ–­å™¨çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆç¼“å­˜å‡»ç©¿ä¿æŠ¤ï¼‰

        å½“æ•°æ®æºè¿ç»­å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å¯ç”¨å…œåº•æ¨¡å¼ã€‚

        Args:
            key: ç¼“å­˜é”®
            is_fail: æœ¬æ¬¡è¯·æ±‚æ˜¯å¦å¤±è´¥
            category: ç¼“å­˜ç±»åˆ«
            failure_threshold: å¤±è´¥é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™å¯ç”¨å…œåº•
            recovery_timeout: æ¢å¤è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            True: å½“å‰åº”è¯¥ä½¿ç”¨å…œåº•æ¨¡å¼
            False: æ­£å¸¸æ¨¡å¼
        """
        cb_key = f"_circuit_breaker:{category}:{key}"

        # è·å–å½“å‰ç†”æ–­å™¨çŠ¶æ€
        state, _ = self.get(cb_key, "_internal", ["memory"])

        if state is None:
            state = {"failures": 0, "last_failure": None, "open": False}

        if is_fail:
            state["failures"] += 1
            state["last_failure"] = datetime.now(timezone.utc).isoformat()

            if state["failures"] >= failure_threshold:
                state["open"] = True
                logger.warning(f"ğŸ”¥ ç†”æ–­å™¨å¼€å¯: {key} (è¿ç»­{state['failures']}æ¬¡å¤±è´¥)")
        else:
            # æˆåŠŸï¼Œå‡å°‘å¤±è´¥è®¡æ•°
            if state["failures"] > 0:
                state["failures"] -= 1

            # å¦‚æœç†”æ–­å™¨å¼€å¯ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥å…³é—­
            if state["open"] and state["last_failure"]:
                last_fail = datetime.fromisoformat(state["last_failure"])
                elapsed = (datetime.now(timezone.utc) - last_fail).total_seconds()
                if elapsed > recovery_timeout:
                    state["open"] = False
                    state["failures"] = 0
                    logger.info(f"âœ… ç†”æ–­å™¨å…³é—­: {key} (å·²æ¢å¤{elapsed:.0f}ç§’)")

        # ä¿å­˜ç†”æ–­å™¨çŠ¶æ€ï¼ˆçŸ­æ—¶æ•ˆï¼‰
        self.set(cb_key, state, 300, "_internal", ["memory"])

        return state["open"]

    # ==================== ç»Ÿè®¡ ====================

    def _increment_stat(self, stat: str):
        """å¢åŠ ç»Ÿè®¡"""
        with self._stats_lock:
            if stat in self._stats:
                self._stats[stat] += 1

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self._stats_lock:
            stats = self._stats.copy()

        total = stats["hits"] + stats["misses"]
        hit_rate = (stats["hits"] / total * 100) if total > 0 else 0

        return {
            "hits": stats["hits"],
            "misses": stats["misses"],
            "sets": stats["sets"],
            "deletes": stats["deletes"],
            "expires": stats["expires"],
            "hit_rate": f"{hit_rate:.2f}%",
            "memory_cache_size": len(self._memory_cache),
        }

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        with self._stats_lock:
            self._stats = {
                "hits": 0,
                "misses": 0,
                "sets": 0,
                "deletes": 0,
                "expires": 0,
            }
        logger.info("ğŸ“Š ç¼“å­˜ç»Ÿè®¡å·²é‡ç½®")


# å…¨å±€ç¼“å­˜æœåŠ¡å®ä¾‹
_cache_service: Optional[UnifiedCacheService] = None


def get_cache_service() -> UnifiedCacheService:
    """è·å–å…¨å±€ç¼“å­˜æœåŠ¡å®ä¾‹"""
    global _cache_service
    if _cache_service is None:
        _cache_service = UnifiedCacheService()
    return _cache_service
