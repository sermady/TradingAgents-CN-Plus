# -*- coding: utf-8 -*-
"""
Data source manager that orchestrates multiple adapters with priority and optional consistency checks
"""

from typing import List, Optional, Tuple, Dict
import logging
from datetime import datetime, timedelta
import pandas as pd

from .base import DataSourceAdapter
from .tushare_adapter import TushareAdapter
from .akshare_adapter import AKShareAdapter
from .baostock_adapter import BaoStockAdapter

logger = logging.getLogger(__name__)


class DataSourceManager:
    """
    æ•°æ®æºç®¡ç†å™¨
    - ç®¡ç†å¤šä¸ªé€‚é…å™¨ï¼ŒåŸºäºä¼˜å…ˆçº§æ’åº
    - æä¾› fallback è·å–èƒ½åŠ›
    - å¯é€‰ï¼šä¸€è‡´æ€§æ£€æŸ¥ï¼ˆè‹¥ä¾èµ–å­˜åœ¨ï¼‰
    """

    def __init__(self):
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ BaoStockï¼ˆé»˜è®¤ç¦ç”¨ï¼‰
        import os
        baostock_enabled = os.getenv("BAOSTOCK_UNIFIED_ENABLED", "false").lower() in ("true", "1", "yes")

        adapters_list = [
            TushareAdapter(),
            AKShareAdapter(),
        ]

        # ä»…åœ¨æ˜ç¡®å¯ç”¨æ—¶æ·»åŠ  BaoStock
        if baostock_enabled:
            adapters_list.append(BaoStockAdapter())
            logger.info("âœ… BaoStock æ•°æ®æºå·²å¯ç”¨")
        else:
            logger.info("â¸ï¸ BaoStock æ•°æ®æºå·²ç¦ç”¨ï¼ˆé€šè¿‡é…ç½®ï¼‰")

        self.adapters: List[DataSourceAdapter] = adapters_list

        # ä»æ•°æ®åº“åŠ è½½ä¼˜å…ˆçº§é…ç½®
        self._load_priority_from_database()

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼Œæ‰€ä»¥é™åºæ’åˆ—ï¼‰
        self.adapters.sort(key=lambda x: x.priority, reverse=True)

        try:
            from .data_consistency_checker import DataConsistencyChecker  # type: ignore

            self.consistency_checker = DataConsistencyChecker()
        except Exception:
            logger.warning("âš ï¸ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨ä¸å¯ç”¨")
            self.consistency_checker = None

    def _load_priority_from_database(self):
        """ä»æ•°æ®åº“åŠ è½½æ•°æ®æºä¼˜å…ˆçº§é…ç½®ï¼ˆä» datasource_groupings é›†åˆè¯»å– Aè‚¡å¸‚åœºçš„ä¼˜å…ˆçº§ï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync

            db = get_mongo_db_sync()
            groupings_collection = db.datasource_groupings

            # æŸ¥è¯¢ Aè‚¡å¸‚åœºçš„æ•°æ®æºåˆ†ç»„é…ç½®
            groupings = list(
                groupings_collection.find(
                    {"market_category_id": "a_shares", "enabled": True}
                )
            )

            if groupings:
                # åˆ›å»ºåç§°åˆ°ä¼˜å…ˆçº§çš„æ˜ å°„ï¼ˆæ•°æ®æºåç§°éœ€è¦è½¬æ¢ä¸ºå°å†™ï¼‰
                priority_map = {}
                for grouping in groupings:
                    data_source_name = grouping.get("data_source_name", "").lower()
                    priority = grouping.get("priority")
                    if data_source_name and priority is not None:
                        priority_map[data_source_name] = priority
                        logger.info(
                            f"ğŸ“Š ä»æ•°æ®åº“è¯»å– {data_source_name} åœ¨ Aè‚¡å¸‚åœºçš„ä¼˜å…ˆçº§: {priority}"
                        )

                # æ›´æ–°å„ä¸ª Adapter çš„ä¼˜å…ˆçº§
                for adapter in self.adapters:
                    if adapter.name in priority_map:
                        # åŠ¨æ€è®¾ç½®ä¼˜å…ˆçº§
                        adapter._priority = priority_map[adapter.name]
                        logger.info(
                            f"âœ… è®¾ç½® {adapter.name} ä¼˜å…ˆçº§: {adapter._priority}"
                        )
                    else:
                        # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
                        adapter._priority = adapter._get_default_priority()
                        logger.info(
                            f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ° {adapter.name} é…ç½®ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§: {adapter._priority}"
                        )
            else:
                logger.info("âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ° Aè‚¡å¸‚åœºçš„æ•°æ®æºé…ç½®ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§")
                # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
                for adapter in self.adapters:
                    adapter._priority = adapter._get_default_priority()
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“åŠ è½½ä¼˜å…ˆçº§å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§")
            import traceback

            logger.warning(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
            for adapter in self.adapters:
                adapter._priority = adapter._get_default_priority()

    def get_available_adapters(self) -> List[DataSourceAdapter]:
        available: List[DataSourceAdapter] = []
        for adapter in self.adapters:
            if adapter.is_available():
                available.append(adapter)
                logger.info(
                    f"Data source {adapter.name} is available (priority: {adapter.priority})"
                )
            else:
                logger.warning(f"Data source {adapter.name} is not available")
        return available

    def get_stock_list_with_fallback(
        self, preferred_sources: Optional[List[str]] = None
    ) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨ï¼Œä¾‹å¦‚ ['akshare', 'baostock']
                             å¦‚æœä¸º Noneï¼Œåˆ™æŒ‰ç…§é»˜è®¤ä¼˜å…ˆçº§é¡ºåº

        Returns:
            (DataFrame, source_name) æˆ– (None, None)
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            logger.info(f"Using preferred data sources: {preferred_sources}")
            # åˆ›å»ºä¼˜å…ˆçº§æ˜ å°„
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            # å°†æŒ‡å®šçš„æ•°æ®æºæ’åœ¨å‰é¢ï¼Œå…¶ä»–çš„ä¿æŒåŸé¡ºåº
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            # æŒ‰ç…§ preferred_sources çš„é¡ºåºæ’åº
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others
            logger.info(f"Reordered adapters: {[a.name for a in available_adapters]}")

        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch stock list from {adapter.name}")
                df = adapter.get_stock_list()
                if df is not None and not df.empty:
                    return df, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch stock list from {adapter.name}: {e}")
                continue
        return None, None

    def get_daily_basic_with_fallback(
        self, trade_date: str, preferred_sources: Optional[List[str]] = None
    ) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """
        è·å–æ¯æ—¥åŸºç¡€æ•°æ®ï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨

        Returns:
            (DataFrame, source_name) æˆ– (None, None)
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others

        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch daily basic data from {adapter.name}")
                df = adapter.get_daily_basic(trade_date)
                if df is not None and not df.empty:
                    return df, adapter.name
            except Exception as e:
                logger.error(
                    f"Failed to fetch daily basic data from {adapter.name}: {e}"
                )
                continue
        return None, None

    def find_latest_trade_date_with_fallback(
        self, preferred_sources: Optional[List[str]] = None
    ) -> Optional[str]:
        """
        æŸ¥æ‰¾æœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨

        Returns:
            äº¤æ˜“æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYYMMDDæ ¼å¼ï¼‰æˆ– None
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others

        for adapter in available_adapters:
            try:
                trade_date = adapter.find_latest_trade_date()
                if trade_date:
                    return trade_date
            except Exception as e:
                logger.error(f"Failed to find trade date from {adapter.name}: {e}")
                continue
        return (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")

    def get_realtime_quotes_with_fallback(
        self,
    ) -> Tuple[Optional[Dict], Optional[str], Dict]:
        """
        è·å–å…¨å¸‚åœºå®æ—¶å¿«ç…§ï¼ŒæŒ‰é€‚é…å™¨ä¼˜å…ˆçº§ä¾æ¬¡å°è¯•ï¼Œè¿”å›é¦–ä¸ªæˆåŠŸç»“æœ

        Returns:
            Tuple[quotes_dict, source_name, diagnostics]
            - quotes_dict: è¡Œæƒ…æ•°æ®ï¼Œæ ¼å¼ { '000001': {'close': 10.0, 'pct_chg': 1.2, 'amount': 1.2e8}, ... }
            - source_name: æˆåŠŸè·å–æ•°æ®çš„æ•°æ®æºåç§°
            - diagnostics: è¯Šæ–­ä¿¡æ¯ï¼ŒåŒ…å«æ‰€æœ‰å°è¯•çš„è¯¦ç»†ä¿¡æ¯
        """
        import os
        import time

        diagnostics = {
            "attempts": [],
            "total_attempts": 0,
            "total_duration": 0.0,
            "fallback_used": False,
            "proxy_status": {
                "http_proxy": os.environ.get("HTTP_PROXY")
                or os.environ.get("http_proxy")
                or "",
                "https_proxy": os.environ.get("HTTPS_PROXY")
                or os.environ.get("https_proxy")
                or "",
            },
        }

        available_adapters = self.get_available_adapters()
        start_time = time.time()

        for adapter in available_adapters:
            attempt_start = time.time()
            diagnostics["total_attempts"] += 1

            try:
                logger.info(f"å°è¯•ä» {adapter.name} è·å–å®æ—¶è¡Œæƒ…...")

                # ğŸ”¥ AKShare æ”¯æŒå¤šä¸ªæ•°æ®æºï¼Œeastmoney å¤±è´¥æ—¶è‡ªåŠ¨å°è¯• sina
                if adapter.name == "akshare":
                    # å…ˆå°è¯• eastmoney
                    data = adapter.get_realtime_quotes(source="eastmoney")
                    if not data:
                        logger.info("ä¸œæ–¹è´¢å¯Œæ¥å£å¤±è´¥ï¼Œå°è¯•æ–°æµªè´¢ç»æ¥å£...")
                        diagnostics["total_attempts"] += 1
                        data = adapter.get_realtime_quotes(source="sina")
                else:
                    data = adapter.get_realtime_quotes()

                duration = time.time() - attempt_start

                if data:
                    diagnostics["attempts"].append(
                        {
                            "source": adapter.name,
                            "success": True,
                            "duration": round(duration, 3),
                            "record_count": len(data),
                            "error": None,
                        }
                    )
                    diagnostics["total_duration"] = time.time() - start_time
                    return data, adapter.name, diagnostics

                diagnostics["attempts"].append(
                    {
                        "source": adapter.name,
                        "success": False,
                        "duration": round(duration, 3),
                        "record_count": 0,
                        "error": "returned_empty_data",
                    }
                )

            except Exception as e:
                duration = time.time() - attempt_start
                error_type = type(e).__name__
                is_network_error = any(
                    x in str(e).lower()
                    for x in [
                        "connection",
                        "remote",
                        "timeout",
                        "aborted",
                        "reset",
                        "closed",
                    ]
                )

                diagnostics["attempts"].append(
                    {
                        "source": adapter.name,
                        "success": False,
                        "duration": round(duration, 3),
                        "record_count": 0,
                        "error_type": error_type,
                        "error": str(e)[:200],
                        "is_network_error": is_network_error,
                    }
                )
                diagnostics["fallback_used"] = True
                continue

        diagnostics["total_duration"] = time.time() - start_time
        logger.error(
            f"âŒ æ‰€æœ‰æ•°æ®æºè·å–å¤±è´¥: "
            f"attempts={diagnostics['total_attempts']}, "
            f"duration={diagnostics['total_duration']:.2f}s"
        )
        return None, None, diagnostics

    def get_daily_quotes_with_fallback(
        self, trade_date: str
    ) -> Tuple[Optional[Dict], Optional[str]]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„å…¨å¸‚åœºæ”¶ç›˜è¡Œæƒ…ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•
        ä¸»è¦ç”¨äºè¡¥å½•å†å²æ”¶ç›˜æ•°æ®

        Returns:
            (quotes_dict, source_name)
        """
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                # æ£€æŸ¥è¯¥ adapter æ˜¯å¦å®ç°äº† get_daily_quotes
                if not hasattr(adapter, "get_daily_quotes"):
                    continue

                logger.info(f"å°è¯•ä» {adapter.name} è·å– {trade_date} çš„æ—¥çº¿è¡Œæƒ…...")
                data = adapter.get_daily_quotes(trade_date)
                if data:
                    return data, adapter.name
            except Exception as e:
                logger.error(f"ä» {adapter.name} è·å–æ—¥çº¿è¡Œæƒ…å¤±è´¥: {e}")
                continue
        return None, None

    def get_snapshot_with_fallback(self) -> Tuple[Optional[Dict], Optional[str]]:
        """
        è·å–æœ€æ–°çš„è¡Œæƒ…å¿«ç…§ï¼ˆç”¨äº backfillï¼‰ã€‚
        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆå°è¯• get_realtime_quotes_with_fallback (Tushare/AkShare å®æ—¶æ¥å£)
        2. å¦‚æœå¤±è´¥ï¼Œå°è¯•è·å–æœ€æ–°äº¤æ˜“æ—¥çš„æ—¥çº¿æ•°æ® get_daily_quotes_with_fallback (Tushare/Baostock)

        Returns:
            (quotes_dict, source_name)
        """
        # 1. å°è¯•å®æ—¶æ¥å£
        logger.info("ğŸ“¡ [Backfillç­–ç•¥] 1. å°è¯•è·å–å®æ—¶è¡Œæƒ…å¿«ç…§...")
        quotes, source, _ = self.get_realtime_quotes_with_fallback()
        if quotes:
            return quotes, source

        # 2. å°è¯•æ—¥çº¿æ¥å£
        logger.info("ğŸ“¡ [Backfillç­–ç•¥] 2. å®æ—¶æ¥å£å¤±è´¥ï¼Œå°è¯•è·å–æœ€æ–°äº¤æ˜“æ—¥æ”¶ç›˜æ•°æ®...")
        try:
            latest_date = self.find_latest_trade_date_with_fallback()
            if not latest_date:
                # å¦‚æœè·å–ä¸åˆ°æœ€æ–°äº¤æ˜“æ—¥ï¼Œå°è¯•ç”¨æ˜¨å¤©
                latest_date = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")

            logger.info(f"ğŸ“… ç›®æ ‡äº¤æ˜“æ—¥: {latest_date}")
            quotes, source = self.get_daily_quotes_with_fallback(latest_date)
            if quotes:
                logger.info(f"âœ… æˆåŠŸä» {source} è·å–åˆ°æ—¥çº¿æ”¶ç›˜æ•°æ®ä½œä¸ºå¿«ç…§")
                return quotes, f"{source}_daily"

        except Exception as e:
            logger.error(f"âŒ è·å–æ—¥çº¿å…œåº•æ•°æ®å¤±è´¥: {e}")

        logger.error("âŒ [Backfillç­–ç•¥] æ‰€æœ‰é€”å¾„å‡å¤±è´¥")
        return None, None

    def get_daily_basic_with_consistency_check(
        self, trade_date: str
    ) -> Tuple[Optional[pd.DataFrame], Optional[str], Optional[Dict]]:
        """
        ä½¿ç”¨ä¸€è‡´æ€§æ£€æŸ¥è·å–æ¯æ—¥åŸºç¡€æ•°æ®

        Returns:
            Tuple[DataFrame, source_name, consistency_report]
        """
        available_adapters = self.get_available_adapters()
        if len(available_adapters) < 2:
            df, source = self.get_daily_basic_with_fallback(trade_date)
            return df, source, None
        primary_adapter = available_adapters[0]
        secondary_adapter = available_adapters[1]
        try:
            logger.info(
                f"ğŸ” è·å–æ•°æ®è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥: {primary_adapter.name} vs {secondary_adapter.name}"
            )
            primary_data = primary_adapter.get_daily_basic(trade_date)
            secondary_data = secondary_adapter.get_daily_basic(trade_date)
            if primary_data is None or primary_data.empty:
                logger.warning(f"âš ï¸ ä¸»æ•°æ®æº{primary_adapter.name}å¤±è´¥ï¼Œä½¿ç”¨fallback")
                df, source = self.get_daily_basic_with_fallback(trade_date)
                return df, source, None
            if secondary_data is None or secondary_data.empty:
                logger.warning(f"âš ï¸ æ¬¡æ•°æ®æº{secondary_adapter.name}å¤±è´¥ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
                return primary_data, primary_adapter.name, None
            if self.consistency_checker:
                consistency_result = (
                    self.consistency_checker.check_daily_basic_consistency(
                        primary_data,
                        secondary_data,
                        primary_adapter.name,
                        secondary_adapter.name,
                    )
                )
                final_data, resolution_strategy = (
                    self.consistency_checker.resolve_data_conflicts(
                        primary_data, secondary_data, consistency_result
                    )
                )
                consistency_report = {
                    "is_consistent": consistency_result.is_consistent,
                    "confidence_score": consistency_result.confidence_score,
                    "recommended_action": consistency_result.recommended_action,
                    "resolution_strategy": resolution_strategy,
                    "differences": consistency_result.differences,
                    "primary_source": primary_adapter.name,
                    "secondary_source": secondary_adapter.name,
                }
                logger.info(
                    f"ğŸ“Š æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ: ç½®ä¿¡åº¦={consistency_result.confidence_score:.2f}, ç­–ç•¥={consistency_result.recommended_action}"
                )
                return final_data, primary_adapter.name, consistency_report
            else:
                logger.warning("âš ï¸ ä¸€è‡´æ€§æ£€æŸ¥å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
                return primary_data, primary_adapter.name, None
        except Exception as e:
            logger.error(f"âŒ ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            df, source = self.get_daily_basic_with_fallback(trade_date)
            return df, source, None

    def get_kline_with_fallback(
        self,
        code: str,
        period: str = "day",
        limit: int = 120,
        adj: Optional[str] = None,
    ) -> Tuple[Optional[List[Dict]], Optional[str]]:
        """æŒ‰ä¼˜å…ˆçº§å°è¯•è·å–Kçº¿ï¼Œè¿”å›(items, source)"""
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch kline from {adapter.name}")
                items = adapter.get_kline(
                    code=code, period=period, limit=limit, adj=adj
                )
                if items:
                    return items, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch kline from {adapter.name}: {e}")
                continue
        return None, None

    def get_news_with_fallback(
        self,
        code: str,
        days: int = 2,
        limit: int = 50,
        include_announcements: bool = True,
    ) -> Tuple[Optional[List[Dict]], Optional[str]]:
        """æŒ‰ä¼˜å…ˆçº§å°è¯•è·å–æ–°é—»ä¸å…¬å‘Šï¼Œè¿”å›(items, source)"""
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch news from {adapter.name}")
                items = adapter.get_news(
                    code=code,
                    days=days,
                    limit=limit,
                    include_announcements=include_announcements,
                )
                if items:
                    return items, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch news from {adapter.name}: {e}")
                continue
        return None, None
